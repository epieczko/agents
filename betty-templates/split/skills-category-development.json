{
  "total_count": 11,
  "category": "development",
  "skills": [
    {
      "name": "api-design-principles",
      "description": "Master REST and GraphQL API design principles to build intuitive, scalable, and maintainable APIs that delight developers. Use when designing new APIs, reviewing API specifications, or establishing API design standards.",
      "plugin": "backend-development",
      "source_path": "plugins/backend-development/skills/api-design-principles/SKILL.md",
      "category": "development",
      "keywords": [
        "backend",
        "api-design",
        "graphql",
        "tdd",
        "architecture"
      ],
      "content": "---\nname: api-design-principles\ndescription: Master REST and GraphQL API design principles to build intuitive, scalable, and maintainable APIs that delight developers. Use when designing new APIs, reviewing API specifications, or establishing API design standards.\n---\n\n# API Design Principles\n\nMaster REST and GraphQL API design principles to build intuitive, scalable, and maintainable APIs that delight developers and stand the test of time.\n\n## When to Use This Skill\n\n- Designing new REST or GraphQL APIs\n- Refactoring existing APIs for better usability\n- Establishing API design standards for your team\n- Reviewing API specifications before implementation\n- Migrating between API paradigms (REST to GraphQL, etc.)\n- Creating developer-friendly API documentation\n- Optimizing APIs for specific use cases (mobile, third-party integrations)\n\n## Core Concepts\n\n### 1. RESTful Design Principles\n\n**Resource-Oriented Architecture**\n- Resources are nouns (users, orders, products), not verbs\n- Use HTTP methods for actions (GET, POST, PUT, PATCH, DELETE)\n- URLs represent resource hierarchies\n- Consistent naming conventions\n\n**HTTP Methods Semantics:**\n- `GET`: Retrieve resources (idempotent, safe)\n- `POST`: Create new resources\n- `PUT`: Replace entire resource (idempotent)\n- `PATCH`: Partial resource updates\n- `DELETE`: Remove resources (idempotent)\n\n### 2. GraphQL Design Principles\n\n**Schema-First Development**\n- Types define your domain model\n- Queries for reading data\n- Mutations for modifying data\n- Subscriptions for real-time updates\n\n**Query Structure:**\n- Clients request exactly what they need\n- Single endpoint, multiple operations\n- Strongly typed schema\n- Introspection built-in\n\n### 3. API Versioning Strategies\n\n**URL Versioning:**\n```\n/api/v1/users\n/api/v2/users\n```\n\n**Header Versioning:**\n```\nAccept: application/vnd.api+json; version=1\n```\n\n**Query Parameter Versioning:**\n```\n/api/users?version=1\n```\n\n## REST API Design Patterns\n\n### Pattern 1: Resource Collection Design\n\n```python\n# Good: Resource-oriented endpoints\nGET    /api/users              # List users (with pagination)\nPOST   /api/users              # Create user\nGET    /api/users/{id}         # Get specific user\nPUT    /api/users/{id}         # Replace user\nPATCH  /api/users/{id}         # Update user fields\nDELETE /api/users/{id}         # Delete user\n\n# Nested resources\nGET    /api/users/{id}/orders  # Get user's orders\nPOST   /api/users/{id}/orders  # Create order for user\n\n# Bad: Action-oriented endpoints (avoid)\nPOST   /api/createUser\nPOST   /api/getUserById\nPOST   /api/deleteUser\n```\n\n### Pattern 2: Pagination and Filtering\n\n```python\nfrom typing import List, Optional\nfrom pydantic import BaseModel, Field\n\nclass PaginationParams(BaseModel):\n    page: int = Field(1, ge=1, description=\"Page number\")\n    page_size: int = Field(20, ge=1, le=100, description=\"Items per page\")\n\nclass FilterParams(BaseModel):\n    status: Optional[str] = None\n    created_after: Optional[str] = None\n    search: Optional[str] = None\n\nclass PaginatedResponse(BaseModel):\n    items: List[dict]\n    total: int\n    page: int\n    page_size: int\n    pages: int\n\n    @property\n    def has_next(self) -> bool:\n        return self.page < self.pages\n\n    @property\n    def has_prev(self) -> bool:\n        return self.page > 1\n\n# FastAPI endpoint example\nfrom fastapi import FastAPI, Query, Depends\n\napp = FastAPI()\n\n@app.get(\"/api/users\", response_model=PaginatedResponse)\nasync def list_users(\n    page: int = Query(1, ge=1),\n    page_size: int = Query(20, ge=1, le=100),\n    status: Optional[str] = Query(None),\n    search: Optional[str] = Query(None)\n):\n    # Apply filters\n    query = build_query(status=status, search=search)\n\n    # Count total\n    total = await count_users(query)\n\n    # Fetch page\n    offset = (page - 1) * page_size\n    users = await fetch_users(query, limit=page_size, offset=offset)\n\n    return PaginatedResponse(\n        items=users,\n        total=total,\n        page=page,\n        page_size=page_size,\n        pages=(total + page_size - 1) // page_size\n    )\n```\n\n### Pattern 3: Error Handling and Status Codes\n\n```python\nfrom fastapi import HTTPException, status\nfrom pydantic import BaseModel\n\nclass ErrorResponse(BaseModel):\n    error: str\n    message: str\n    details: Optional[dict] = None\n    timestamp: str\n    path: str\n\nclass ValidationErrorDetail(BaseModel):\n    field: str\n    message: str\n    value: Any\n\n# Consistent error responses\nSTATUS_CODES = {\n    \"success\": 200,\n    \"created\": 201,\n    \"no_content\": 204,\n    \"bad_request\": 400,\n    \"unauthorized\": 401,\n    \"forbidden\": 403,\n    \"not_found\": 404,\n    \"conflict\": 409,\n    \"unprocessable\": 422,\n    \"internal_error\": 500\n}\n\ndef raise_not_found(resource: str, id: str):\n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail={\n            \"error\": \"NotFound\",\n            \"message\": f\"{resource} not found\",\n            \"details\": {\"id\": id}\n        }\n    )\n\ndef raise_validation_error(errors: List[ValidationErrorDetail]):\n    raise HTTPException(\n        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n        detail={\n            \"error\": \"ValidationError\",\n            \"message\": \"Request validation failed\",\n            \"details\": {\"errors\": [e.dict() for e in errors]}\n        }\n    )\n\n# Example usage\n@app.get(\"/api/users/{user_id}\")\nasync def get_user(user_id: str):\n    user = await fetch_user(user_id)\n    if not user:\n        raise_not_found(\"User\", user_id)\n    return user\n```\n\n### Pattern 4: HATEOAS (Hypermedia as the Engine of Application State)\n\n```python\nclass UserResponse(BaseModel):\n    id: str\n    name: str\n    email: str\n    _links: dict\n\n    @classmethod\n    def from_user(cls, user: User, base_url: str):\n        return cls(\n            id=user.id,\n            name=user.name,\n            email=user.email,\n            _links={\n                \"self\": {\"href\": f\"{base_url}/api/users/{user.id}\"},\n                \"orders\": {\"href\": f\"{base_url}/api/users/{user.id}/orders\"},\n                \"update\": {\n                    \"href\": f\"{base_url}/api/users/{user.id}\",\n                    \"method\": \"PATCH\"\n                },\n                \"delete\": {\n                    \"href\": f\"{base_url}/api/users/{user.id}\",\n                    \"method\": \"DELETE\"\n                }\n            }\n        )\n```\n\n## GraphQL Design Patterns\n\n### Pattern 1: Schema Design\n\n```graphql\n# schema.graphql\n\n# Clear type definitions\ntype User {\n  id: ID!\n  email: String!\n  name: String!\n  createdAt: DateTime!\n\n  # Relationships\n  orders(\n    first: Int = 20\n    after: String\n    status: OrderStatus\n  ): OrderConnection!\n\n  profile: UserProfile\n}\n\ntype Order {\n  id: ID!\n  status: OrderStatus!\n  total: Money!\n  items: [OrderItem!]!\n  createdAt: DateTime!\n\n  # Back-reference\n  user: User!\n}\n\n# Pagination pattern (Relay-style)\ntype OrderConnection {\n  edges: [OrderEdge!]!\n  pageInfo: PageInfo!\n  totalCount: Int!\n}\n\ntype OrderEdge {\n  node: Order!\n  cursor: String!\n}\n\ntype PageInfo {\n  hasNextPage: Boolean!\n  hasPreviousPage: Boolean!\n  startCursor: String\n  endCursor: String\n}\n\n# Enums for type safety\nenum OrderStatus {\n  PENDING\n  CONFIRMED\n  SHIPPED\n  DELIVERED\n  CANCELLED\n}\n\n# Custom scalars\nscalar DateTime\nscalar Money\n\n# Query root\ntype Query {\n  user(id: ID!): User\n  users(\n    first: Int = 20\n    after: String\n    search: String\n  ): UserConnection!\n\n  order(id: ID!): Order\n}\n\n# Mutation root\ntype Mutation {\n  createUser(input: CreateUserInput!): CreateUserPayload!\n  updateUser(input: UpdateUserInput!): UpdateUserPayload!\n  deleteUser(id: ID!): DeleteUserPayload!\n\n  createOrder(input: CreateOrderInput!): CreateOrderPayload!\n}\n\n# Input types for mutations\ninput CreateUserInput {\n  email: String!\n  name: String!\n  password: String!\n}\n\n# Payload types for mutations\ntype CreateUserPayload {\n  user: User\n  errors: [Error!]\n}\n\ntype Error {\n  field: String\n  message: String!\n}\n```\n\n### Pattern 2: Resolver Design\n\n```python\nfrom typing import Optional, List\nfrom ariadne import QueryType, MutationType, ObjectType\nfrom dataclasses import dataclass\n\nquery = QueryType()\nmutation = MutationType()\nuser_type = ObjectType(\"User\")\n\n@query.field(\"user\")\nasync def resolve_user(obj, info, id: str) -> Optional[dict]:\n    \"\"\"Resolve single user by ID.\"\"\"\n    return await fetch_user_by_id(id)\n\n@query.field(\"users\")\nasync def resolve_users(\n    obj,\n    info,\n    first: int = 20,\n    after: Optional[str] = None,\n    search: Optional[str] = None\n) -> dict:\n    \"\"\"Resolve paginated user list.\"\"\"\n    # Decode cursor\n    offset = decode_cursor(after) if after else 0\n\n    # Fetch users\n    users = await fetch_users(\n        limit=first + 1,  # Fetch one extra to check hasNextPage\n        offset=offset,\n        search=search\n    )\n\n    # Pagination\n    has_next = len(users) > first\n    if has_next:\n        users = users[:first]\n\n    edges = [\n        {\n            \"node\": user,\n            \"cursor\": encode_cursor(offset + i)\n        }\n        for i, user in enumerate(users)\n    ]\n\n    return {\n        \"edges\": edges,\n        \"pageInfo\": {\n            \"hasNextPage\": has_next,\n            \"hasPreviousPage\": offset > 0,\n            \"startCursor\": edges[0][\"cursor\"] if edges else None,\n            \"endCursor\": edges[-1][\"cursor\"] if edges else None\n        },\n        \"totalCount\": await count_users(search=search)\n    }\n\n@user_type.field(\"orders\")\nasync def resolve_user_orders(user: dict, info, first: int = 20) -> dict:\n    \"\"\"Resolve user's orders (N+1 prevention with DataLoader).\"\"\"\n    # Use DataLoader to batch requests\n    loader = info.context[\"loaders\"][\"orders_by_user\"]\n    orders = await loader.load(user[\"id\"])\n\n    return paginate_orders(orders, first)\n\n@mutation.field(\"createUser\")\nasync def resolve_create_user(obj, info, input: dict) -> dict:\n    \"\"\"Create new user.\"\"\"\n    try:\n        # Validate input\n        validate_user_input(input)\n\n        # Create user\n        user = await create_user(\n            email=input[\"email\"],\n            name=input[\"name\"],\n            password=hash_password(input[\"password\"])\n        )\n\n        return {\n            \"user\": user,\n            \"errors\": []\n        }\n    except ValidationError as e:\n        return {\n            \"user\": None,\n            \"errors\": [{\"field\": e.field, \"message\": e.message}]\n        }\n```\n\n### Pattern 3: DataLoader (N+1 Problem Prevention)\n\n```python\nfrom aiodataloader import DataLoader\nfrom typing import List, Optional\n\nclass UserLoader(DataLoader):\n    \"\"\"Batch load users by ID.\"\"\"\n\n    async def batch_load_fn(self, user_ids: List[str]) -> List[Optional[dict]]:\n        \"\"\"Load multiple users in single query.\"\"\"\n        users = await fetch_users_by_ids(user_ids)\n\n        # Map results back to input order\n        user_map = {user[\"id\"]: user for user in users}\n        return [user_map.get(user_id) for user_id in user_ids]\n\nclass OrdersByUserLoader(DataLoader):\n    \"\"\"Batch load orders by user ID.\"\"\"\n\n    async def batch_load_fn(self, user_ids: List[str]) -> List[List[dict]]:\n        \"\"\"Load orders for multiple users in single query.\"\"\"\n        orders = await fetch_orders_by_user_ids(user_ids)\n\n        # Group orders by user_id\n        orders_by_user = {}\n        for order in orders:\n            user_id = order[\"user_id\"]\n            if user_id not in orders_by_user:\n                orders_by_user[user_id] = []\n            orders_by_user[user_id].append(order)\n\n        # Return in input order\n        return [orders_by_user.get(user_id, []) for user_id in user_ids]\n\n# Context setup\ndef create_context():\n    return {\n        \"loaders\": {\n            \"user\": UserLoader(),\n            \"orders_by_user\": OrdersByUserLoader()\n        }\n    }\n```\n\n## Best Practices\n\n### REST APIs\n1. **Consistent Naming**: Use plural nouns for collections (`/users`, not `/user`)\n2. **Stateless**: Each request contains all necessary information\n3. **Use HTTP Status Codes Correctly**: 2xx success, 4xx client errors, 5xx server errors\n4. **Version Your API**: Plan for breaking changes from day one\n5. **Pagination**: Always paginate large collections\n6. **Rate Limiting**: Protect your API with rate limits\n7. **Documentation**: Use OpenAPI/Swagger for interactive docs\n\n### GraphQL APIs\n1. **Schema First**: Design schema before writing resolvers\n2. **Avoid N+1**: Use DataLoaders for efficient data fetching\n3. **Input Validation**: Validate at schema and resolver levels\n4. **Error Handling**: Return structured errors in mutation payloads\n5. **Pagination**: Use cursor-based pagination (Relay spec)\n6. **Deprecation**: Use `@deprecated` directive for gradual migration\n7. **Monitoring**: Track query complexity and execution time\n\n## Common Pitfalls\n\n- **Over-fetching/Under-fetching (REST)**: Fixed in GraphQL but requires DataLoaders\n- **Breaking Changes**: Version APIs or use deprecation strategies\n- **Inconsistent Error Formats**: Standardize error responses\n- **Missing Rate Limits**: APIs without limits are vulnerable to abuse\n- **Poor Documentation**: Undocumented APIs frustrate developers\n- **Ignoring HTTP Semantics**: POST for idempotent operations breaks expectations\n- **Tight Coupling**: API structure shouldn't mirror database schema\n\n## Resources\n\n- **references/rest-best-practices.md**: Comprehensive REST API design guide\n- **references/graphql-schema-design.md**: GraphQL schema patterns and anti-patterns\n- **references/api-versioning-strategies.md**: Versioning approaches and migration paths\n- **assets/rest-api-template.py**: FastAPI REST API template\n- **assets/graphql-schema-template.graphql**: Complete GraphQL schema example\n- **assets/api-design-checklist.md**: Pre-implementation review checklist\n- **scripts/openapi-generator.py**: Generate OpenAPI specs from code\n",
      "references": {
        "rest-best-practices.md": "# REST API Best Practices\n\n## URL Structure\n\n### Resource Naming\n```\n# Good - Plural nouns\nGET /api/users\nGET /api/orders\nGET /api/products\n\n# Bad - Verbs or mixed conventions\nGET /api/getUser\nGET /api/user  (inconsistent singular)\nPOST /api/createOrder\n```\n\n### Nested Resources\n```\n# Shallow nesting (preferred)\nGET /api/users/{id}/orders\nGET /api/orders/{id}\n\n# Deep nesting (avoid)\nGET /api/users/{id}/orders/{orderId}/items/{itemId}/reviews\n# Better:\nGET /api/order-items/{id}/reviews\n```\n\n## HTTP Methods and Status Codes\n\n### GET - Retrieve Resources\n```\nGET /api/users              \u2192 200 OK (with list)\nGET /api/users/{id}         \u2192 200 OK or 404 Not Found\nGET /api/users?page=2       \u2192 200 OK (paginated)\n```\n\n### POST - Create Resources\n```\nPOST /api/users\n  Body: {\"name\": \"John\", \"email\": \"john@example.com\"}\n  \u2192 201 Created\n  Location: /api/users/123\n  Body: {\"id\": \"123\", \"name\": \"John\", ...}\n\nPOST /api/users (validation error)\n  \u2192 422 Unprocessable Entity\n  Body: {\"errors\": [...]}\n```\n\n### PUT - Replace Resources\n```\nPUT /api/users/{id}\n  Body: {complete user object}\n  \u2192 200 OK (updated)\n  \u2192 404 Not Found (doesn't exist)\n\n# Must include ALL fields\n```\n\n### PATCH - Partial Update\n```\nPATCH /api/users/{id}\n  Body: {\"name\": \"Jane\"}  (only changed fields)\n  \u2192 200 OK\n  \u2192 404 Not Found\n```\n\n### DELETE - Remove Resources\n```\nDELETE /api/users/{id}\n  \u2192 204 No Content (deleted)\n  \u2192 404 Not Found\n  \u2192 409 Conflict (can't delete due to references)\n```\n\n## Filtering, Sorting, and Searching\n\n### Query Parameters\n```\n# Filtering\nGET /api/users?status=active\nGET /api/users?role=admin&status=active\n\n# Sorting\nGET /api/users?sort=created_at\nGET /api/users?sort=-created_at  (descending)\nGET /api/users?sort=name,created_at\n\n# Searching\nGET /api/users?search=john\nGET /api/users?q=john\n\n# Field selection (sparse fieldsets)\nGET /api/users?fields=id,name,email\n```\n\n## Pagination Patterns\n\n### Offset-Based Pagination\n```python\nGET /api/users?page=2&page_size=20\n\nResponse:\n{\n  \"items\": [...],\n  \"page\": 2,\n  \"page_size\": 20,\n  \"total\": 150,\n  \"pages\": 8\n}\n```\n\n### Cursor-Based Pagination (for large datasets)\n```python\nGET /api/users?limit=20&cursor=eyJpZCI6MTIzfQ\n\nResponse:\n{\n  \"items\": [...],\n  \"next_cursor\": \"eyJpZCI6MTQzfQ\",\n  \"has_more\": true\n}\n```\n\n### Link Header Pagination (RESTful)\n```\nGET /api/users?page=2\n\nResponse Headers:\nLink: <https://api.example.com/users?page=3>; rel=\"next\",\n      <https://api.example.com/users?page=1>; rel=\"prev\",\n      <https://api.example.com/users?page=1>; rel=\"first\",\n      <https://api.example.com/users?page=8>; rel=\"last\"\n```\n\n## Versioning Strategies\n\n### URL Versioning (Recommended)\n```\n/api/v1/users\n/api/v2/users\n\nPros: Clear, easy to route\nCons: Multiple URLs for same resource\n```\n\n### Header Versioning\n```\nGET /api/users\nAccept: application/vnd.api+json; version=2\n\nPros: Clean URLs\nCons: Less visible, harder to test\n```\n\n### Query Parameter\n```\nGET /api/users?version=2\n\nPros: Easy to test\nCons: Optional parameter can be forgotten\n```\n\n## Rate Limiting\n\n### Headers\n```\nX-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 742\nX-RateLimit-Reset: 1640000000\n\nResponse when limited:\n429 Too Many Requests\nRetry-After: 3600\n```\n\n### Implementation Pattern\n```python\nfrom fastapi import HTTPException, Request\nfrom datetime import datetime, timedelta\n\nclass RateLimiter:\n    def __init__(self, calls: int, period: int):\n        self.calls = calls\n        self.period = period\n        self.cache = {}\n\n    def check(self, key: str) -> bool:\n        now = datetime.now()\n        if key not in self.cache:\n            self.cache[key] = []\n\n        # Remove old requests\n        self.cache[key] = [\n            ts for ts in self.cache[key]\n            if now - ts < timedelta(seconds=self.period)\n        ]\n\n        if len(self.cache[key]) >= self.calls:\n            return False\n\n        self.cache[key].append(now)\n        return True\n\nlimiter = RateLimiter(calls=100, period=60)\n\n@app.get(\"/api/users\")\nasync def get_users(request: Request):\n    if not limiter.check(request.client.host):\n        raise HTTPException(\n            status_code=429,\n            headers={\"Retry-After\": \"60\"}\n        )\n    return {\"users\": [...]}\n```\n\n## Authentication and Authorization\n\n### Bearer Token\n```\nAuthorization: Bearer eyJhbGciOiJIUzI1NiIs...\n\n401 Unauthorized - Missing/invalid token\n403 Forbidden - Valid token, insufficient permissions\n```\n\n### API Keys\n```\nX-API-Key: your-api-key-here\n```\n\n## Error Response Format\n\n### Consistent Structure\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Request validation failed\",\n    \"details\": [\n      {\n        \"field\": \"email\",\n        \"message\": \"Invalid email format\",\n        \"value\": \"not-an-email\"\n      }\n    ],\n    \"timestamp\": \"2025-10-16T12:00:00Z\",\n    \"path\": \"/api/users\"\n  }\n}\n```\n\n### Status Code Guidelines\n- `200 OK`: Successful GET, PATCH, PUT\n- `201 Created`: Successful POST\n- `204 No Content`: Successful DELETE\n- `400 Bad Request`: Malformed request\n- `401 Unauthorized`: Authentication required\n- `403 Forbidden`: Authenticated but not authorized\n- `404 Not Found`: Resource doesn't exist\n- `409 Conflict`: State conflict (duplicate email, etc.)\n- `422 Unprocessable Entity`: Validation errors\n- `429 Too Many Requests`: Rate limited\n- `500 Internal Server Error`: Server error\n- `503 Service Unavailable`: Temporary downtime\n\n## Caching\n\n### Cache Headers\n```\n# Client caching\nCache-Control: public, max-age=3600\n\n# No caching\nCache-Control: no-cache, no-store, must-revalidate\n\n# Conditional requests\nETag: \"33a64df551425fcc55e4d42a148795d9f25f89d4\"\nIf-None-Match: \"33a64df551425fcc55e4d42a148795d9f25f89d4\"\n\u2192 304 Not Modified\n```\n\n## Bulk Operations\n\n### Batch Endpoints\n```python\nPOST /api/users/batch\n{\n  \"items\": [\n    {\"name\": \"User1\", \"email\": \"user1@example.com\"},\n    {\"name\": \"User2\", \"email\": \"user2@example.com\"}\n  ]\n}\n\nResponse:\n{\n  \"results\": [\n    {\"id\": \"1\", \"status\": \"created\"},\n    {\"id\": null, \"status\": \"failed\", \"error\": \"Email already exists\"}\n  ]\n}\n```\n\n## Idempotency\n\n### Idempotency Keys\n```\nPOST /api/orders\nIdempotency-Key: unique-key-123\n\nIf duplicate request:\n\u2192 200 OK (return cached response)\n```\n\n## CORS Configuration\n\n```python\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"https://example.com\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n```\n\n## Documentation with OpenAPI\n\n```python\nfrom fastapi import FastAPI\n\napp = FastAPI(\n    title=\"My API\",\n    description=\"API for managing users\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\n@app.get(\n    \"/api/users/{user_id}\",\n    summary=\"Get user by ID\",\n    response_description=\"User details\",\n    tags=[\"Users\"]\n)\nasync def get_user(\n    user_id: str = Path(..., description=\"The user ID\")\n):\n    \"\"\"\n    Retrieve user by ID.\n\n    Returns full user profile including:\n    - Basic information\n    - Contact details\n    - Account status\n    \"\"\"\n    pass\n```\n\n## Health and Monitoring Endpoints\n\n```python\n@app.get(\"/health\")\nasync def health_check():\n    return {\n        \"status\": \"healthy\",\n        \"version\": \"1.0.0\",\n        \"timestamp\": datetime.now().isoformat()\n    }\n\n@app.get(\"/health/detailed\")\nasync def detailed_health():\n    return {\n        \"status\": \"healthy\",\n        \"checks\": {\n            \"database\": await check_database(),\n            \"redis\": await check_redis(),\n            \"external_api\": await check_external_api()\n        }\n    }\n```\n",
        "graphql-schema-design.md": "# GraphQL Schema Design Patterns\n\n## Schema Organization\n\n### Modular Schema Structure\n```graphql\n# user.graphql\ntype User {\n  id: ID!\n  email: String!\n  name: String!\n  posts: [Post!]!\n}\n\nextend type Query {\n  user(id: ID!): User\n  users(first: Int, after: String): UserConnection!\n}\n\nextend type Mutation {\n  createUser(input: CreateUserInput!): CreateUserPayload!\n}\n\n# post.graphql\ntype Post {\n  id: ID!\n  title: String!\n  content: String!\n  author: User!\n}\n\nextend type Query {\n  post(id: ID!): Post\n}\n```\n\n## Type Design Patterns\n\n### 1. Non-Null Types\n```graphql\ntype User {\n  id: ID!              # Always required\n  email: String!       # Required\n  phone: String        # Optional (nullable)\n  posts: [Post!]!      # Non-null array of non-null posts\n  tags: [String!]      # Nullable array of non-null strings\n}\n```\n\n### 2. Interfaces for Polymorphism\n```graphql\ninterface Node {\n  id: ID!\n  createdAt: DateTime!\n}\n\ntype User implements Node {\n  id: ID!\n  createdAt: DateTime!\n  email: String!\n}\n\ntype Post implements Node {\n  id: ID!\n  createdAt: DateTime!\n  title: String!\n}\n\ntype Query {\n  node(id: ID!): Node\n}\n```\n\n### 3. Unions for Heterogeneous Results\n```graphql\nunion SearchResult = User | Post | Comment\n\ntype Query {\n  search(query: String!): [SearchResult!]!\n}\n\n# Query example\n{\n  search(query: \"graphql\") {\n    ... on User {\n      name\n      email\n    }\n    ... on Post {\n      title\n      content\n    }\n    ... on Comment {\n      text\n      author { name }\n    }\n  }\n}\n```\n\n### 4. Input Types\n```graphql\ninput CreateUserInput {\n  email: String!\n  name: String!\n  password: String!\n  profileInput: ProfileInput\n}\n\ninput ProfileInput {\n  bio: String\n  avatar: String\n  website: String\n}\n\ninput UpdateUserInput {\n  id: ID!\n  email: String\n  name: String\n  profileInput: ProfileInput\n}\n```\n\n## Pagination Patterns\n\n### Relay Cursor Pagination (Recommended)\n```graphql\ntype UserConnection {\n  edges: [UserEdge!]!\n  pageInfo: PageInfo!\n  totalCount: Int!\n}\n\ntype UserEdge {\n  node: User!\n  cursor: String!\n}\n\ntype PageInfo {\n  hasNextPage: Boolean!\n  hasPreviousPage: Boolean!\n  startCursor: String\n  endCursor: String\n}\n\ntype Query {\n  users(\n    first: Int\n    after: String\n    last: Int\n    before: String\n  ): UserConnection!\n}\n\n# Usage\n{\n  users(first: 10, after: \"cursor123\") {\n    edges {\n      cursor\n      node {\n        id\n        name\n      }\n    }\n    pageInfo {\n      hasNextPage\n      endCursor\n    }\n  }\n}\n```\n\n### Offset Pagination (Simpler)\n```graphql\ntype UserList {\n  items: [User!]!\n  total: Int!\n  page: Int!\n  pageSize: Int!\n}\n\ntype Query {\n  users(page: Int = 1, pageSize: Int = 20): UserList!\n}\n```\n\n## Mutation Design Patterns\n\n### 1. Input/Payload Pattern\n```graphql\ninput CreatePostInput {\n  title: String!\n  content: String!\n  tags: [String!]\n}\n\ntype CreatePostPayload {\n  post: Post\n  errors: [Error!]\n  success: Boolean!\n}\n\ntype Error {\n  field: String\n  message: String!\n  code: String!\n}\n\ntype Mutation {\n  createPost(input: CreatePostInput!): CreatePostPayload!\n}\n```\n\n### 2. Optimistic Response Support\n```graphql\ntype UpdateUserPayload {\n  user: User\n  clientMutationId: String\n  errors: [Error!]\n}\n\ninput UpdateUserInput {\n  id: ID!\n  name: String\n  clientMutationId: String\n}\n\ntype Mutation {\n  updateUser(input: UpdateUserInput!): UpdateUserPayload!\n}\n```\n\n### 3. Batch Mutations\n```graphql\ninput BatchCreateUserInput {\n  users: [CreateUserInput!]!\n}\n\ntype BatchCreateUserPayload {\n  results: [CreateUserResult!]!\n  successCount: Int!\n  errorCount: Int!\n}\n\ntype CreateUserResult {\n  user: User\n  errors: [Error!]\n  index: Int!\n}\n\ntype Mutation {\n  batchCreateUsers(input: BatchCreateUserInput!): BatchCreateUserPayload!\n}\n```\n\n## Field Design\n\n### Arguments and Filtering\n```graphql\ntype Query {\n  posts(\n    # Pagination\n    first: Int = 20\n    after: String\n\n    # Filtering\n    status: PostStatus\n    authorId: ID\n    tag: String\n\n    # Sorting\n    orderBy: PostOrderBy = CREATED_AT\n    orderDirection: OrderDirection = DESC\n\n    # Searching\n    search: String\n  ): PostConnection!\n}\n\nenum PostStatus {\n  DRAFT\n  PUBLISHED\n  ARCHIVED\n}\n\nenum PostOrderBy {\n  CREATED_AT\n  UPDATED_AT\n  TITLE\n}\n\nenum OrderDirection {\n  ASC\n  DESC\n}\n```\n\n### Computed Fields\n```graphql\ntype User {\n  firstName: String!\n  lastName: String!\n  fullName: String!  # Computed in resolver\n\n  posts: [Post!]!\n  postCount: Int!    # Computed, doesn't load all posts\n}\n\ntype Post {\n  likeCount: Int!\n  commentCount: Int!\n  isLikedByViewer: Boolean!  # Context-dependent\n}\n```\n\n## Subscriptions\n\n```graphql\ntype Subscription {\n  postAdded: Post!\n\n  postUpdated(postId: ID!): Post!\n\n  userStatusChanged(userId: ID!): UserStatus!\n}\n\ntype UserStatus {\n  userId: ID!\n  online: Boolean!\n  lastSeen: DateTime!\n}\n\n# Client usage\nsubscription {\n  postAdded {\n    id\n    title\n    author {\n      name\n    }\n  }\n}\n```\n\n## Custom Scalars\n\n```graphql\nscalar DateTime\nscalar Email\nscalar URL\nscalar JSON\nscalar Money\n\ntype User {\n  email: Email!\n  website: URL\n  createdAt: DateTime!\n  metadata: JSON\n}\n\ntype Product {\n  price: Money!\n}\n```\n\n## Directives\n\n### Built-in Directives\n```graphql\ntype User {\n  name: String!\n  email: String! @deprecated(reason: \"Use emails field instead\")\n  emails: [String!]!\n\n  # Conditional inclusion\n  privateData: PrivateData @include(if: $isOwner)\n}\n\n# Query\nquery GetUser($isOwner: Boolean!) {\n  user(id: \"123\") {\n    name\n    privateData @include(if: $isOwner) {\n      ssn\n    }\n  }\n}\n```\n\n### Custom Directives\n```graphql\ndirective @auth(requires: Role = USER) on FIELD_DEFINITION\n\nenum Role {\n  USER\n  ADMIN\n  MODERATOR\n}\n\ntype Mutation {\n  deleteUser(id: ID!): Boolean! @auth(requires: ADMIN)\n  updateProfile(input: ProfileInput!): User! @auth\n}\n```\n\n## Error Handling\n\n### Union Error Pattern\n```graphql\ntype User {\n  id: ID!\n  email: String!\n}\n\ntype ValidationError {\n  field: String!\n  message: String!\n}\n\ntype NotFoundError {\n  message: String!\n  resourceType: String!\n  resourceId: ID!\n}\n\ntype AuthorizationError {\n  message: String!\n}\n\nunion UserResult = User | ValidationError | NotFoundError | AuthorizationError\n\ntype Query {\n  user(id: ID!): UserResult!\n}\n\n# Usage\n{\n  user(id: \"123\") {\n    ... on User {\n      id\n      email\n    }\n    ... on NotFoundError {\n      message\n      resourceType\n    }\n    ... on AuthorizationError {\n      message\n    }\n  }\n}\n```\n\n### Errors in Payload\n```graphql\ntype CreateUserPayload {\n  user: User\n  errors: [Error!]\n  success: Boolean!\n}\n\ntype Error {\n  field: String\n  message: String!\n  code: ErrorCode!\n}\n\nenum ErrorCode {\n  VALIDATION_ERROR\n  UNAUTHORIZED\n  NOT_FOUND\n  INTERNAL_ERROR\n}\n```\n\n## N+1 Query Problem Solutions\n\n### DataLoader Pattern\n```python\nfrom aiodataloader import DataLoader\n\nclass PostLoader(DataLoader):\n    async def batch_load_fn(self, post_ids):\n        posts = await db.posts.find({\"id\": {\"$in\": post_ids}})\n        post_map = {post[\"id\"]: post for post in posts}\n        return [post_map.get(pid) for pid in post_ids]\n\n# Resolver\n@user_type.field(\"posts\")\nasync def resolve_posts(user, info):\n    loader = info.context[\"loaders\"][\"post\"]\n    return await loader.load_many(user[\"post_ids\"])\n```\n\n### Query Depth Limiting\n```python\nfrom graphql import GraphQLError\n\ndef depth_limit_validator(max_depth: int):\n    def validate(context, node, ancestors):\n        depth = len(ancestors)\n        if depth > max_depth:\n            raise GraphQLError(\n                f\"Query depth {depth} exceeds maximum {max_depth}\"\n            )\n    return validate\n```\n\n### Query Complexity Analysis\n```python\ndef complexity_limit_validator(max_complexity: int):\n    def calculate_complexity(node):\n        # Each field = 1, lists multiply\n        complexity = 1\n        if is_list_field(node):\n            complexity *= get_list_size_arg(node)\n        return complexity\n\n    return validate_complexity\n```\n\n## Schema Versioning\n\n### Field Deprecation\n```graphql\ntype User {\n  name: String! @deprecated(reason: \"Use firstName and lastName\")\n  firstName: String!\n  lastName: String!\n}\n```\n\n### Schema Evolution\n```graphql\n# v1 - Initial\ntype User {\n  name: String!\n}\n\n# v2 - Add optional field (backward compatible)\ntype User {\n  name: String!\n  email: String\n}\n\n# v3 - Deprecate and add new field\ntype User {\n  name: String! @deprecated(reason: \"Use firstName/lastName\")\n  firstName: String!\n  lastName: String!\n  email: String\n}\n```\n\n## Best Practices Summary\n\n1. **Nullable vs Non-Null**: Start nullable, make non-null when guaranteed\n2. **Input Types**: Always use input types for mutations\n3. **Payload Pattern**: Return errors in mutation payloads\n4. **Pagination**: Use cursor-based for infinite scroll, offset for simple cases\n5. **Naming**: Use camelCase for fields, PascalCase for types\n6. **Deprecation**: Use `@deprecated` instead of removing fields\n7. **DataLoaders**: Always use for relationships to prevent N+1\n8. **Complexity Limits**: Protect against expensive queries\n9. **Custom Scalars**: Use for domain-specific types (Email, DateTime)\n10. **Documentation**: Document all fields with descriptions\n"
      },
      "assets": {
        "api-design-checklist.md": "# API Design Checklist\n\n## Pre-Implementation Review\n\n### Resource Design\n- [ ] Resources are nouns, not verbs\n- [ ] Plural names for collections\n- [ ] Consistent naming across all endpoints\n- [ ] Clear resource hierarchy (avoid deep nesting >2 levels)\n- [ ] All CRUD operations properly mapped to HTTP methods\n\n### HTTP Methods\n- [ ] GET for retrieval (safe, idempotent)\n- [ ] POST for creation\n- [ ] PUT for full replacement (idempotent)\n- [ ] PATCH for partial updates\n- [ ] DELETE for removal (idempotent)\n\n### Status Codes\n- [ ] 200 OK for successful GET/PATCH/PUT\n- [ ] 201 Created for POST\n- [ ] 204 No Content for DELETE\n- [ ] 400 Bad Request for malformed requests\n- [ ] 401 Unauthorized for missing auth\n- [ ] 403 Forbidden for insufficient permissions\n- [ ] 404 Not Found for missing resources\n- [ ] 422 Unprocessable Entity for validation errors\n- [ ] 429 Too Many Requests for rate limiting\n- [ ] 500 Internal Server Error for server issues\n\n### Pagination\n- [ ] All collection endpoints paginated\n- [ ] Default page size defined (e.g., 20)\n- [ ] Maximum page size enforced (e.g., 100)\n- [ ] Pagination metadata included (total, pages, etc.)\n- [ ] Cursor-based or offset-based pattern chosen\n\n### Filtering & Sorting\n- [ ] Query parameters for filtering\n- [ ] Sort parameter supported\n- [ ] Search parameter for full-text search\n- [ ] Field selection supported (sparse fieldsets)\n\n### Versioning\n- [ ] Versioning strategy defined (URL/header/query)\n- [ ] Version included in all endpoints\n- [ ] Deprecation policy documented\n\n### Error Handling\n- [ ] Consistent error response format\n- [ ] Detailed error messages\n- [ ] Field-level validation errors\n- [ ] Error codes for client handling\n- [ ] Timestamps in error responses\n\n### Authentication & Authorization\n- [ ] Authentication method defined (Bearer token, API key)\n- [ ] Authorization checks on all endpoints\n- [ ] 401 vs 403 used correctly\n- [ ] Token expiration handled\n\n### Rate Limiting\n- [ ] Rate limits defined per endpoint/user\n- [ ] Rate limit headers included\n- [ ] 429 status code for exceeded limits\n- [ ] Retry-After header provided\n\n### Documentation\n- [ ] OpenAPI/Swagger spec generated\n- [ ] All endpoints documented\n- [ ] Request/response examples provided\n- [ ] Error responses documented\n- [ ] Authentication flow documented\n\n### Testing\n- [ ] Unit tests for business logic\n- [ ] Integration tests for endpoints\n- [ ] Error scenarios tested\n- [ ] Edge cases covered\n- [ ] Performance tests for heavy endpoints\n\n### Security\n- [ ] Input validation on all fields\n- [ ] SQL injection prevention\n- [ ] XSS prevention\n- [ ] CORS configured correctly\n- [ ] HTTPS enforced\n- [ ] Sensitive data not in URLs\n- [ ] No secrets in responses\n\n### Performance\n- [ ] Database queries optimized\n- [ ] N+1 queries prevented\n- [ ] Caching strategy defined\n- [ ] Cache headers set appropriately\n- [ ] Large responses paginated\n\n### Monitoring\n- [ ] Logging implemented\n- [ ] Error tracking configured\n- [ ] Performance metrics collected\n- [ ] Health check endpoint available\n- [ ] Alerts configured for errors\n\n## GraphQL-Specific Checks\n\n### Schema Design\n- [ ] Schema-first approach used\n- [ ] Types properly defined\n- [ ] Non-null vs nullable decided\n- [ ] Interfaces/unions used appropriately\n- [ ] Custom scalars defined\n\n### Queries\n- [ ] Query depth limiting\n- [ ] Query complexity analysis\n- [ ] DataLoaders prevent N+1\n- [ ] Pagination pattern chosen (Relay/offset)\n\n### Mutations\n- [ ] Input types defined\n- [ ] Payload types with errors\n- [ ] Optimistic response support\n- [ ] Idempotency considered\n\n### Performance\n- [ ] DataLoader for all relationships\n- [ ] Query batching enabled\n- [ ] Persisted queries considered\n- [ ] Response caching implemented\n\n### Documentation\n- [ ] All fields documented\n- [ ] Deprecations marked\n- [ ] Examples provided\n- [ ] Schema introspection enabled\n"
      }
    },
    {
      "name": "architecture-patterns",
      "description": "Implement proven backend architecture patterns including Clean Architecture, Hexagonal Architecture, and Domain-Driven Design. Use when architecting complex backend systems or refactoring existing applications for better maintainability.",
      "plugin": "backend-development",
      "source_path": "plugins/backend-development/skills/architecture-patterns/SKILL.md",
      "category": "development",
      "keywords": [
        "backend",
        "api-design",
        "graphql",
        "tdd",
        "architecture"
      ],
      "content": "---\nname: architecture-patterns\ndescription: Implement proven backend architecture patterns including Clean Architecture, Hexagonal Architecture, and Domain-Driven Design. Use when architecting complex backend systems or refactoring existing applications for better maintainability.\n---\n\n# Architecture Patterns\n\nMaster proven backend architecture patterns including Clean Architecture, Hexagonal Architecture, and Domain-Driven Design to build maintainable, testable, and scalable systems.\n\n## When to Use This Skill\n\n- Designing new backend systems from scratch\n- Refactoring monolithic applications for better maintainability\n- Establishing architecture standards for your team\n- Migrating from tightly coupled to loosely coupled architectures\n- Implementing domain-driven design principles\n- Creating testable and mockable codebases\n- Planning microservices decomposition\n\n## Core Concepts\n\n### 1. Clean Architecture (Uncle Bob)\n\n**Layers (dependency flows inward):**\n- **Entities**: Core business models\n- **Use Cases**: Application business rules\n- **Interface Adapters**: Controllers, presenters, gateways\n- **Frameworks & Drivers**: UI, database, external services\n\n**Key Principles:**\n- Dependencies point inward\n- Inner layers know nothing about outer layers\n- Business logic independent of frameworks\n- Testable without UI, database, or external services\n\n### 2. Hexagonal Architecture (Ports and Adapters)\n\n**Components:**\n- **Domain Core**: Business logic\n- **Ports**: Interfaces defining interactions\n- **Adapters**: Implementations of ports (database, REST, message queue)\n\n**Benefits:**\n- Swap implementations easily (mock for testing)\n- Technology-agnostic core\n- Clear separation of concerns\n\n### 3. Domain-Driven Design (DDD)\n\n**Strategic Patterns:**\n- **Bounded Contexts**: Separate models for different domains\n- **Context Mapping**: How contexts relate\n- **Ubiquitous Language**: Shared terminology\n\n**Tactical Patterns:**\n- **Entities**: Objects with identity\n- **Value Objects**: Immutable objects defined by attributes\n- **Aggregates**: Consistency boundaries\n- **Repositories**: Data access abstraction\n- **Domain Events**: Things that happened\n\n## Clean Architecture Pattern\n\n### Directory Structure\n```\napp/\n\u251c\u2500\u2500 domain/           # Entities & business rules\n\u2502   \u251c\u2500\u2500 entities/\n\u2502   \u2502   \u251c\u2500\u2500 user.py\n\u2502   \u2502   \u2514\u2500\u2500 order.py\n\u2502   \u251c\u2500\u2500 value_objects/\n\u2502   \u2502   \u251c\u2500\u2500 email.py\n\u2502   \u2502   \u2514\u2500\u2500 money.py\n\u2502   \u2514\u2500\u2500 interfaces/   # Abstract interfaces\n\u2502       \u251c\u2500\u2500 user_repository.py\n\u2502       \u2514\u2500\u2500 payment_gateway.py\n\u251c\u2500\u2500 use_cases/        # Application business rules\n\u2502   \u251c\u2500\u2500 create_user.py\n\u2502   \u251c\u2500\u2500 process_order.py\n\u2502   \u2514\u2500\u2500 send_notification.py\n\u251c\u2500\u2500 adapters/         # Interface implementations\n\u2502   \u251c\u2500\u2500 repositories/\n\u2502   \u2502   \u251c\u2500\u2500 postgres_user_repository.py\n\u2502   \u2502   \u2514\u2500\u2500 redis_cache_repository.py\n\u2502   \u251c\u2500\u2500 controllers/\n\u2502   \u2502   \u2514\u2500\u2500 user_controller.py\n\u2502   \u2514\u2500\u2500 gateways/\n\u2502       \u251c\u2500\u2500 stripe_payment_gateway.py\n\u2502       \u2514\u2500\u2500 sendgrid_email_gateway.py\n\u2514\u2500\u2500 infrastructure/   # Framework & external concerns\n    \u251c\u2500\u2500 database.py\n    \u251c\u2500\u2500 config.py\n    \u2514\u2500\u2500 logging.py\n```\n\n### Implementation Example\n\n```python\n# domain/entities/user.py\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Optional\n\n@dataclass\nclass User:\n    \"\"\"Core user entity - no framework dependencies.\"\"\"\n    id: str\n    email: str\n    name: str\n    created_at: datetime\n    is_active: bool = True\n\n    def deactivate(self):\n        \"\"\"Business rule: deactivating user.\"\"\"\n        self.is_active = False\n\n    def can_place_order(self) -> bool:\n        \"\"\"Business rule: active users can order.\"\"\"\n        return self.is_active\n\n# domain/interfaces/user_repository.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, List\nfrom domain.entities.user import User\n\nclass IUserRepository(ABC):\n    \"\"\"Port: defines contract, no implementation.\"\"\"\n\n    @abstractmethod\n    async def find_by_id(self, user_id: str) -> Optional[User]:\n        pass\n\n    @abstractmethod\n    async def find_by_email(self, email: str) -> Optional[User]:\n        pass\n\n    @abstractmethod\n    async def save(self, user: User) -> User:\n        pass\n\n    @abstractmethod\n    async def delete(self, user_id: str) -> bool:\n        pass\n\n# use_cases/create_user.py\nfrom domain.entities.user import User\nfrom domain.interfaces.user_repository import IUserRepository\nfrom dataclasses import dataclass\nfrom datetime import datetime\nimport uuid\n\n@dataclass\nclass CreateUserRequest:\n    email: str\n    name: str\n\n@dataclass\nclass CreateUserResponse:\n    user: User\n    success: bool\n    error: Optional[str] = None\n\nclass CreateUserUseCase:\n    \"\"\"Use case: orchestrates business logic.\"\"\"\n\n    def __init__(self, user_repository: IUserRepository):\n        self.user_repository = user_repository\n\n    async def execute(self, request: CreateUserRequest) -> CreateUserResponse:\n        # Business validation\n        existing = await self.user_repository.find_by_email(request.email)\n        if existing:\n            return CreateUserResponse(\n                user=None,\n                success=False,\n                error=\"Email already exists\"\n            )\n\n        # Create entity\n        user = User(\n            id=str(uuid.uuid4()),\n            email=request.email,\n            name=request.name,\n            created_at=datetime.now(),\n            is_active=True\n        )\n\n        # Persist\n        saved_user = await self.user_repository.save(user)\n\n        return CreateUserResponse(\n            user=saved_user,\n            success=True\n        )\n\n# adapters/repositories/postgres_user_repository.py\nfrom domain.interfaces.user_repository import IUserRepository\nfrom domain.entities.user import User\nfrom typing import Optional\nimport asyncpg\n\nclass PostgresUserRepository(IUserRepository):\n    \"\"\"Adapter: PostgreSQL implementation.\"\"\"\n\n    def __init__(self, pool: asyncpg.Pool):\n        self.pool = pool\n\n    async def find_by_id(self, user_id: str) -> Optional[User]:\n        async with self.pool.acquire() as conn:\n            row = await conn.fetchrow(\n                \"SELECT * FROM users WHERE id = $1\", user_id\n            )\n            return self._to_entity(row) if row else None\n\n    async def find_by_email(self, email: str) -> Optional[User]:\n        async with self.pool.acquire() as conn:\n            row = await conn.fetchrow(\n                \"SELECT * FROM users WHERE email = $1\", email\n            )\n            return self._to_entity(row) if row else None\n\n    async def save(self, user: User) -> User:\n        async with self.pool.acquire() as conn:\n            await conn.execute(\n                \"\"\"\n                INSERT INTO users (id, email, name, created_at, is_active)\n                VALUES ($1, $2, $3, $4, $5)\n                ON CONFLICT (id) DO UPDATE\n                SET email = $2, name = $3, is_active = $5\n                \"\"\",\n                user.id, user.email, user.name, user.created_at, user.is_active\n            )\n            return user\n\n    async def delete(self, user_id: str) -> bool:\n        async with self.pool.acquire() as conn:\n            result = await conn.execute(\n                \"DELETE FROM users WHERE id = $1\", user_id\n            )\n            return result == \"DELETE 1\"\n\n    def _to_entity(self, row) -> User:\n        \"\"\"Map database row to entity.\"\"\"\n        return User(\n            id=row[\"id\"],\n            email=row[\"email\"],\n            name=row[\"name\"],\n            created_at=row[\"created_at\"],\n            is_active=row[\"is_active\"]\n        )\n\n# adapters/controllers/user_controller.py\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom use_cases.create_user import CreateUserUseCase, CreateUserRequest\nfrom pydantic import BaseModel\n\nrouter = APIRouter()\n\nclass CreateUserDTO(BaseModel):\n    email: str\n    name: str\n\n@router.post(\"/users\")\nasync def create_user(\n    dto: CreateUserDTO,\n    use_case: CreateUserUseCase = Depends(get_create_user_use_case)\n):\n    \"\"\"Controller: handles HTTP concerns only.\"\"\"\n    request = CreateUserRequest(email=dto.email, name=dto.name)\n    response = await use_case.execute(request)\n\n    if not response.success:\n        raise HTTPException(status_code=400, detail=response.error)\n\n    return {\"user\": response.user}\n```\n\n## Hexagonal Architecture Pattern\n\n```python\n# Core domain (hexagon center)\nclass OrderService:\n    \"\"\"Domain service - no infrastructure dependencies.\"\"\"\n\n    def __init__(\n        self,\n        order_repository: OrderRepositoryPort,\n        payment_gateway: PaymentGatewayPort,\n        notification_service: NotificationPort\n    ):\n        self.orders = order_repository\n        self.payments = payment_gateway\n        self.notifications = notification_service\n\n    async def place_order(self, order: Order) -> OrderResult:\n        # Business logic\n        if not order.is_valid():\n            return OrderResult(success=False, error=\"Invalid order\")\n\n        # Use ports (interfaces)\n        payment = await self.payments.charge(\n            amount=order.total,\n            customer=order.customer_id\n        )\n\n        if not payment.success:\n            return OrderResult(success=False, error=\"Payment failed\")\n\n        order.mark_as_paid()\n        saved_order = await self.orders.save(order)\n\n        await self.notifications.send(\n            to=order.customer_email,\n            subject=\"Order confirmed\",\n            body=f\"Order {order.id} confirmed\"\n        )\n\n        return OrderResult(success=True, order=saved_order)\n\n# Ports (interfaces)\nclass OrderRepositoryPort(ABC):\n    @abstractmethod\n    async def save(self, order: Order) -> Order:\n        pass\n\nclass PaymentGatewayPort(ABC):\n    @abstractmethod\n    async def charge(self, amount: Money, customer: str) -> PaymentResult:\n        pass\n\nclass NotificationPort(ABC):\n    @abstractmethod\n    async def send(self, to: str, subject: str, body: str):\n        pass\n\n# Adapters (implementations)\nclass StripePaymentAdapter(PaymentGatewayPort):\n    \"\"\"Primary adapter: connects to Stripe API.\"\"\"\n\n    def __init__(self, api_key: str):\n        self.stripe = stripe\n        self.stripe.api_key = api_key\n\n    async def charge(self, amount: Money, customer: str) -> PaymentResult:\n        try:\n            charge = self.stripe.Charge.create(\n                amount=amount.cents,\n                currency=amount.currency,\n                customer=customer\n            )\n            return PaymentResult(success=True, transaction_id=charge.id)\n        except stripe.error.CardError as e:\n            return PaymentResult(success=False, error=str(e))\n\nclass MockPaymentAdapter(PaymentGatewayPort):\n    \"\"\"Test adapter: no external dependencies.\"\"\"\n\n    async def charge(self, amount: Money, customer: str) -> PaymentResult:\n        return PaymentResult(success=True, transaction_id=\"mock-123\")\n```\n\n## Domain-Driven Design Pattern\n\n```python\n# Value Objects (immutable)\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass(frozen=True)\nclass Email:\n    \"\"\"Value object: validated email.\"\"\"\n    value: str\n\n    def __post_init__(self):\n        if \"@\" not in self.value:\n            raise ValueError(\"Invalid email\")\n\n@dataclass(frozen=True)\nclass Money:\n    \"\"\"Value object: amount with currency.\"\"\"\n    amount: int  # cents\n    currency: str\n\n    def add(self, other: \"Money\") -> \"Money\":\n        if self.currency != other.currency:\n            raise ValueError(\"Currency mismatch\")\n        return Money(self.amount + other.amount, self.currency)\n\n# Entities (with identity)\nclass Order:\n    \"\"\"Entity: has identity, mutable state.\"\"\"\n\n    def __init__(self, id: str, customer: Customer):\n        self.id = id\n        self.customer = customer\n        self.items: List[OrderItem] = []\n        self.status = OrderStatus.PENDING\n        self._events: List[DomainEvent] = []\n\n    def add_item(self, product: Product, quantity: int):\n        \"\"\"Business logic in entity.\"\"\"\n        item = OrderItem(product, quantity)\n        self.items.append(item)\n        self._events.append(ItemAddedEvent(self.id, item))\n\n    def total(self) -> Money:\n        \"\"\"Calculated property.\"\"\"\n        return sum(item.subtotal() for item in self.items)\n\n    def submit(self):\n        \"\"\"State transition with business rules.\"\"\"\n        if not self.items:\n            raise ValueError(\"Cannot submit empty order\")\n        if self.status != OrderStatus.PENDING:\n            raise ValueError(\"Order already submitted\")\n\n        self.status = OrderStatus.SUBMITTED\n        self._events.append(OrderSubmittedEvent(self.id))\n\n# Aggregates (consistency boundary)\nclass Customer:\n    \"\"\"Aggregate root: controls access to entities.\"\"\"\n\n    def __init__(self, id: str, email: Email):\n        self.id = id\n        self.email = email\n        self._addresses: List[Address] = []\n        self._orders: List[str] = []  # Order IDs, not full objects\n\n    def add_address(self, address: Address):\n        \"\"\"Aggregate enforces invariants.\"\"\"\n        if len(self._addresses) >= 5:\n            raise ValueError(\"Maximum 5 addresses allowed\")\n        self._addresses.append(address)\n\n    @property\n    def primary_address(self) -> Optional[Address]:\n        return next((a for a in self._addresses if a.is_primary), None)\n\n# Domain Events\n@dataclass\nclass OrderSubmittedEvent:\n    order_id: str\n    occurred_at: datetime = field(default_factory=datetime.now)\n\n# Repository (aggregate persistence)\nclass OrderRepository:\n    \"\"\"Repository: persist/retrieve aggregates.\"\"\"\n\n    async def find_by_id(self, order_id: str) -> Optional[Order]:\n        \"\"\"Reconstitute aggregate from storage.\"\"\"\n        pass\n\n    async def save(self, order: Order):\n        \"\"\"Persist aggregate and publish events.\"\"\"\n        await self._persist(order)\n        await self._publish_events(order._events)\n        order._events.clear()\n```\n\n## Resources\n\n- **references/clean-architecture-guide.md**: Detailed layer breakdown\n- **references/hexagonal-architecture-guide.md**: Ports and adapters patterns\n- **references/ddd-tactical-patterns.md**: Entities, value objects, aggregates\n- **assets/clean-architecture-template/**: Complete project structure\n- **assets/ddd-examples/**: Domain modeling examples\n\n## Best Practices\n\n1. **Dependency Rule**: Dependencies always point inward\n2. **Interface Segregation**: Small, focused interfaces\n3. **Business Logic in Domain**: Keep frameworks out of core\n4. **Test Independence**: Core testable without infrastructure\n5. **Bounded Contexts**: Clear domain boundaries\n6. **Ubiquitous Language**: Consistent terminology\n7. **Thin Controllers**: Delegate to use cases\n8. **Rich Domain Models**: Behavior with data\n\n## Common Pitfalls\n\n- **Anemic Domain**: Entities with only data, no behavior\n- **Framework Coupling**: Business logic depends on frameworks\n- **Fat Controllers**: Business logic in controllers\n- **Repository Leakage**: Exposing ORM objects\n- **Missing Abstractions**: Concrete dependencies in core\n- **Over-Engineering**: Clean architecture for simple CRUD\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "microservices-patterns",
      "description": "Design microservices architectures with service boundaries, event-driven communication, and resilience patterns. Use when building distributed systems, decomposing monoliths, or implementing microservices.",
      "plugin": "backend-development",
      "source_path": "plugins/backend-development/skills/microservices-patterns/SKILL.md",
      "category": "development",
      "keywords": [
        "backend",
        "api-design",
        "graphql",
        "tdd",
        "architecture"
      ],
      "content": "---\nname: microservices-patterns\ndescription: Design microservices architectures with service boundaries, event-driven communication, and resilience patterns. Use when building distributed systems, decomposing monoliths, or implementing microservices.\n---\n\n# Microservices Patterns\n\nMaster microservices architecture patterns including service boundaries, inter-service communication, data management, and resilience patterns for building distributed systems.\n\n## When to Use This Skill\n\n- Decomposing monoliths into microservices\n- Designing service boundaries and contracts\n- Implementing inter-service communication\n- Managing distributed data and transactions\n- Building resilient distributed systems\n- Implementing service discovery and load balancing\n- Designing event-driven architectures\n\n## Core Concepts\n\n### 1. Service Decomposition Strategies\n\n**By Business Capability**\n- Organize services around business functions\n- Each service owns its domain\n- Example: OrderService, PaymentService, InventoryService\n\n**By Subdomain (DDD)**\n- Core domain, supporting subdomains\n- Bounded contexts map to services\n- Clear ownership and responsibility\n\n**Strangler Fig Pattern**\n- Gradually extract from monolith\n- New functionality as microservices\n- Proxy routes to old/new systems\n\n### 2. Communication Patterns\n\n**Synchronous (Request/Response)**\n- REST APIs\n- gRPC\n- GraphQL\n\n**Asynchronous (Events/Messages)**\n- Event streaming (Kafka)\n- Message queues (RabbitMQ, SQS)\n- Pub/Sub patterns\n\n### 3. Data Management\n\n**Database Per Service**\n- Each service owns its data\n- No shared databases\n- Loose coupling\n\n**Saga Pattern**\n- Distributed transactions\n- Compensating actions\n- Eventual consistency\n\n### 4. Resilience Patterns\n\n**Circuit Breaker**\n- Fail fast on repeated errors\n- Prevent cascade failures\n\n**Retry with Backoff**\n- Transient fault handling\n- Exponential backoff\n\n**Bulkhead**\n- Isolate resources\n- Limit impact of failures\n\n## Service Decomposition Patterns\n\n### Pattern 1: By Business Capability\n\n```python\n# E-commerce example\n\n# Order Service\nclass OrderService:\n    \"\"\"Handles order lifecycle.\"\"\"\n\n    async def create_order(self, order_data: dict) -> Order:\n        order = Order.create(order_data)\n\n        # Publish event for other services\n        await self.event_bus.publish(\n            OrderCreatedEvent(\n                order_id=order.id,\n                customer_id=order.customer_id,\n                items=order.items,\n                total=order.total\n            )\n        )\n\n        return order\n\n# Payment Service (separate service)\nclass PaymentService:\n    \"\"\"Handles payment processing.\"\"\"\n\n    async def process_payment(self, payment_request: PaymentRequest) -> PaymentResult:\n        # Process payment\n        result = await self.payment_gateway.charge(\n            amount=payment_request.amount,\n            customer=payment_request.customer_id\n        )\n\n        if result.success:\n            await self.event_bus.publish(\n                PaymentCompletedEvent(\n                    order_id=payment_request.order_id,\n                    transaction_id=result.transaction_id\n                )\n            )\n\n        return result\n\n# Inventory Service (separate service)\nclass InventoryService:\n    \"\"\"Handles inventory management.\"\"\"\n\n    async def reserve_items(self, order_id: str, items: List[OrderItem]) -> ReservationResult:\n        # Check availability\n        for item in items:\n            available = await self.inventory_repo.get_available(item.product_id)\n            if available < item.quantity:\n                return ReservationResult(\n                    success=False,\n                    error=f\"Insufficient inventory for {item.product_id}\"\n                )\n\n        # Reserve items\n        reservation = await self.create_reservation(order_id, items)\n\n        await self.event_bus.publish(\n            InventoryReservedEvent(\n                order_id=order_id,\n                reservation_id=reservation.id\n            )\n        )\n\n        return ReservationResult(success=True, reservation=reservation)\n```\n\n### Pattern 2: API Gateway\n\n```python\nfrom fastapi import FastAPI, HTTPException, Depends\nimport httpx\nfrom circuitbreaker import circuit\n\napp = FastAPI()\n\nclass APIGateway:\n    \"\"\"Central entry point for all client requests.\"\"\"\n\n    def __init__(self):\n        self.order_service_url = \"http://order-service:8000\"\n        self.payment_service_url = \"http://payment-service:8001\"\n        self.inventory_service_url = \"http://inventory-service:8002\"\n        self.http_client = httpx.AsyncClient(timeout=5.0)\n\n    @circuit(failure_threshold=5, recovery_timeout=30)\n    async def call_order_service(self, path: str, method: str = \"GET\", **kwargs):\n        \"\"\"Call order service with circuit breaker.\"\"\"\n        response = await self.http_client.request(\n            method,\n            f\"{self.order_service_url}{path}\",\n            **kwargs\n        )\n        response.raise_for_status()\n        return response.json()\n\n    async def create_order_aggregate(self, order_id: str) -> dict:\n        \"\"\"Aggregate data from multiple services.\"\"\"\n        # Parallel requests\n        order, payment, inventory = await asyncio.gather(\n            self.call_order_service(f\"/orders/{order_id}\"),\n            self.call_payment_service(f\"/payments/order/{order_id}\"),\n            self.call_inventory_service(f\"/reservations/order/{order_id}\"),\n            return_exceptions=True\n        )\n\n        # Handle partial failures\n        result = {\"order\": order}\n        if not isinstance(payment, Exception):\n            result[\"payment\"] = payment\n        if not isinstance(inventory, Exception):\n            result[\"inventory\"] = inventory\n\n        return result\n\n@app.post(\"/api/orders\")\nasync def create_order(\n    order_data: dict,\n    gateway: APIGateway = Depends()\n):\n    \"\"\"API Gateway endpoint.\"\"\"\n    try:\n        # Route to order service\n        order = await gateway.call_order_service(\n            \"/orders\",\n            method=\"POST\",\n            json=order_data\n        )\n        return {\"order\": order}\n    except httpx.HTTPError as e:\n        raise HTTPException(status_code=503, detail=\"Order service unavailable\")\n```\n\n## Communication Patterns\n\n### Pattern 1: Synchronous REST Communication\n\n```python\n# Service A calls Service B\nimport httpx\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\nclass ServiceClient:\n    \"\"\"HTTP client with retries and timeout.\"\"\"\n\n    def __init__(self, base_url: str):\n        self.base_url = base_url\n        self.client = httpx.AsyncClient(\n            timeout=httpx.Timeout(5.0, connect=2.0),\n            limits=httpx.Limits(max_keepalive_connections=20)\n        )\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=2, max=10)\n    )\n    async def get(self, path: str, **kwargs):\n        \"\"\"GET with automatic retries.\"\"\"\n        response = await self.client.get(f\"{self.base_url}{path}\", **kwargs)\n        response.raise_for_status()\n        return response.json()\n\n    async def post(self, path: str, **kwargs):\n        \"\"\"POST request.\"\"\"\n        response = await self.client.post(f\"{self.base_url}{path}\", **kwargs)\n        response.raise_for_status()\n        return response.json()\n\n# Usage\npayment_client = ServiceClient(\"http://payment-service:8001\")\nresult = await payment_client.post(\"/payments\", json=payment_data)\n```\n\n### Pattern 2: Asynchronous Event-Driven\n\n```python\n# Event-driven communication with Kafka\nfrom aiokafka import AIOKafkaProducer, AIOKafkaConsumer\nimport json\nfrom dataclasses import dataclass, asdict\nfrom datetime import datetime\n\n@dataclass\nclass DomainEvent:\n    event_id: str\n    event_type: str\n    aggregate_id: str\n    occurred_at: datetime\n    data: dict\n\nclass EventBus:\n    \"\"\"Event publishing and subscription.\"\"\"\n\n    def __init__(self, bootstrap_servers: List[str]):\n        self.bootstrap_servers = bootstrap_servers\n        self.producer = None\n\n    async def start(self):\n        self.producer = AIOKafkaProducer(\n            bootstrap_servers=self.bootstrap_servers,\n            value_serializer=lambda v: json.dumps(v).encode()\n        )\n        await self.producer.start()\n\n    async def publish(self, event: DomainEvent):\n        \"\"\"Publish event to Kafka topic.\"\"\"\n        topic = event.event_type\n        await self.producer.send_and_wait(\n            topic,\n            value=asdict(event),\n            key=event.aggregate_id.encode()\n        )\n\n    async def subscribe(self, topic: str, handler: callable):\n        \"\"\"Subscribe to events.\"\"\"\n        consumer = AIOKafkaConsumer(\n            topic,\n            bootstrap_servers=self.bootstrap_servers,\n            value_deserializer=lambda v: json.loads(v.decode()),\n            group_id=\"my-service\"\n        )\n        await consumer.start()\n\n        try:\n            async for message in consumer:\n                event_data = message.value\n                await handler(event_data)\n        finally:\n            await consumer.stop()\n\n# Order Service publishes event\nasync def create_order(order_data: dict):\n    order = await save_order(order_data)\n\n    event = DomainEvent(\n        event_id=str(uuid.uuid4()),\n        event_type=\"OrderCreated\",\n        aggregate_id=order.id,\n        occurred_at=datetime.now(),\n        data={\n            \"order_id\": order.id,\n            \"customer_id\": order.customer_id,\n            \"total\": order.total\n        }\n    )\n\n    await event_bus.publish(event)\n\n# Inventory Service listens for OrderCreated\nasync def handle_order_created(event_data: dict):\n    \"\"\"React to order creation.\"\"\"\n    order_id = event_data[\"data\"][\"order_id\"]\n    items = event_data[\"data\"][\"items\"]\n\n    # Reserve inventory\n    await reserve_inventory(order_id, items)\n```\n\n### Pattern 3: Saga Pattern (Distributed Transactions)\n\n```python\n# Saga orchestration for order fulfillment\nfrom enum import Enum\nfrom typing import List, Callable\n\nclass SagaStep:\n    \"\"\"Single step in saga.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        action: Callable,\n        compensation: Callable\n    ):\n        self.name = name\n        self.action = action\n        self.compensation = compensation\n\nclass SagaStatus(Enum):\n    PENDING = \"pending\"\n    COMPLETED = \"completed\"\n    COMPENSATING = \"compensating\"\n    FAILED = \"failed\"\n\nclass OrderFulfillmentSaga:\n    \"\"\"Orchestrated saga for order fulfillment.\"\"\"\n\n    def __init__(self):\n        self.steps: List[SagaStep] = [\n            SagaStep(\n                \"create_order\",\n                action=self.create_order,\n                compensation=self.cancel_order\n            ),\n            SagaStep(\n                \"reserve_inventory\",\n                action=self.reserve_inventory,\n                compensation=self.release_inventory\n            ),\n            SagaStep(\n                \"process_payment\",\n                action=self.process_payment,\n                compensation=self.refund_payment\n            ),\n            SagaStep(\n                \"confirm_order\",\n                action=self.confirm_order,\n                compensation=self.cancel_order_confirmation\n            )\n        ]\n\n    async def execute(self, order_data: dict) -> SagaResult:\n        \"\"\"Execute saga steps.\"\"\"\n        completed_steps = []\n        context = {\"order_data\": order_data}\n\n        try:\n            for step in self.steps:\n                # Execute step\n                result = await step.action(context)\n                if not result.success:\n                    # Compensate\n                    await self.compensate(completed_steps, context)\n                    return SagaResult(\n                        status=SagaStatus.FAILED,\n                        error=result.error\n                    )\n\n                completed_steps.append(step)\n                context.update(result.data)\n\n            return SagaResult(status=SagaStatus.COMPLETED, data=context)\n\n        except Exception as e:\n            # Compensate on error\n            await self.compensate(completed_steps, context)\n            return SagaResult(status=SagaStatus.FAILED, error=str(e))\n\n    async def compensate(self, completed_steps: List[SagaStep], context: dict):\n        \"\"\"Execute compensating actions in reverse order.\"\"\"\n        for step in reversed(completed_steps):\n            try:\n                await step.compensation(context)\n            except Exception as e:\n                # Log compensation failure\n                print(f\"Compensation failed for {step.name}: {e}\")\n\n    # Step implementations\n    async def create_order(self, context: dict) -> StepResult:\n        order = await order_service.create(context[\"order_data\"])\n        return StepResult(success=True, data={\"order_id\": order.id})\n\n    async def cancel_order(self, context: dict):\n        await order_service.cancel(context[\"order_id\"])\n\n    async def reserve_inventory(self, context: dict) -> StepResult:\n        result = await inventory_service.reserve(\n            context[\"order_id\"],\n            context[\"order_data\"][\"items\"]\n        )\n        return StepResult(\n            success=result.success,\n            data={\"reservation_id\": result.reservation_id}\n        )\n\n    async def release_inventory(self, context: dict):\n        await inventory_service.release(context[\"reservation_id\"])\n\n    async def process_payment(self, context: dict) -> StepResult:\n        result = await payment_service.charge(\n            context[\"order_id\"],\n            context[\"order_data\"][\"total\"]\n        )\n        return StepResult(\n            success=result.success,\n            data={\"transaction_id\": result.transaction_id},\n            error=result.error\n        )\n\n    async def refund_payment(self, context: dict):\n        await payment_service.refund(context[\"transaction_id\"])\n```\n\n## Resilience Patterns\n\n### Circuit Breaker Pattern\n\n```python\nfrom enum import Enum\nfrom datetime import datetime, timedelta\nfrom typing import Callable, Any\n\nclass CircuitState(Enum):\n    CLOSED = \"closed\"  # Normal operation\n    OPEN = \"open\"      # Failing, reject requests\n    HALF_OPEN = \"half_open\"  # Testing if recovered\n\nclass CircuitBreaker:\n    \"\"\"Circuit breaker for service calls.\"\"\"\n\n    def __init__(\n        self,\n        failure_threshold: int = 5,\n        recovery_timeout: int = 30,\n        success_threshold: int = 2\n    ):\n        self.failure_threshold = failure_threshold\n        self.recovery_timeout = recovery_timeout\n        self.success_threshold = success_threshold\n\n        self.failure_count = 0\n        self.success_count = 0\n        self.state = CircuitState.CLOSED\n        self.opened_at = None\n\n    async def call(self, func: Callable, *args, **kwargs) -> Any:\n        \"\"\"Execute function with circuit breaker.\"\"\"\n\n        if self.state == CircuitState.OPEN:\n            if self._should_attempt_reset():\n                self.state = CircuitState.HALF_OPEN\n            else:\n                raise CircuitBreakerOpenError(\"Circuit breaker is open\")\n\n        try:\n            result = await func(*args, **kwargs)\n            self._on_success()\n            return result\n\n        except Exception as e:\n            self._on_failure()\n            raise\n\n    def _on_success(self):\n        \"\"\"Handle successful call.\"\"\"\n        self.failure_count = 0\n\n        if self.state == CircuitState.HALF_OPEN:\n            self.success_count += 1\n            if self.success_count >= self.success_threshold:\n                self.state = CircuitState.CLOSED\n                self.success_count = 0\n\n    def _on_failure(self):\n        \"\"\"Handle failed call.\"\"\"\n        self.failure_count += 1\n\n        if self.failure_count >= self.failure_threshold:\n            self.state = CircuitState.OPEN\n            self.opened_at = datetime.now()\n\n        if self.state == CircuitState.HALF_OPEN:\n            self.state = CircuitState.OPEN\n            self.opened_at = datetime.now()\n\n    def _should_attempt_reset(self) -> bool:\n        \"\"\"Check if enough time passed to try again.\"\"\"\n        return (\n            datetime.now() - self.opened_at\n            > timedelta(seconds=self.recovery_timeout)\n        )\n\n# Usage\nbreaker = CircuitBreaker(failure_threshold=5, recovery_timeout=30)\n\nasync def call_payment_service(payment_data: dict):\n    return await breaker.call(\n        payment_client.process_payment,\n        payment_data\n    )\n```\n\n## Resources\n\n- **references/service-decomposition-guide.md**: Breaking down monoliths\n- **references/communication-patterns.md**: Sync vs async patterns\n- **references/saga-implementation.md**: Distributed transactions\n- **assets/circuit-breaker.py**: Production circuit breaker\n- **assets/event-bus-template.py**: Kafka event bus implementation\n- **assets/api-gateway-template.py**: Complete API gateway\n\n## Best Practices\n\n1. **Service Boundaries**: Align with business capabilities\n2. **Database Per Service**: No shared databases\n3. **API Contracts**: Versioned, backward compatible\n4. **Async When Possible**: Events over direct calls\n5. **Circuit Breakers**: Fail fast on service failures\n6. **Distributed Tracing**: Track requests across services\n7. **Service Registry**: Dynamic service discovery\n8. **Health Checks**: Liveness and readiness probes\n\n## Common Pitfalls\n\n- **Distributed Monolith**: Tightly coupled services\n- **Chatty Services**: Too many inter-service calls\n- **Shared Databases**: Tight coupling through data\n- **No Circuit Breakers**: Cascade failures\n- **Synchronous Everything**: Tight coupling, poor resilience\n- **Premature Microservices**: Starting with microservices\n- **Ignoring Network Failures**: Assuming reliable network\n- **No Compensation Logic**: Can't undo failed transactions\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "git-advanced-workflows",
      "description": "Master advanced Git workflows including rebasing, cherry-picking, bisect, worktrees, and reflog to maintain clean history and recover from any situation. Use when managing complex Git histories, collaborating on feature branches, or troubleshooting repository issues.",
      "plugin": "developer-essentials",
      "source_path": "plugins/developer-essentials/skills/git-advanced-workflows/SKILL.md",
      "category": "development",
      "keywords": [
        "git",
        "sql",
        "debugging",
        "testing",
        "authentication",
        "code-review",
        "monorepo",
        "essential"
      ],
      "content": "---\nname: git-advanced-workflows\ndescription: Master advanced Git workflows including rebasing, cherry-picking, bisect, worktrees, and reflog to maintain clean history and recover from any situation. Use when managing complex Git histories, collaborating on feature branches, or troubleshooting repository issues.\n---\n\n# Git Advanced Workflows\n\nMaster advanced Git techniques to maintain clean history, collaborate effectively, and recover from any situation with confidence.\n\n## When to Use This Skill\n\n- Cleaning up commit history before merging\n- Applying specific commits across branches\n- Finding commits that introduced bugs\n- Working on multiple features simultaneously\n- Recovering from Git mistakes or lost commits\n- Managing complex branch workflows\n- Preparing clean PRs for review\n- Synchronizing diverged branches\n\n## Core Concepts\n\n### 1. Interactive Rebase\n\nInteractive rebase is the Swiss Army knife of Git history editing.\n\n**Common Operations:**\n- `pick`: Keep commit as-is\n- `reword`: Change commit message\n- `edit`: Amend commit content\n- `squash`: Combine with previous commit\n- `fixup`: Like squash but discard message\n- `drop`: Remove commit entirely\n\n**Basic Usage:**\n```bash\n# Rebase last 5 commits\ngit rebase -i HEAD~5\n\n# Rebase all commits on current branch\ngit rebase -i $(git merge-base HEAD main)\n\n# Rebase onto specific commit\ngit rebase -i abc123\n```\n\n### 2. Cherry-Picking\n\nApply specific commits from one branch to another without merging entire branches.\n\n```bash\n# Cherry-pick single commit\ngit cherry-pick abc123\n\n# Cherry-pick range of commits (exclusive start)\ngit cherry-pick abc123..def456\n\n# Cherry-pick without committing (stage changes only)\ngit cherry-pick -n abc123\n\n# Cherry-pick and edit commit message\ngit cherry-pick -e abc123\n```\n\n### 3. Git Bisect\n\nBinary search through commit history to find the commit that introduced a bug.\n\n```bash\n# Start bisect\ngit bisect start\n\n# Mark current commit as bad\ngit bisect bad\n\n# Mark known good commit\ngit bisect good v1.0.0\n\n# Git will checkout middle commit - test it\n# Then mark as good or bad\ngit bisect good  # or: git bisect bad\n\n# Continue until bug found\n# When done\ngit bisect reset\n```\n\n**Automated Bisect:**\n```bash\n# Use script to test automatically\ngit bisect start HEAD v1.0.0\ngit bisect run ./test.sh\n\n# test.sh should exit 0 for good, 1-127 (except 125) for bad\n```\n\n### 4. Worktrees\n\nWork on multiple branches simultaneously without stashing or switching.\n\n```bash\n# List existing worktrees\ngit worktree list\n\n# Add new worktree for feature branch\ngit worktree add ../project-feature feature/new-feature\n\n# Add worktree and create new branch\ngit worktree add -b bugfix/urgent ../project-hotfix main\n\n# Remove worktree\ngit worktree remove ../project-feature\n\n# Prune stale worktrees\ngit worktree prune\n```\n\n### 5. Reflog\n\nYour safety net - tracks all ref movements, even deleted commits.\n\n```bash\n# View reflog\ngit reflog\n\n# View reflog for specific branch\ngit reflog show feature/branch\n\n# Restore deleted commit\ngit reflog\n# Find commit hash\ngit checkout abc123\ngit branch recovered-branch\n\n# Restore deleted branch\ngit reflog\ngit branch deleted-branch abc123\n```\n\n## Practical Workflows\n\n### Workflow 1: Clean Up Feature Branch Before PR\n\n```bash\n# Start with feature branch\ngit checkout feature/user-auth\n\n# Interactive rebase to clean history\ngit rebase -i main\n\n# Example rebase operations:\n# - Squash \"fix typo\" commits\n# - Reword commit messages for clarity\n# - Reorder commits logically\n# - Drop unnecessary commits\n\n# Force push cleaned branch (safe if no one else is using it)\ngit push --force-with-lease origin feature/user-auth\n```\n\n### Workflow 2: Apply Hotfix to Multiple Releases\n\n```bash\n# Create fix on main\ngit checkout main\ngit commit -m \"fix: critical security patch\"\n\n# Apply to release branches\ngit checkout release/2.0\ngit cherry-pick abc123\n\ngit checkout release/1.9\ngit cherry-pick abc123\n\n# Handle conflicts if they arise\ngit cherry-pick --continue\n# or\ngit cherry-pick --abort\n```\n\n### Workflow 3: Find Bug Introduction\n\n```bash\n# Start bisect\ngit bisect start\ngit bisect bad HEAD\ngit bisect good v2.1.0\n\n# Git checks out middle commit - run tests\nnpm test\n\n# If tests fail\ngit bisect bad\n\n# If tests pass\ngit bisect good\n\n# Git will automatically checkout next commit to test\n# Repeat until bug found\n\n# Automated version\ngit bisect start HEAD v2.1.0\ngit bisect run npm test\n```\n\n### Workflow 4: Multi-Branch Development\n\n```bash\n# Main project directory\ncd ~/projects/myapp\n\n# Create worktree for urgent bugfix\ngit worktree add ../myapp-hotfix hotfix/critical-bug\n\n# Work on hotfix in separate directory\ncd ../myapp-hotfix\n# Make changes, commit\ngit commit -m \"fix: resolve critical bug\"\ngit push origin hotfix/critical-bug\n\n# Return to main work without interruption\ncd ~/projects/myapp\ngit fetch origin\ngit cherry-pick hotfix/critical-bug\n\n# Clean up when done\ngit worktree remove ../myapp-hotfix\n```\n\n### Workflow 5: Recover from Mistakes\n\n```bash\n# Accidentally reset to wrong commit\ngit reset --hard HEAD~5  # Oh no!\n\n# Use reflog to find lost commits\ngit reflog\n# Output shows:\n# abc123 HEAD@{0}: reset: moving to HEAD~5\n# def456 HEAD@{1}: commit: my important changes\n\n# Recover lost commits\ngit reset --hard def456\n\n# Or create branch from lost commit\ngit branch recovery def456\n```\n\n## Advanced Techniques\n\n### Rebase vs Merge Strategy\n\n**When to Rebase:**\n- Cleaning up local commits before pushing\n- Keeping feature branch up-to-date with main\n- Creating linear history for easier review\n\n**When to Merge:**\n- Integrating completed features into main\n- Preserving exact history of collaboration\n- Public branches used by others\n\n```bash\n# Update feature branch with main changes (rebase)\ngit checkout feature/my-feature\ngit fetch origin\ngit rebase origin/main\n\n# Handle conflicts\ngit status\n# Fix conflicts in files\ngit add .\ngit rebase --continue\n\n# Or merge instead\ngit merge origin/main\n```\n\n### Autosquash Workflow\n\nAutomatically squash fixup commits during rebase.\n\n```bash\n# Make initial commit\ngit commit -m \"feat: add user authentication\"\n\n# Later, fix something in that commit\n# Stage changes\ngit commit --fixup HEAD  # or specify commit hash\n\n# Make more changes\ngit commit --fixup abc123\n\n# Rebase with autosquash\ngit rebase -i --autosquash main\n\n# Git automatically marks fixup commits\n```\n\n### Split Commit\n\nBreak one commit into multiple logical commits.\n\n```bash\n# Start interactive rebase\ngit rebase -i HEAD~3\n\n# Mark commit to split with 'edit'\n# Git will stop at that commit\n\n# Reset commit but keep changes\ngit reset HEAD^\n\n# Stage and commit in logical chunks\ngit add file1.py\ngit commit -m \"feat: add validation\"\n\ngit add file2.py\ngit commit -m \"feat: add error handling\"\n\n# Continue rebase\ngit rebase --continue\n```\n\n### Partial Cherry-Pick\n\nCherry-pick only specific files from a commit.\n\n```bash\n# Show files in commit\ngit show --name-only abc123\n\n# Checkout specific files from commit\ngit checkout abc123 -- path/to/file1.py path/to/file2.py\n\n# Stage and commit\ngit commit -m \"cherry-pick: apply specific changes from abc123\"\n```\n\n## Best Practices\n\n1. **Always Use --force-with-lease**: Safer than --force, prevents overwriting others' work\n2. **Rebase Only Local Commits**: Don't rebase commits that have been pushed and shared\n3. **Descriptive Commit Messages**: Future you will thank present you\n4. **Atomic Commits**: Each commit should be a single logical change\n5. **Test Before Force Push**: Ensure history rewrite didn't break anything\n6. **Keep Reflog Aware**: Remember reflog is your safety net for 90 days\n7. **Branch Before Risky Operations**: Create backup branch before complex rebases\n\n```bash\n# Safe force push\ngit push --force-with-lease origin feature/branch\n\n# Create backup before risky operation\ngit branch backup-branch\ngit rebase -i main\n# If something goes wrong\ngit reset --hard backup-branch\n```\n\n## Common Pitfalls\n\n- **Rebasing Public Branches**: Causes history conflicts for collaborators\n- **Force Pushing Without Lease**: Can overwrite teammate's work\n- **Losing Work in Rebase**: Resolve conflicts carefully, test after rebase\n- **Forgetting Worktree Cleanup**: Orphaned worktrees consume disk space\n- **Not Backing Up Before Experiment**: Always create safety branch\n- **Bisect on Dirty Working Directory**: Commit or stash before bisecting\n\n## Recovery Commands\n\n```bash\n# Abort operations in progress\ngit rebase --abort\ngit merge --abort\ngit cherry-pick --abort\ngit bisect reset\n\n# Restore file to version from specific commit\ngit restore --source=abc123 path/to/file\n\n# Undo last commit but keep changes\ngit reset --soft HEAD^\n\n# Undo last commit and discard changes\ngit reset --hard HEAD^\n\n# Recover deleted branch (within 90 days)\ngit reflog\ngit branch recovered-branch abc123\n```\n\n## Resources\n\n- **references/git-rebase-guide.md**: Deep dive into interactive rebase\n- **references/git-conflict-resolution.md**: Advanced conflict resolution strategies\n- **references/git-history-rewriting.md**: Safely rewriting Git history\n- **assets/git-workflow-checklist.md**: Pre-PR cleanup checklist\n- **assets/git-aliases.md**: Useful Git aliases for advanced workflows\n- **scripts/git-clean-branches.sh**: Clean up merged and stale branches\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "sql-optimization-patterns",
      "description": "Master SQL query optimization, indexing strategies, and EXPLAIN analysis to dramatically improve database performance and eliminate slow queries. Use when debugging slow queries, designing database schemas, or optimizing application performance.",
      "plugin": "developer-essentials",
      "source_path": "plugins/developer-essentials/skills/sql-optimization-patterns/SKILL.md",
      "category": "development",
      "keywords": [
        "git",
        "sql",
        "debugging",
        "testing",
        "authentication",
        "code-review",
        "monorepo",
        "essential"
      ],
      "content": "---\nname: sql-optimization-patterns\ndescription: Master SQL query optimization, indexing strategies, and EXPLAIN analysis to dramatically improve database performance and eliminate slow queries. Use when debugging slow queries, designing database schemas, or optimizing application performance.\n---\n\n# SQL Optimization Patterns\n\nTransform slow database queries into lightning-fast operations through systematic optimization, proper indexing, and query plan analysis.\n\n## When to Use This Skill\n\n- Debugging slow-running queries\n- Designing performant database schemas\n- Optimizing application response times\n- Reducing database load and costs\n- Improving scalability for growing datasets\n- Analyzing EXPLAIN query plans\n- Implementing efficient indexes\n- Resolving N+1 query problems\n\n## Core Concepts\n\n### 1. Query Execution Plans (EXPLAIN)\n\nUnderstanding EXPLAIN output is fundamental to optimization.\n\n**PostgreSQL EXPLAIN:**\n```sql\n-- Basic explain\nEXPLAIN SELECT * FROM users WHERE email = 'user@example.com';\n\n-- With actual execution stats\nEXPLAIN ANALYZE\nSELECT * FROM users WHERE email = 'user@example.com';\n\n-- Verbose output with more details\nEXPLAIN (ANALYZE, BUFFERS, VERBOSE)\nSELECT u.*, o.order_total\nFROM users u\nJOIN orders o ON u.id = o.user_id\nWHERE u.created_at > NOW() - INTERVAL '30 days';\n```\n\n**Key Metrics to Watch:**\n- **Seq Scan**: Full table scan (usually slow for large tables)\n- **Index Scan**: Using index (good)\n- **Index Only Scan**: Using index without touching table (best)\n- **Nested Loop**: Join method (okay for small datasets)\n- **Hash Join**: Join method (good for larger datasets)\n- **Merge Join**: Join method (good for sorted data)\n- **Cost**: Estimated query cost (lower is better)\n- **Rows**: Estimated rows returned\n- **Actual Time**: Real execution time\n\n### 2. Index Strategies\n\nIndexes are the most powerful optimization tool.\n\n**Index Types:**\n- **B-Tree**: Default, good for equality and range queries\n- **Hash**: Only for equality (=) comparisons\n- **GIN**: Full-text search, array queries, JSONB\n- **GiST**: Geometric data, full-text search\n- **BRIN**: Block Range INdex for very large tables with correlation\n\n```sql\n-- Standard B-Tree index\nCREATE INDEX idx_users_email ON users(email);\n\n-- Composite index (order matters!)\nCREATE INDEX idx_orders_user_status ON orders(user_id, status);\n\n-- Partial index (index subset of rows)\nCREATE INDEX idx_active_users ON users(email)\nWHERE status = 'active';\n\n-- Expression index\nCREATE INDEX idx_users_lower_email ON users(LOWER(email));\n\n-- Covering index (include additional columns)\nCREATE INDEX idx_users_email_covering ON users(email)\nINCLUDE (name, created_at);\n\n-- Full-text search index\nCREATE INDEX idx_posts_search ON posts\nUSING GIN(to_tsvector('english', title || ' ' || body));\n\n-- JSONB index\nCREATE INDEX idx_metadata ON events USING GIN(metadata);\n```\n\n### 3. Query Optimization Patterns\n\n**Avoid SELECT \\*:**\n```sql\n-- Bad: Fetches unnecessary columns\nSELECT * FROM users WHERE id = 123;\n\n-- Good: Fetch only what you need\nSELECT id, email, name FROM users WHERE id = 123;\n```\n\n**Use WHERE Clause Efficiently:**\n```sql\n-- Bad: Function prevents index usage\nSELECT * FROM users WHERE LOWER(email) = 'user@example.com';\n\n-- Good: Create functional index or use exact match\nCREATE INDEX idx_users_email_lower ON users(LOWER(email));\n-- Then:\nSELECT * FROM users WHERE LOWER(email) = 'user@example.com';\n\n-- Or store normalized data\nSELECT * FROM users WHERE email = 'user@example.com';\n```\n\n**Optimize JOINs:**\n```sql\n-- Bad: Cartesian product then filter\nSELECT u.name, o.total\nFROM users u, orders o\nWHERE u.id = o.user_id AND u.created_at > '2024-01-01';\n\n-- Good: Filter before join\nSELECT u.name, o.total\nFROM users u\nJOIN orders o ON u.id = o.user_id\nWHERE u.created_at > '2024-01-01';\n\n-- Better: Filter both tables\nSELECT u.name, o.total\nFROM (SELECT * FROM users WHERE created_at > '2024-01-01') u\nJOIN orders o ON u.id = o.user_id;\n```\n\n## Optimization Patterns\n\n### Pattern 1: Eliminate N+1 Queries\n\n**Problem: N+1 Query Anti-Pattern**\n```python\n# Bad: Executes N+1 queries\nusers = db.query(\"SELECT * FROM users LIMIT 10\")\nfor user in users:\n    orders = db.query(\"SELECT * FROM orders WHERE user_id = ?\", user.id)\n    # Process orders\n```\n\n**Solution: Use JOINs or Batch Loading**\n```sql\n-- Solution 1: JOIN\nSELECT\n    u.id, u.name,\n    o.id as order_id, o.total\nFROM users u\nLEFT JOIN orders o ON u.id = o.user_id\nWHERE u.id IN (1, 2, 3, 4, 5);\n\n-- Solution 2: Batch query\nSELECT * FROM orders\nWHERE user_id IN (1, 2, 3, 4, 5);\n```\n\n```python\n# Good: Single query with JOIN or batch load\n# Using JOIN\nresults = db.query(\"\"\"\n    SELECT u.id, u.name, o.id as order_id, o.total\n    FROM users u\n    LEFT JOIN orders o ON u.id = o.user_id\n    WHERE u.id IN (1, 2, 3, 4, 5)\n\"\"\")\n\n# Or batch load\nusers = db.query(\"SELECT * FROM users LIMIT 10\")\nuser_ids = [u.id for u in users]\norders = db.query(\n    \"SELECT * FROM orders WHERE user_id IN (?)\",\n    user_ids\n)\n# Group orders by user_id\norders_by_user = {}\nfor order in orders:\n    orders_by_user.setdefault(order.user_id, []).append(order)\n```\n\n### Pattern 2: Optimize Pagination\n\n**Bad: OFFSET on Large Tables**\n```sql\n-- Slow for large offsets\nSELECT * FROM users\nORDER BY created_at DESC\nLIMIT 20 OFFSET 100000;  -- Very slow!\n```\n\n**Good: Cursor-Based Pagination**\n```sql\n-- Much faster: Use cursor (last seen ID)\nSELECT * FROM users\nWHERE created_at < '2024-01-15 10:30:00'  -- Last cursor\nORDER BY created_at DESC\nLIMIT 20;\n\n-- With composite sorting\nSELECT * FROM users\nWHERE (created_at, id) < ('2024-01-15 10:30:00', 12345)\nORDER BY created_at DESC, id DESC\nLIMIT 20;\n\n-- Requires index\nCREATE INDEX idx_users_cursor ON users(created_at DESC, id DESC);\n```\n\n### Pattern 3: Aggregate Efficiently\n\n**Optimize COUNT Queries:**\n```sql\n-- Bad: Counts all rows\nSELECT COUNT(*) FROM orders;  -- Slow on large tables\n\n-- Good: Use estimates for approximate counts\nSELECT reltuples::bigint AS estimate\nFROM pg_class\nWHERE relname = 'orders';\n\n-- Good: Filter before counting\nSELECT COUNT(*) FROM orders\nWHERE created_at > NOW() - INTERVAL '7 days';\n\n-- Better: Use index-only scan\nCREATE INDEX idx_orders_created ON orders(created_at);\nSELECT COUNT(*) FROM orders\nWHERE created_at > NOW() - INTERVAL '7 days';\n```\n\n**Optimize GROUP BY:**\n```sql\n-- Bad: Group by then filter\nSELECT user_id, COUNT(*) as order_count\nFROM orders\nGROUP BY user_id\nHAVING COUNT(*) > 10;\n\n-- Better: Filter first, then group (if possible)\nSELECT user_id, COUNT(*) as order_count\nFROM orders\nWHERE status = 'completed'\nGROUP BY user_id\nHAVING COUNT(*) > 10;\n\n-- Best: Use covering index\nCREATE INDEX idx_orders_user_status ON orders(user_id, status);\n```\n\n### Pattern 4: Subquery Optimization\n\n**Transform Correlated Subqueries:**\n```sql\n-- Bad: Correlated subquery (runs for each row)\nSELECT u.name, u.email,\n    (SELECT COUNT(*) FROM orders o WHERE o.user_id = u.id) as order_count\nFROM users u;\n\n-- Good: JOIN with aggregation\nSELECT u.name, u.email, COUNT(o.id) as order_count\nFROM users u\nLEFT JOIN orders o ON o.user_id = u.id\nGROUP BY u.id, u.name, u.email;\n\n-- Better: Use window functions\nSELECT DISTINCT ON (u.id)\n    u.name, u.email,\n    COUNT(o.id) OVER (PARTITION BY u.id) as order_count\nFROM users u\nLEFT JOIN orders o ON o.user_id = u.id;\n```\n\n**Use CTEs for Clarity:**\n```sql\n-- Using Common Table Expressions\nWITH recent_users AS (\n    SELECT id, name, email\n    FROM users\n    WHERE created_at > NOW() - INTERVAL '30 days'\n),\nuser_order_counts AS (\n    SELECT user_id, COUNT(*) as order_count\n    FROM orders\n    WHERE created_at > NOW() - INTERVAL '30 days'\n    GROUP BY user_id\n)\nSELECT ru.name, ru.email, COALESCE(uoc.order_count, 0) as orders\nFROM recent_users ru\nLEFT JOIN user_order_counts uoc ON ru.id = uoc.user_id;\n```\n\n### Pattern 5: Batch Operations\n\n**Batch INSERT:**\n```sql\n-- Bad: Multiple individual inserts\nINSERT INTO users (name, email) VALUES ('Alice', 'alice@example.com');\nINSERT INTO users (name, email) VALUES ('Bob', 'bob@example.com');\nINSERT INTO users (name, email) VALUES ('Carol', 'carol@example.com');\n\n-- Good: Batch insert\nINSERT INTO users (name, email) VALUES\n    ('Alice', 'alice@example.com'),\n    ('Bob', 'bob@example.com'),\n    ('Carol', 'carol@example.com');\n\n-- Better: Use COPY for bulk inserts (PostgreSQL)\nCOPY users (name, email) FROM '/tmp/users.csv' CSV HEADER;\n```\n\n**Batch UPDATE:**\n```sql\n-- Bad: Update in loop\nUPDATE users SET status = 'active' WHERE id = 1;\nUPDATE users SET status = 'active' WHERE id = 2;\n-- ... repeat for many IDs\n\n-- Good: Single UPDATE with IN clause\nUPDATE users\nSET status = 'active'\nWHERE id IN (1, 2, 3, 4, 5, ...);\n\n-- Better: Use temporary table for large batches\nCREATE TEMP TABLE temp_user_updates (id INT, new_status VARCHAR);\nINSERT INTO temp_user_updates VALUES (1, 'active'), (2, 'active'), ...;\n\nUPDATE users u\nSET status = t.new_status\nFROM temp_user_updates t\nWHERE u.id = t.id;\n```\n\n## Advanced Techniques\n\n### Materialized Views\n\nPre-compute expensive queries.\n\n```sql\n-- Create materialized view\nCREATE MATERIALIZED VIEW user_order_summary AS\nSELECT\n    u.id,\n    u.name,\n    COUNT(o.id) as total_orders,\n    SUM(o.total) as total_spent,\n    MAX(o.created_at) as last_order_date\nFROM users u\nLEFT JOIN orders o ON u.id = o.user_id\nGROUP BY u.id, u.name;\n\n-- Add index to materialized view\nCREATE INDEX idx_user_summary_spent ON user_order_summary(total_spent DESC);\n\n-- Refresh materialized view\nREFRESH MATERIALIZED VIEW user_order_summary;\n\n-- Concurrent refresh (PostgreSQL)\nREFRESH MATERIALIZED VIEW CONCURRENTLY user_order_summary;\n\n-- Query materialized view (very fast)\nSELECT * FROM user_order_summary\nWHERE total_spent > 1000\nORDER BY total_spent DESC;\n```\n\n### Partitioning\n\nSplit large tables for better performance.\n\n```sql\n-- Range partitioning by date (PostgreSQL)\nCREATE TABLE orders (\n    id SERIAL,\n    user_id INT,\n    total DECIMAL,\n    created_at TIMESTAMP\n) PARTITION BY RANGE (created_at);\n\n-- Create partitions\nCREATE TABLE orders_2024_q1 PARTITION OF orders\n    FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');\n\nCREATE TABLE orders_2024_q2 PARTITION OF orders\n    FOR VALUES FROM ('2024-04-01') TO ('2024-07-01');\n\n-- Queries automatically use appropriate partition\nSELECT * FROM orders\nWHERE created_at BETWEEN '2024-02-01' AND '2024-02-28';\n-- Only scans orders_2024_q1 partition\n```\n\n### Query Hints and Optimization\n\n```sql\n-- Force index usage (MySQL)\nSELECT * FROM users\nUSE INDEX (idx_users_email)\nWHERE email = 'user@example.com';\n\n-- Parallel query (PostgreSQL)\nSET max_parallel_workers_per_gather = 4;\nSELECT * FROM large_table WHERE condition;\n\n-- Join hints (PostgreSQL)\nSET enable_nestloop = OFF;  -- Force hash or merge join\n```\n\n## Best Practices\n\n1. **Index Selectively**: Too many indexes slow down writes\n2. **Monitor Query Performance**: Use slow query logs\n3. **Keep Statistics Updated**: Run ANALYZE regularly\n4. **Use Appropriate Data Types**: Smaller types = better performance\n5. **Normalize Thoughtfully**: Balance normalization vs performance\n6. **Cache Frequently Accessed Data**: Use application-level caching\n7. **Connection Pooling**: Reuse database connections\n8. **Regular Maintenance**: VACUUM, ANALYZE, rebuild indexes\n\n```sql\n-- Update statistics\nANALYZE users;\nANALYZE VERBOSE orders;\n\n-- Vacuum (PostgreSQL)\nVACUUM ANALYZE users;\nVACUUM FULL users;  -- Reclaim space (locks table)\n\n-- Reindex\nREINDEX INDEX idx_users_email;\nREINDEX TABLE users;\n```\n\n## Common Pitfalls\n\n- **Over-Indexing**: Each index slows down INSERT/UPDATE/DELETE\n- **Unused Indexes**: Waste space and slow writes\n- **Missing Indexes**: Slow queries, full table scans\n- **Implicit Type Conversion**: Prevents index usage\n- **OR Conditions**: Can't use indexes efficiently\n- **LIKE with Leading Wildcard**: `LIKE '%abc'` can't use index\n- **Function in WHERE**: Prevents index usage unless functional index exists\n\n## Monitoring Queries\n\n```sql\n-- Find slow queries (PostgreSQL)\nSELECT query, calls, total_time, mean_time\nFROM pg_stat_statements\nORDER BY mean_time DESC\nLIMIT 10;\n\n-- Find missing indexes (PostgreSQL)\nSELECT\n    schemaname,\n    tablename,\n    seq_scan,\n    seq_tup_read,\n    idx_scan,\n    seq_tup_read / seq_scan AS avg_seq_tup_read\nFROM pg_stat_user_tables\nWHERE seq_scan > 0\nORDER BY seq_tup_read DESC\nLIMIT 10;\n\n-- Find unused indexes (PostgreSQL)\nSELECT\n    schemaname,\n    tablename,\n    indexname,\n    idx_scan,\n    idx_tup_read,\n    idx_tup_fetch\nFROM pg_stat_user_indexes\nWHERE idx_scan = 0\nORDER BY pg_relation_size(indexrelid) DESC;\n```\n\n## Resources\n\n- **references/postgres-optimization-guide.md**: PostgreSQL-specific optimization\n- **references/mysql-optimization-guide.md**: MySQL/MariaDB optimization\n- **references/query-plan-analysis.md**: Deep dive into EXPLAIN plans\n- **assets/index-strategy-checklist.md**: When and how to create indexes\n- **assets/query-optimization-checklist.md**: Step-by-step optimization guide\n- **scripts/analyze-slow-queries.sql**: Identify slow queries in your database\n- **scripts/index-recommendations.sql**: Generate index recommendations\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "error-handling-patterns",
      "description": "Master error handling patterns across languages including exceptions, Result types, error propagation, and graceful degradation to build resilient applications. Use when implementing error handling, designing APIs, or improving application reliability.",
      "plugin": "developer-essentials",
      "source_path": "plugins/developer-essentials/skills/error-handling-patterns/SKILL.md",
      "category": "development",
      "keywords": [
        "git",
        "sql",
        "debugging",
        "testing",
        "authentication",
        "code-review",
        "monorepo",
        "essential"
      ],
      "content": "---\nname: error-handling-patterns\ndescription: Master error handling patterns across languages including exceptions, Result types, error propagation, and graceful degradation to build resilient applications. Use when implementing error handling, designing APIs, or improving application reliability.\n---\n\n# Error Handling Patterns\n\nBuild resilient applications with robust error handling strategies that gracefully handle failures and provide excellent debugging experiences.\n\n## When to Use This Skill\n\n- Implementing error handling in new features\n- Designing error-resilient APIs\n- Debugging production issues\n- Improving application reliability\n- Creating better error messages for users and developers\n- Implementing retry and circuit breaker patterns\n- Handling async/concurrent errors\n- Building fault-tolerant distributed systems\n\n## Core Concepts\n\n### 1. Error Handling Philosophies\n\n**Exceptions vs Result Types:**\n- **Exceptions**: Traditional try-catch, disrupts control flow\n- **Result Types**: Explicit success/failure, functional approach\n- **Error Codes**: C-style, requires discipline\n- **Option/Maybe Types**: For nullable values\n\n**When to Use Each:**\n- Exceptions: Unexpected errors, exceptional conditions\n- Result Types: Expected errors, validation failures\n- Panics/Crashes: Unrecoverable errors, programming bugs\n\n### 2. Error Categories\n\n**Recoverable Errors:**\n- Network timeouts\n- Missing files\n- Invalid user input\n- API rate limits\n\n**Unrecoverable Errors:**\n- Out of memory\n- Stack overflow\n- Programming bugs (null pointer, etc.)\n\n## Language-Specific Patterns\n\n### Python Error Handling\n\n**Custom Exception Hierarchy:**\n```python\nclass ApplicationError(Exception):\n    \"\"\"Base exception for all application errors.\"\"\"\n    def __init__(self, message: str, code: str = None, details: dict = None):\n        super().__init__(message)\n        self.code = code\n        self.details = details or {}\n        self.timestamp = datetime.utcnow()\n\nclass ValidationError(ApplicationError):\n    \"\"\"Raised when validation fails.\"\"\"\n    pass\n\nclass NotFoundError(ApplicationError):\n    \"\"\"Raised when resource not found.\"\"\"\n    pass\n\nclass ExternalServiceError(ApplicationError):\n    \"\"\"Raised when external service fails.\"\"\"\n    def __init__(self, message: str, service: str, **kwargs):\n        super().__init__(message, **kwargs)\n        self.service = service\n\n# Usage\ndef get_user(user_id: str) -> User:\n    user = db.query(User).filter_by(id=user_id).first()\n    if not user:\n        raise NotFoundError(\n            f\"User not found\",\n            code=\"USER_NOT_FOUND\",\n            details={\"user_id\": user_id}\n        )\n    return user\n```\n\n**Context Managers for Cleanup:**\n```python\nfrom contextlib import contextmanager\n\n@contextmanager\ndef database_transaction(session):\n    \"\"\"Ensure transaction is committed or rolled back.\"\"\"\n    try:\n        yield session\n        session.commit()\n    except Exception as e:\n        session.rollback()\n        raise\n    finally:\n        session.close()\n\n# Usage\nwith database_transaction(db.session) as session:\n    user = User(name=\"Alice\")\n    session.add(user)\n    # Automatic commit or rollback\n```\n\n**Retry with Exponential Backoff:**\n```python\nimport time\nfrom functools import wraps\nfrom typing import TypeVar, Callable\n\nT = TypeVar('T')\n\ndef retry(\n    max_attempts: int = 3,\n    backoff_factor: float = 2.0,\n    exceptions: tuple = (Exception,)\n):\n    \"\"\"Retry decorator with exponential backoff.\"\"\"\n    def decorator(func: Callable[..., T]) -> Callable[..., T]:\n        @wraps(func)\n        def wrapper(*args, **kwargs) -> T:\n            last_exception = None\n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except exceptions as e:\n                    last_exception = e\n                    if attempt < max_attempts - 1:\n                        sleep_time = backoff_factor ** attempt\n                        time.sleep(sleep_time)\n                        continue\n                    raise\n            raise last_exception\n        return wrapper\n    return decorator\n\n# Usage\n@retry(max_attempts=3, exceptions=(NetworkError,))\ndef fetch_data(url: str) -> dict:\n    response = requests.get(url, timeout=5)\n    response.raise_for_status()\n    return response.json()\n```\n\n### TypeScript/JavaScript Error Handling\n\n**Custom Error Classes:**\n```typescript\n// Custom error classes\nclass ApplicationError extends Error {\n    constructor(\n        message: string,\n        public code: string,\n        public statusCode: number = 500,\n        public details?: Record<string, any>\n    ) {\n        super(message);\n        this.name = this.constructor.name;\n        Error.captureStackTrace(this, this.constructor);\n    }\n}\n\nclass ValidationError extends ApplicationError {\n    constructor(message: string, details?: Record<string, any>) {\n        super(message, 'VALIDATION_ERROR', 400, details);\n    }\n}\n\nclass NotFoundError extends ApplicationError {\n    constructor(resource: string, id: string) {\n        super(\n            `${resource} not found`,\n            'NOT_FOUND',\n            404,\n            { resource, id }\n        );\n    }\n}\n\n// Usage\nfunction getUser(id: string): User {\n    const user = users.find(u => u.id === id);\n    if (!user) {\n        throw new NotFoundError('User', id);\n    }\n    return user;\n}\n```\n\n**Result Type Pattern:**\n```typescript\n// Result type for explicit error handling\ntype Result<T, E = Error> =\n    | { ok: true; value: T }\n    | { ok: false; error: E };\n\n// Helper functions\nfunction Ok<T>(value: T): Result<T, never> {\n    return { ok: true, value };\n}\n\nfunction Err<E>(error: E): Result<never, E> {\n    return { ok: false, error };\n}\n\n// Usage\nfunction parseJSON<T>(json: string): Result<T, SyntaxError> {\n    try {\n        const value = JSON.parse(json) as T;\n        return Ok(value);\n    } catch (error) {\n        return Err(error as SyntaxError);\n    }\n}\n\n// Consuming Result\nconst result = parseJSON<User>(userJson);\nif (result.ok) {\n    console.log(result.value.name);\n} else {\n    console.error('Parse failed:', result.error.message);\n}\n\n// Chaining Results\nfunction chain<T, U, E>(\n    result: Result<T, E>,\n    fn: (value: T) => Result<U, E>\n): Result<U, E> {\n    return result.ok ? fn(result.value) : result;\n}\n```\n\n**Async Error Handling:**\n```typescript\n// Async/await with proper error handling\nasync function fetchUserOrders(userId: string): Promise<Order[]> {\n    try {\n        const user = await getUser(userId);\n        const orders = await getOrders(user.id);\n        return orders;\n    } catch (error) {\n        if (error instanceof NotFoundError) {\n            return [];  // Return empty array for not found\n        }\n        if (error instanceof NetworkError) {\n            // Retry logic\n            return retryFetchOrders(userId);\n        }\n        // Re-throw unexpected errors\n        throw error;\n    }\n}\n\n// Promise error handling\nfunction fetchData(url: string): Promise<Data> {\n    return fetch(url)\n        .then(response => {\n            if (!response.ok) {\n                throw new NetworkError(`HTTP ${response.status}`);\n            }\n            return response.json();\n        })\n        .catch(error => {\n            console.error('Fetch failed:', error);\n            throw error;\n        });\n}\n```\n\n### Rust Error Handling\n\n**Result and Option Types:**\n```rust\nuse std::fs::File;\nuse std::io::{self, Read};\n\n// Result type for operations that can fail\nfn read_file(path: &str) -> Result<String, io::Error> {\n    let mut file = File::open(path)?;  // ? operator propagates errors\n    let mut contents = String::new();\n    file.read_to_string(&mut contents)?;\n    Ok(contents)\n}\n\n// Custom error types\n#[derive(Debug)]\nenum AppError {\n    Io(io::Error),\n    Parse(std::num::ParseIntError),\n    NotFound(String),\n    Validation(String),\n}\n\nimpl From<io::Error> for AppError {\n    fn from(error: io::Error) -> Self {\n        AppError::Io(error)\n    }\n}\n\n// Using custom error type\nfn read_number_from_file(path: &str) -> Result<i32, AppError> {\n    let contents = read_file(path)?;  // Auto-converts io::Error\n    let number = contents.trim().parse()\n        .map_err(AppError::Parse)?;   // Explicitly convert ParseIntError\n    Ok(number)\n}\n\n// Option for nullable values\nfn find_user(id: &str) -> Option<User> {\n    users.iter().find(|u| u.id == id).cloned()\n}\n\n// Combining Option and Result\nfn get_user_age(id: &str) -> Result<u32, AppError> {\n    find_user(id)\n        .ok_or_else(|| AppError::NotFound(id.to_string()))\n        .map(|user| user.age)\n}\n```\n\n### Go Error Handling\n\n**Explicit Error Returns:**\n```go\n// Basic error handling\nfunc getUser(id string) (*User, error) {\n    user, err := db.QueryUser(id)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to query user: %w\", err)\n    }\n    if user == nil {\n        return nil, errors.New(\"user not found\")\n    }\n    return user, nil\n}\n\n// Custom error types\ntype ValidationError struct {\n    Field   string\n    Message string\n}\n\nfunc (e *ValidationError) Error() string {\n    return fmt.Sprintf(\"validation failed for %s: %s\", e.Field, e.Message)\n}\n\n// Sentinel errors for comparison\nvar (\n    ErrNotFound     = errors.New(\"not found\")\n    ErrUnauthorized = errors.New(\"unauthorized\")\n    ErrInvalidInput = errors.New(\"invalid input\")\n)\n\n// Error checking\nuser, err := getUser(\"123\")\nif err != nil {\n    if errors.Is(err, ErrNotFound) {\n        // Handle not found\n    } else {\n        // Handle other errors\n    }\n}\n\n// Error wrapping and unwrapping\nfunc processUser(id string) error {\n    user, err := getUser(id)\n    if err != nil {\n        return fmt.Errorf(\"process user failed: %w\", err)\n    }\n    // Process user\n    return nil\n}\n\n// Unwrap errors\nerr := processUser(\"123\")\nif err != nil {\n    var valErr *ValidationError\n    if errors.As(err, &valErr) {\n        fmt.Printf(\"Validation error: %s\\n\", valErr.Field)\n    }\n}\n```\n\n## Universal Patterns\n\n### Pattern 1: Circuit Breaker\n\nPrevent cascading failures in distributed systems.\n\n```python\nfrom enum import Enum\nfrom datetime import datetime, timedelta\nfrom typing import Callable, TypeVar\n\nT = TypeVar('T')\n\nclass CircuitState(Enum):\n    CLOSED = \"closed\"       # Normal operation\n    OPEN = \"open\"          # Failing, reject requests\n    HALF_OPEN = \"half_open\"  # Testing if recovered\n\nclass CircuitBreaker:\n    def __init__(\n        self,\n        failure_threshold: int = 5,\n        timeout: timedelta = timedelta(seconds=60),\n        success_threshold: int = 2\n    ):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.success_threshold = success_threshold\n        self.failure_count = 0\n        self.success_count = 0\n        self.state = CircuitState.CLOSED\n        self.last_failure_time = None\n\n    def call(self, func: Callable[[], T]) -> T:\n        if self.state == CircuitState.OPEN:\n            if datetime.now() - self.last_failure_time > self.timeout:\n                self.state = CircuitState.HALF_OPEN\n                self.success_count = 0\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n\n        try:\n            result = func()\n            self.on_success()\n            return result\n        except Exception as e:\n            self.on_failure()\n            raise\n\n    def on_success(self):\n        self.failure_count = 0\n        if self.state == CircuitState.HALF_OPEN:\n            self.success_count += 1\n            if self.success_count >= self.success_threshold:\n                self.state = CircuitState.CLOSED\n                self.success_count = 0\n\n    def on_failure(self):\n        self.failure_count += 1\n        self.last_failure_time = datetime.now()\n        if self.failure_count >= self.failure_threshold:\n            self.state = CircuitState.OPEN\n\n# Usage\ncircuit_breaker = CircuitBreaker()\n\ndef fetch_data():\n    return circuit_breaker.call(lambda: external_api.get_data())\n```\n\n### Pattern 2: Error Aggregation\n\nCollect multiple errors instead of failing on first error.\n\n```typescript\nclass ErrorCollector {\n    private errors: Error[] = [];\n\n    add(error: Error): void {\n        this.errors.push(error);\n    }\n\n    hasErrors(): boolean {\n        return this.errors.length > 0;\n    }\n\n    getErrors(): Error[] {\n        return [...this.errors];\n    }\n\n    throw(): never {\n        if (this.errors.length === 1) {\n            throw this.errors[0];\n        }\n        throw new AggregateError(\n            this.errors,\n            `${this.errors.length} errors occurred`\n        );\n    }\n}\n\n// Usage: Validate multiple fields\nfunction validateUser(data: any): User {\n    const errors = new ErrorCollector();\n\n    if (!data.email) {\n        errors.add(new ValidationError('Email is required'));\n    } else if (!isValidEmail(data.email)) {\n        errors.add(new ValidationError('Email is invalid'));\n    }\n\n    if (!data.name || data.name.length < 2) {\n        errors.add(new ValidationError('Name must be at least 2 characters'));\n    }\n\n    if (!data.age || data.age < 18) {\n        errors.add(new ValidationError('Age must be 18 or older'));\n    }\n\n    if (errors.hasErrors()) {\n        errors.throw();\n    }\n\n    return data as User;\n}\n```\n\n### Pattern 3: Graceful Degradation\n\nProvide fallback functionality when errors occur.\n\n```python\nfrom typing import Optional, Callable, TypeVar\n\nT = TypeVar('T')\n\ndef with_fallback(\n    primary: Callable[[], T],\n    fallback: Callable[[], T],\n    log_error: bool = True\n) -> T:\n    \"\"\"Try primary function, fall back to fallback on error.\"\"\"\n    try:\n        return primary()\n    except Exception as e:\n        if log_error:\n            logger.error(f\"Primary function failed: {e}\")\n        return fallback()\n\n# Usage\ndef get_user_profile(user_id: str) -> UserProfile:\n    return with_fallback(\n        primary=lambda: fetch_from_cache(user_id),\n        fallback=lambda: fetch_from_database(user_id)\n    )\n\n# Multiple fallbacks\ndef get_exchange_rate(currency: str) -> float:\n    return (\n        try_function(lambda: api_provider_1.get_rate(currency))\n        or try_function(lambda: api_provider_2.get_rate(currency))\n        or try_function(lambda: cache.get_rate(currency))\n        or DEFAULT_RATE\n    )\n\ndef try_function(func: Callable[[], Optional[T]]) -> Optional[T]:\n    try:\n        return func()\n    except Exception:\n        return None\n```\n\n## Best Practices\n\n1. **Fail Fast**: Validate input early, fail quickly\n2. **Preserve Context**: Include stack traces, metadata, timestamps\n3. **Meaningful Messages**: Explain what happened and how to fix it\n4. **Log Appropriately**: Error = log, expected failure = don't spam logs\n5. **Handle at Right Level**: Catch where you can meaningfully handle\n6. **Clean Up Resources**: Use try-finally, context managers, defer\n7. **Don't Swallow Errors**: Log or re-throw, don't silently ignore\n8. **Type-Safe Errors**: Use typed errors when possible\n\n```python\n# Good error handling example\ndef process_order(order_id: str) -> Order:\n    \"\"\"Process order with comprehensive error handling.\"\"\"\n    try:\n        # Validate input\n        if not order_id:\n            raise ValidationError(\"Order ID is required\")\n\n        # Fetch order\n        order = db.get_order(order_id)\n        if not order:\n            raise NotFoundError(\"Order\", order_id)\n\n        # Process payment\n        try:\n            payment_result = payment_service.charge(order.total)\n        except PaymentServiceError as e:\n            # Log and wrap external service error\n            logger.error(f\"Payment failed for order {order_id}: {e}\")\n            raise ExternalServiceError(\n                f\"Payment processing failed\",\n                service=\"payment_service\",\n                details={\"order_id\": order_id, \"amount\": order.total}\n            ) from e\n\n        # Update order\n        order.status = \"completed\"\n        order.payment_id = payment_result.id\n        db.save(order)\n\n        return order\n\n    except ApplicationError:\n        # Re-raise known application errors\n        raise\n    except Exception as e:\n        # Log unexpected errors\n        logger.exception(f\"Unexpected error processing order {order_id}\")\n        raise ApplicationError(\n            \"Order processing failed\",\n            code=\"INTERNAL_ERROR\"\n        ) from e\n```\n\n## Common Pitfalls\n\n- **Catching Too Broadly**: `except Exception` hides bugs\n- **Empty Catch Blocks**: Silently swallowing errors\n- **Logging and Re-throwing**: Creates duplicate log entries\n- **Not Cleaning Up**: Forgetting to close files, connections\n- **Poor Error Messages**: \"Error occurred\" is not helpful\n- **Returning Error Codes**: Use exceptions or Result types\n- **Ignoring Async Errors**: Unhandled promise rejections\n\n## Resources\n\n- **references/exception-hierarchy-design.md**: Designing error class hierarchies\n- **references/error-recovery-strategies.md**: Recovery patterns for different scenarios\n- **references/async-error-handling.md**: Handling errors in concurrent code\n- **assets/error-handling-checklist.md**: Review checklist for error handling\n- **assets/error-message-guide.md**: Writing helpful error messages\n- **scripts/error-analyzer.py**: Analyze error patterns in logs\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "code-review-excellence",
      "description": "Master effective code review practices to provide constructive feedback, catch bugs early, and foster knowledge sharing while maintaining team morale. Use when reviewing pull requests, establishing review standards, or mentoring developers.",
      "plugin": "developer-essentials",
      "source_path": "plugins/developer-essentials/skills/code-review-excellence/SKILL.md",
      "category": "development",
      "keywords": [
        "git",
        "sql",
        "debugging",
        "testing",
        "authentication",
        "code-review",
        "monorepo",
        "essential"
      ],
      "content": "---\nname: code-review-excellence\ndescription: Master effective code review practices to provide constructive feedback, catch bugs early, and foster knowledge sharing while maintaining team morale. Use when reviewing pull requests, establishing review standards, or mentoring developers.\n---\n\n# Code Review Excellence\n\nTransform code reviews from gatekeeping to knowledge sharing through constructive feedback, systematic analysis, and collaborative improvement.\n\n## When to Use This Skill\n\n- Reviewing pull requests and code changes\n- Establishing code review standards for teams\n- Mentoring junior developers through reviews\n- Conducting architecture reviews\n- Creating review checklists and guidelines\n- Improving team collaboration\n- Reducing code review cycle time\n- Maintaining code quality standards\n\n## Core Principles\n\n### 1. The Review Mindset\n\n**Goals of Code Review:**\n- Catch bugs and edge cases\n- Ensure code maintainability\n- Share knowledge across team\n- Enforce coding standards\n- Improve design and architecture\n- Build team culture\n\n**Not the Goals:**\n- Show off knowledge\n- Nitpick formatting (use linters)\n- Block progress unnecessarily\n- Rewrite to your preference\n\n### 2. Effective Feedback\n\n**Good Feedback is:**\n- Specific and actionable\n- Educational, not judgmental\n- Focused on the code, not the person\n- Balanced (praise good work too)\n- Prioritized (critical vs nice-to-have)\n\n```markdown\n\u274c Bad: \"This is wrong.\"\n\u2705 Good: \"This could cause a race condition when multiple users\n         access simultaneously. Consider using a mutex here.\"\n\n\u274c Bad: \"Why didn't you use X pattern?\"\n\u2705 Good: \"Have you considered the Repository pattern? It would\n         make this easier to test. Here's an example: [link]\"\n\n\u274c Bad: \"Rename this variable.\"\n\u2705 Good: \"[nit] Consider `userCount` instead of `uc` for\n         clarity. Not blocking if you prefer to keep it.\"\n```\n\n### 3. Review Scope\n\n**What to Review:**\n- Logic correctness and edge cases\n- Security vulnerabilities\n- Performance implications\n- Test coverage and quality\n- Error handling\n- Documentation and comments\n- API design and naming\n- Architectural fit\n\n**What Not to Review Manually:**\n- Code formatting (use Prettier, Black, etc.)\n- Import organization\n- Linting violations\n- Simple typos\n\n## Review Process\n\n### Phase 1: Context Gathering (2-3 minutes)\n\n```markdown\nBefore diving into code, understand:\n\n1. Read PR description and linked issue\n2. Check PR size (>400 lines? Ask to split)\n3. Review CI/CD status (tests passing?)\n4. Understand the business requirement\n5. Note any relevant architectural decisions\n```\n\n### Phase 2: High-Level Review (5-10 minutes)\n\n```markdown\n1. **Architecture & Design**\n   - Does the solution fit the problem?\n   - Are there simpler approaches?\n   - Is it consistent with existing patterns?\n   - Will it scale?\n\n2. **File Organization**\n   - Are new files in the right places?\n   - Is code grouped logically?\n   - Are there duplicate files?\n\n3. **Testing Strategy**\n   - Are there tests?\n   - Do tests cover edge cases?\n   - Are tests readable?\n```\n\n### Phase 3: Line-by-Line Review (10-20 minutes)\n\n```markdown\nFor each file:\n\n1. **Logic & Correctness**\n   - Edge cases handled?\n   - Off-by-one errors?\n   - Null/undefined checks?\n   - Race conditions?\n\n2. **Security**\n   - Input validation?\n   - SQL injection risks?\n   - XSS vulnerabilities?\n   - Sensitive data exposure?\n\n3. **Performance**\n   - N+1 queries?\n   - Unnecessary loops?\n   - Memory leaks?\n   - Blocking operations?\n\n4. **Maintainability**\n   - Clear variable names?\n   - Functions doing one thing?\n   - Complex code commented?\n   - Magic numbers extracted?\n```\n\n### Phase 4: Summary & Decision (2-3 minutes)\n\n```markdown\n1. Summarize key concerns\n2. Highlight what you liked\n3. Make clear decision:\n   - \u2705 Approve\n   - \ud83d\udcac Comment (minor suggestions)\n   - \ud83d\udd04 Request Changes (must address)\n4. Offer to pair if complex\n```\n\n## Review Techniques\n\n### Technique 1: The Checklist Method\n\n```markdown\n## Security Checklist\n- [ ] User input validated and sanitized\n- [ ] SQL queries use parameterization\n- [ ] Authentication/authorization checked\n- [ ] Secrets not hardcoded\n- [ ] Error messages don't leak info\n\n## Performance Checklist\n- [ ] No N+1 queries\n- [ ] Database queries indexed\n- [ ] Large lists paginated\n- [ ] Expensive operations cached\n- [ ] No blocking I/O in hot paths\n\n## Testing Checklist\n- [ ] Happy path tested\n- [ ] Edge cases covered\n- [ ] Error cases tested\n- [ ] Test names are descriptive\n- [ ] Tests are deterministic\n```\n\n### Technique 2: The Question Approach\n\nInstead of stating problems, ask questions to encourage thinking:\n\n```markdown\n\u274c \"This will fail if the list is empty.\"\n\u2705 \"What happens if `items` is an empty array?\"\n\n\u274c \"You need error handling here.\"\n\u2705 \"How should this behave if the API call fails?\"\n\n\u274c \"This is inefficient.\"\n\u2705 \"I see this loops through all users. Have we considered\n    the performance impact with 100k users?\"\n```\n\n### Technique 3: Suggest, Don't Command\n\n```markdown\n## Use Collaborative Language\n\n\u274c \"You must change this to use async/await\"\n\u2705 \"Suggestion: async/await might make this more readable:\n    ```typescript\n    async function fetchUser(id: string) {\n        const user = await db.query('SELECT * FROM users WHERE id = ?', id);\n        return user;\n    }\n    ```\n    What do you think?\"\n\n\u274c \"Extract this into a function\"\n\u2705 \"This logic appears in 3 places. Would it make sense to\n    extract it into a shared utility function?\"\n```\n\n### Technique 4: Differentiate Severity\n\n```markdown\nUse labels to indicate priority:\n\n\ud83d\udd34 [blocking] - Must fix before merge\n\ud83d\udfe1 [important] - Should fix, discuss if disagree\n\ud83d\udfe2 [nit] - Nice to have, not blocking\n\ud83d\udca1 [suggestion] - Alternative approach to consider\n\ud83d\udcda [learning] - Educational comment, no action needed\n\ud83c\udf89 [praise] - Good work, keep it up!\n\nExample:\n\"\ud83d\udd34 [blocking] This SQL query is vulnerable to injection.\n Please use parameterized queries.\"\n\n\"\ud83d\udfe2 [nit] Consider renaming `data` to `userData` for clarity.\"\n\n\"\ud83c\udf89 [praise] Excellent test coverage! This will catch edge cases.\"\n```\n\n## Language-Specific Patterns\n\n### Python Code Review\n\n```python\n# Check for Python-specific issues\n\n# \u274c Mutable default arguments\ndef add_item(item, items=[]):  # Bug! Shared across calls\n    items.append(item)\n    return items\n\n# \u2705 Use None as default\ndef add_item(item, items=None):\n    if items is None:\n        items = []\n    items.append(item)\n    return items\n\n# \u274c Catching too broad\ntry:\n    result = risky_operation()\nexcept:  # Catches everything, even KeyboardInterrupt!\n    pass\n\n# \u2705 Catch specific exceptions\ntry:\n    result = risky_operation()\nexcept ValueError as e:\n    logger.error(f\"Invalid value: {e}\")\n    raise\n\n# \u274c Using mutable class attributes\nclass User:\n    permissions = []  # Shared across all instances!\n\n# \u2705 Initialize in __init__\nclass User:\n    def __init__(self):\n        self.permissions = []\n```\n\n### TypeScript/JavaScript Code Review\n\n```typescript\n// Check for TypeScript-specific issues\n\n// \u274c Using any defeats type safety\nfunction processData(data: any) {  // Avoid any\n    return data.value;\n}\n\n// \u2705 Use proper types\ninterface DataPayload {\n    value: string;\n}\nfunction processData(data: DataPayload) {\n    return data.value;\n}\n\n// \u274c Not handling async errors\nasync function fetchUser(id: string) {\n    const response = await fetch(`/api/users/${id}`);\n    return response.json();  // What if network fails?\n}\n\n// \u2705 Handle errors properly\nasync function fetchUser(id: string): Promise<User> {\n    try {\n        const response = await fetch(`/api/users/${id}`);\n        if (!response.ok) {\n            throw new Error(`HTTP ${response.status}`);\n        }\n        return await response.json();\n    } catch (error) {\n        console.error('Failed to fetch user:', error);\n        throw error;\n    }\n}\n\n// \u274c Mutation of props\nfunction UserProfile({ user }: Props) {\n    user.lastViewed = new Date();  // Mutating prop!\n    return <div>{user.name}</div>;\n}\n\n// \u2705 Don't mutate props\nfunction UserProfile({ user, onView }: Props) {\n    useEffect(() => {\n        onView(user.id);  // Notify parent to update\n    }, [user.id]);\n    return <div>{user.name}</div>;\n}\n```\n\n## Advanced Review Patterns\n\n### Pattern 1: Architectural Review\n\n```markdown\nWhen reviewing significant changes:\n\n1. **Design Document First**\n   - For large features, request design doc before code\n   - Review design with team before implementation\n   - Agree on approach to avoid rework\n\n2. **Review in Stages**\n   - First PR: Core abstractions and interfaces\n   - Second PR: Implementation\n   - Third PR: Integration and tests\n   - Easier to review, faster to iterate\n\n3. **Consider Alternatives**\n   - \"Have we considered using [pattern/library]?\"\n   - \"What's the tradeoff vs. the simpler approach?\"\n   - \"How will this evolve as requirements change?\"\n```\n\n### Pattern 2: Test Quality Review\n\n```typescript\n// \u274c Poor test: Implementation detail testing\ntest('increments counter variable', () => {\n    const component = render(<Counter />);\n    const button = component.getByRole('button');\n    fireEvent.click(button);\n    expect(component.state.counter).toBe(1);  // Testing internal state\n});\n\n// \u2705 Good test: Behavior testing\ntest('displays incremented count when clicked', () => {\n    render(<Counter />);\n    const button = screen.getByRole('button', { name: /increment/i });\n    fireEvent.click(button);\n    expect(screen.getByText('Count: 1')).toBeInTheDocument();\n});\n\n// Review questions for tests:\n// - Do tests describe behavior, not implementation?\n// - Are test names clear and descriptive?\n// - Do tests cover edge cases?\n// - Are tests independent (no shared state)?\n// - Can tests run in any order?\n```\n\n### Pattern 3: Security Review\n\n```markdown\n## Security Review Checklist\n\n### Authentication & Authorization\n- [ ] Is authentication required where needed?\n- [ ] Are authorization checks before every action?\n- [ ] Is JWT validation proper (signature, expiry)?\n- [ ] Are API keys/secrets properly secured?\n\n### Input Validation\n- [ ] All user inputs validated?\n- [ ] File uploads restricted (size, type)?\n- [ ] SQL queries parameterized?\n- [ ] XSS protection (escape output)?\n\n### Data Protection\n- [ ] Passwords hashed (bcrypt/argon2)?\n- [ ] Sensitive data encrypted at rest?\n- [ ] HTTPS enforced for sensitive data?\n- [ ] PII handled according to regulations?\n\n### Common Vulnerabilities\n- [ ] No eval() or similar dynamic execution?\n- [ ] No hardcoded secrets?\n- [ ] CSRF protection for state-changing operations?\n- [ ] Rate limiting on public endpoints?\n```\n\n## Giving Difficult Feedback\n\n### Pattern: The Sandwich Method (Modified)\n\n```markdown\nTraditional: Praise + Criticism + Praise (feels fake)\n\nBetter: Context + Specific Issue + Helpful Solution\n\nExample:\n\"I noticed the payment processing logic is inline in the\ncontroller. This makes it harder to test and reuse.\n\n[Specific Issue]\nThe calculateTotal() function mixes tax calculation,\ndiscount logic, and database queries, making it difficult\nto unit test and reason about.\n\n[Helpful Solution]\nCould we extract this into a PaymentService class? That\nwould make it testable and reusable. I can pair with you\non this if helpful.\"\n```\n\n### Handling Disagreements\n\n```markdown\nWhen author disagrees with your feedback:\n\n1. **Seek to Understand**\n   \"Help me understand your approach. What led you to\n    choose this pattern?\"\n\n2. **Acknowledge Valid Points**\n   \"That's a good point about X. I hadn't considered that.\"\n\n3. **Provide Data**\n   \"I'm concerned about performance. Can we add a benchmark\n    to validate the approach?\"\n\n4. **Escalate if Needed**\n   \"Let's get [architect/senior dev] to weigh in on this.\"\n\n5. **Know When to Let Go**\n   If it's working and not a critical issue, approve it.\n   Perfection is the enemy of progress.\n```\n\n## Best Practices\n\n1. **Review Promptly**: Within 24 hours, ideally same day\n2. **Limit PR Size**: 200-400 lines max for effective review\n3. **Review in Time Blocks**: 60 minutes max, take breaks\n4. **Use Review Tools**: GitHub, GitLab, or dedicated tools\n5. **Automate What You Can**: Linters, formatters, security scans\n6. **Build Rapport**: Emoji, praise, and empathy matter\n7. **Be Available**: Offer to pair on complex issues\n8. **Learn from Others**: Review others' review comments\n\n## Common Pitfalls\n\n- **Perfectionism**: Blocking PRs for minor style preferences\n- **Scope Creep**: \"While you're at it, can you also...\"\n- **Inconsistency**: Different standards for different people\n- **Delayed Reviews**: Letting PRs sit for days\n- **Ghosting**: Requesting changes then disappearing\n- **Rubber Stamping**: Approving without actually reviewing\n- **Bike Shedding**: Debating trivial details extensively\n\n## Templates\n\n### PR Review Comment Template\n\n```markdown\n## Summary\n[Brief overview of what was reviewed]\n\n## Strengths\n- [What was done well]\n- [Good patterns or approaches]\n\n## Required Changes\n\ud83d\udd34 [Blocking issue 1]\n\ud83d\udd34 [Blocking issue 2]\n\n## Suggestions\n\ud83d\udca1 [Improvement 1]\n\ud83d\udca1 [Improvement 2]\n\n## Questions\n\u2753 [Clarification needed on X]\n\u2753 [Alternative approach consideration]\n\n## Verdict\n\u2705 Approve after addressing required changes\n```\n\n## Resources\n\n- **references/code-review-best-practices.md**: Comprehensive review guidelines\n- **references/common-bugs-checklist.md**: Language-specific bugs to watch for\n- **references/security-review-guide.md**: Security-focused review checklist\n- **assets/pr-review-template.md**: Standard review comment template\n- **assets/review-checklist.md**: Quick reference checklist\n- **scripts/pr-analyzer.py**: Analyze PR complexity and suggest reviewers\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "e2e-testing-patterns",
      "description": "Master end-to-end testing with Playwright and Cypress to build reliable test suites that catch bugs, improve confidence, and enable fast deployment. Use when implementing E2E tests, debugging flaky tests, or establishing testing standards.",
      "plugin": "developer-essentials",
      "source_path": "plugins/developer-essentials/skills/e2e-testing-patterns/SKILL.md",
      "category": "development",
      "keywords": [
        "git",
        "sql",
        "debugging",
        "testing",
        "authentication",
        "code-review",
        "monorepo",
        "essential"
      ],
      "content": "---\nname: e2e-testing-patterns\ndescription: Master end-to-end testing with Playwright and Cypress to build reliable test suites that catch bugs, improve confidence, and enable fast deployment. Use when implementing E2E tests, debugging flaky tests, or establishing testing standards.\n---\n\n# E2E Testing Patterns\n\nBuild reliable, fast, and maintainable end-to-end test suites that provide confidence to ship code quickly and catch regressions before users do.\n\n## When to Use This Skill\n\n- Implementing end-to-end test automation\n- Debugging flaky or unreliable tests\n- Testing critical user workflows\n- Setting up CI/CD test pipelines\n- Testing across multiple browsers\n- Validating accessibility requirements\n- Testing responsive designs\n- Establishing E2E testing standards\n\n## Core Concepts\n\n### 1. E2E Testing Fundamentals\n\n**What to Test with E2E:**\n- Critical user journeys (login, checkout, signup)\n- Complex interactions (drag-and-drop, multi-step forms)\n- Cross-browser compatibility\n- Real API integration\n- Authentication flows\n\n**What NOT to Test with E2E:**\n- Unit-level logic (use unit tests)\n- API contracts (use integration tests)\n- Edge cases (too slow)\n- Internal implementation details\n\n### 2. Test Philosophy\n\n**The Testing Pyramid:**\n```\n        /\\\n       /E2E\\         \u2190 Few, focused on critical paths\n      /\u2500\u2500\u2500\u2500\u2500\\\n     /Integr\\        \u2190 More, test component interactions\n    /\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\\n   /Unit Tests\\      \u2190 Many, fast, isolated\n  /\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\\n```\n\n**Best Practices:**\n- Test user behavior, not implementation\n- Keep tests independent\n- Make tests deterministic\n- Optimize for speed\n- Use data-testid, not CSS selectors\n\n## Playwright Patterns\n\n### Setup and Configuration\n\n```typescript\n// playwright.config.ts\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n    testDir: './e2e',\n    timeout: 30000,\n    expect: {\n        timeout: 5000,\n    },\n    fullyParallel: true,\n    forbidOnly: !!process.env.CI,\n    retries: process.env.CI ? 2 : 0,\n    workers: process.env.CI ? 1 : undefined,\n    reporter: [\n        ['html'],\n        ['junit', { outputFile: 'results.xml' }],\n    ],\n    use: {\n        baseURL: 'http://localhost:3000',\n        trace: 'on-first-retry',\n        screenshot: 'only-on-failure',\n        video: 'retain-on-failure',\n    },\n    projects: [\n        { name: 'chromium', use: { ...devices['Desktop Chrome'] } },\n        { name: 'firefox', use: { ...devices['Desktop Firefox'] } },\n        { name: 'webkit', use: { ...devices['Desktop Safari'] } },\n        { name: 'mobile', use: { ...devices['iPhone 13'] } },\n    ],\n});\n```\n\n### Pattern 1: Page Object Model\n\n```typescript\n// pages/LoginPage.ts\nimport { Page, Locator } from '@playwright/test';\n\nexport class LoginPage {\n    readonly page: Page;\n    readonly emailInput: Locator;\n    readonly passwordInput: Locator;\n    readonly loginButton: Locator;\n    readonly errorMessage: Locator;\n\n    constructor(page: Page) {\n        this.page = page;\n        this.emailInput = page.getByLabel('Email');\n        this.passwordInput = page.getByLabel('Password');\n        this.loginButton = page.getByRole('button', { name: 'Login' });\n        this.errorMessage = page.getByRole('alert');\n    }\n\n    async goto() {\n        await this.page.goto('/login');\n    }\n\n    async login(email: string, password: string) {\n        await this.emailInput.fill(email);\n        await this.passwordInput.fill(password);\n        await this.loginButton.click();\n    }\n\n    async getErrorMessage(): Promise<string> {\n        return await this.errorMessage.textContent() ?? '';\n    }\n}\n\n// Test using Page Object\nimport { test, expect } from '@playwright/test';\nimport { LoginPage } from './pages/LoginPage';\n\ntest('successful login', async ({ page }) => {\n    const loginPage = new LoginPage(page);\n    await loginPage.goto();\n    await loginPage.login('user@example.com', 'password123');\n\n    await expect(page).toHaveURL('/dashboard');\n    await expect(page.getByRole('heading', { name: 'Dashboard' }))\n        .toBeVisible();\n});\n\ntest('failed login shows error', async ({ page }) => {\n    const loginPage = new LoginPage(page);\n    await loginPage.goto();\n    await loginPage.login('invalid@example.com', 'wrong');\n\n    const error = await loginPage.getErrorMessage();\n    expect(error).toContain('Invalid credentials');\n});\n```\n\n### Pattern 2: Fixtures for Test Data\n\n```typescript\n// fixtures/test-data.ts\nimport { test as base } from '@playwright/test';\n\ntype TestData = {\n    testUser: {\n        email: string;\n        password: string;\n        name: string;\n    };\n    adminUser: {\n        email: string;\n        password: string;\n    };\n};\n\nexport const test = base.extend<TestData>({\n    testUser: async ({}, use) => {\n        const user = {\n            email: `test-${Date.now()}@example.com`,\n            password: 'Test123!@#',\n            name: 'Test User',\n        };\n        // Setup: Create user in database\n        await createTestUser(user);\n        await use(user);\n        // Teardown: Clean up user\n        await deleteTestUser(user.email);\n    },\n\n    adminUser: async ({}, use) => {\n        await use({\n            email: 'admin@example.com',\n            password: process.env.ADMIN_PASSWORD!,\n        });\n    },\n});\n\n// Usage in tests\nimport { test } from './fixtures/test-data';\n\ntest('user can update profile', async ({ page, testUser }) => {\n    await page.goto('/login');\n    await page.getByLabel('Email').fill(testUser.email);\n    await page.getByLabel('Password').fill(testUser.password);\n    await page.getByRole('button', { name: 'Login' }).click();\n\n    await page.goto('/profile');\n    await page.getByLabel('Name').fill('Updated Name');\n    await page.getByRole('button', { name: 'Save' }).click();\n\n    await expect(page.getByText('Profile updated')).toBeVisible();\n});\n```\n\n### Pattern 3: Waiting Strategies\n\n```typescript\n// \u274c Bad: Fixed timeouts\nawait page.waitForTimeout(3000);  // Flaky!\n\n// \u2705 Good: Wait for specific conditions\nawait page.waitForLoadState('networkidle');\nawait page.waitForURL('/dashboard');\nawait page.waitForSelector('[data-testid=\"user-profile\"]');\n\n// \u2705 Better: Auto-waiting with assertions\nawait expect(page.getByText('Welcome')).toBeVisible();\nawait expect(page.getByRole('button', { name: 'Submit' }))\n    .toBeEnabled();\n\n// Wait for API response\nconst responsePromise = page.waitForResponse(\n    response => response.url().includes('/api/users') && response.status() === 200\n);\nawait page.getByRole('button', { name: 'Load Users' }).click();\nconst response = await responsePromise;\nconst data = await response.json();\nexpect(data.users).toHaveLength(10);\n\n// Wait for multiple conditions\nawait Promise.all([\n    page.waitForURL('/success'),\n    page.waitForLoadState('networkidle'),\n    expect(page.getByText('Payment successful')).toBeVisible(),\n]);\n```\n\n### Pattern 4: Network Mocking and Interception\n\n```typescript\n// Mock API responses\ntest('displays error when API fails', async ({ page }) => {\n    await page.route('**/api/users', route => {\n        route.fulfill({\n            status: 500,\n            contentType: 'application/json',\n            body: JSON.stringify({ error: 'Internal Server Error' }),\n        });\n    });\n\n    await page.goto('/users');\n    await expect(page.getByText('Failed to load users')).toBeVisible();\n});\n\n// Intercept and modify requests\ntest('can modify API request', async ({ page }) => {\n    await page.route('**/api/users', async route => {\n        const request = route.request();\n        const postData = JSON.parse(request.postData() || '{}');\n\n        // Modify request\n        postData.role = 'admin';\n\n        await route.continue({\n            postData: JSON.stringify(postData),\n        });\n    });\n\n    // Test continues...\n});\n\n// Mock third-party services\ntest('payment flow with mocked Stripe', async ({ page }) => {\n    await page.route('**/api/stripe/**', route => {\n        route.fulfill({\n            status: 200,\n            body: JSON.stringify({\n                id: 'mock_payment_id',\n                status: 'succeeded',\n            }),\n        });\n    });\n\n    // Test payment flow with mocked response\n});\n```\n\n## Cypress Patterns\n\n### Setup and Configuration\n\n```typescript\n// cypress.config.ts\nimport { defineConfig } from 'cypress';\n\nexport default defineConfig({\n    e2e: {\n        baseUrl: 'http://localhost:3000',\n        viewportWidth: 1280,\n        viewportHeight: 720,\n        video: false,\n        screenshotOnRunFailure: true,\n        defaultCommandTimeout: 10000,\n        requestTimeout: 10000,\n        setupNodeEvents(on, config) {\n            // Implement node event listeners\n        },\n    },\n});\n```\n\n### Pattern 1: Custom Commands\n\n```typescript\n// cypress/support/commands.ts\ndeclare global {\n    namespace Cypress {\n        interface Chainable {\n            login(email: string, password: string): Chainable<void>;\n            createUser(userData: UserData): Chainable<User>;\n            dataCy(value: string): Chainable<JQuery<HTMLElement>>;\n        }\n    }\n}\n\nCypress.Commands.add('login', (email: string, password: string) => {\n    cy.visit('/login');\n    cy.get('[data-testid=\"email\"]').type(email);\n    cy.get('[data-testid=\"password\"]').type(password);\n    cy.get('[data-testid=\"login-button\"]').click();\n    cy.url().should('include', '/dashboard');\n});\n\nCypress.Commands.add('createUser', (userData: UserData) => {\n    return cy.request('POST', '/api/users', userData)\n        .its('body');\n});\n\nCypress.Commands.add('dataCy', (value: string) => {\n    return cy.get(`[data-cy=\"${value}\"]`);\n});\n\n// Usage\ncy.login('user@example.com', 'password');\ncy.dataCy('submit-button').click();\n```\n\n### Pattern 2: Cypress Intercept\n\n```typescript\n// Mock API calls\ncy.intercept('GET', '/api/users', {\n    statusCode: 200,\n    body: [\n        { id: 1, name: 'John' },\n        { id: 2, name: 'Jane' },\n    ],\n}).as('getUsers');\n\ncy.visit('/users');\ncy.wait('@getUsers');\ncy.get('[data-testid=\"user-list\"]').children().should('have.length', 2);\n\n// Modify responses\ncy.intercept('GET', '/api/users', (req) => {\n    req.reply((res) => {\n        // Modify response\n        res.body.users = res.body.users.slice(0, 5);\n        res.send();\n    });\n});\n\n// Simulate slow network\ncy.intercept('GET', '/api/data', (req) => {\n    req.reply((res) => {\n        res.delay(3000);  // 3 second delay\n        res.send();\n    });\n});\n```\n\n## Advanced Patterns\n\n### Pattern 1: Visual Regression Testing\n\n```typescript\n// With Playwright\nimport { test, expect } from '@playwright/test';\n\ntest('homepage looks correct', async ({ page }) => {\n    await page.goto('/');\n    await expect(page).toHaveScreenshot('homepage.png', {\n        fullPage: true,\n        maxDiffPixels: 100,\n    });\n});\n\ntest('button in all states', async ({ page }) => {\n    await page.goto('/components');\n\n    const button = page.getByRole('button', { name: 'Submit' });\n\n    // Default state\n    await expect(button).toHaveScreenshot('button-default.png');\n\n    // Hover state\n    await button.hover();\n    await expect(button).toHaveScreenshot('button-hover.png');\n\n    // Disabled state\n    await button.evaluate(el => el.setAttribute('disabled', 'true'));\n    await expect(button).toHaveScreenshot('button-disabled.png');\n});\n```\n\n### Pattern 2: Parallel Testing with Sharding\n\n```typescript\n// playwright.config.ts\nexport default defineConfig({\n    projects: [\n        {\n            name: 'shard-1',\n            use: { ...devices['Desktop Chrome'] },\n            grepInvert: /@slow/,\n            shard: { current: 1, total: 4 },\n        },\n        {\n            name: 'shard-2',\n            use: { ...devices['Desktop Chrome'] },\n            shard: { current: 2, total: 4 },\n        },\n        // ... more shards\n    ],\n});\n\n// Run in CI\n// npx playwright test --shard=1/4\n// npx playwright test --shard=2/4\n```\n\n### Pattern 3: Accessibility Testing\n\n```typescript\n// Install: npm install @axe-core/playwright\nimport { test, expect } from '@playwright/test';\nimport AxeBuilder from '@axe-core/playwright';\n\ntest('page should not have accessibility violations', async ({ page }) => {\n    await page.goto('/');\n\n    const accessibilityScanResults = await new AxeBuilder({ page })\n        .exclude('#third-party-widget')\n        .analyze();\n\n    expect(accessibilityScanResults.violations).toEqual([]);\n});\n\ntest('form is accessible', async ({ page }) => {\n    await page.goto('/signup');\n\n    const results = await new AxeBuilder({ page })\n        .include('form')\n        .analyze();\n\n    expect(results.violations).toEqual([]);\n});\n```\n\n## Best Practices\n\n1. **Use Data Attributes**: `data-testid` or `data-cy` for stable selectors\n2. **Avoid Brittle Selectors**: Don't rely on CSS classes or DOM structure\n3. **Test User Behavior**: Click, type, see - not implementation details\n4. **Keep Tests Independent**: Each test should run in isolation\n5. **Clean Up Test Data**: Create and destroy test data in each test\n6. **Use Page Objects**: Encapsulate page logic\n7. **Meaningful Assertions**: Check actual user-visible behavior\n8. **Optimize for Speed**: Mock when possible, parallel execution\n\n```typescript\n// \u274c Bad selectors\ncy.get('.btn.btn-primary.submit-button').click();\ncy.get('div > form > div:nth-child(2) > input').type('text');\n\n// \u2705 Good selectors\ncy.getByRole('button', { name: 'Submit' }).click();\ncy.getByLabel('Email address').type('user@example.com');\ncy.get('[data-testid=\"email-input\"]').type('user@example.com');\n```\n\n## Common Pitfalls\n\n- **Flaky Tests**: Use proper waits, not fixed timeouts\n- **Slow Tests**: Mock external APIs, use parallel execution\n- **Over-Testing**: Don't test every edge case with E2E\n- **Coupled Tests**: Tests should not depend on each other\n- **Poor Selectors**: Avoid CSS classes and nth-child\n- **No Cleanup**: Clean up test data after each test\n- **Testing Implementation**: Test user behavior, not internals\n\n## Debugging Failing Tests\n\n```typescript\n// Playwright debugging\n// 1. Run in headed mode\nnpx playwright test --headed\n\n// 2. Run in debug mode\nnpx playwright test --debug\n\n// 3. Use trace viewer\nawait page.screenshot({ path: 'screenshot.png' });\nawait page.video()?.saveAs('video.webm');\n\n// 4. Add test.step for better reporting\ntest('checkout flow', async ({ page }) => {\n    await test.step('Add item to cart', async () => {\n        await page.goto('/products');\n        await page.getByRole('button', { name: 'Add to Cart' }).click();\n    });\n\n    await test.step('Proceed to checkout', async () => {\n        await page.goto('/cart');\n        await page.getByRole('button', { name: 'Checkout' }).click();\n    });\n});\n\n// 5. Inspect page state\nawait page.pause();  // Pauses execution, opens inspector\n```\n\n## Resources\n\n- **references/playwright-best-practices.md**: Playwright-specific patterns\n- **references/cypress-best-practices.md**: Cypress-specific patterns\n- **references/flaky-test-debugging.md**: Debugging unreliable tests\n- **assets/e2e-testing-checklist.md**: What to test with E2E\n- **assets/selector-strategies.md**: Finding reliable selectors\n- **scripts/test-analyzer.ts**: Analyze test flakiness and duration\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "auth-implementation-patterns",
      "description": "Master authentication and authorization patterns including JWT, OAuth2, session management, and RBAC to build secure, scalable access control systems. Use when implementing auth systems, securing APIs, or debugging security issues.",
      "plugin": "developer-essentials",
      "source_path": "plugins/developer-essentials/skills/auth-implementation-patterns/SKILL.md",
      "category": "development",
      "keywords": [
        "git",
        "sql",
        "debugging",
        "testing",
        "authentication",
        "code-review",
        "monorepo",
        "essential"
      ],
      "content": "---\nname: auth-implementation-patterns\ndescription: Master authentication and authorization patterns including JWT, OAuth2, session management, and RBAC to build secure, scalable access control systems. Use when implementing auth systems, securing APIs, or debugging security issues.\n---\n\n# Authentication & Authorization Implementation Patterns\n\nBuild secure, scalable authentication and authorization systems using industry-standard patterns and modern best practices.\n\n## When to Use This Skill\n\n- Implementing user authentication systems\n- Securing REST or GraphQL APIs\n- Adding OAuth2/social login\n- Implementing role-based access control (RBAC)\n- Designing session management\n- Migrating authentication systems\n- Debugging auth issues\n- Implementing SSO or multi-tenancy\n\n## Core Concepts\n\n### 1. Authentication vs Authorization\n\n**Authentication (AuthN)**: Who are you?\n- Verifying identity (username/password, OAuth, biometrics)\n- Issuing credentials (sessions, tokens)\n- Managing login/logout\n\n**Authorization (AuthZ)**: What can you do?\n- Permission checking\n- Role-based access control (RBAC)\n- Resource ownership validation\n- Policy enforcement\n\n### 2. Authentication Strategies\n\n**Session-Based:**\n- Server stores session state\n- Session ID in cookie\n- Traditional, simple, stateful\n\n**Token-Based (JWT):**\n- Stateless, self-contained\n- Scales horizontally\n- Can store claims\n\n**OAuth2/OpenID Connect:**\n- Delegate authentication\n- Social login (Google, GitHub)\n- Enterprise SSO\n\n## JWT Authentication\n\n### Pattern 1: JWT Implementation\n\n```typescript\n// JWT structure: header.payload.signature\nimport jwt from 'jsonwebtoken';\nimport { Request, Response, NextFunction } from 'express';\n\ninterface JWTPayload {\n    userId: string;\n    email: string;\n    role: string;\n    iat: number;\n    exp: number;\n}\n\n// Generate JWT\nfunction generateTokens(userId: string, email: string, role: string) {\n    const accessToken = jwt.sign(\n        { userId, email, role },\n        process.env.JWT_SECRET!,\n        { expiresIn: '15m' }  // Short-lived\n    );\n\n    const refreshToken = jwt.sign(\n        { userId },\n        process.env.JWT_REFRESH_SECRET!,\n        { expiresIn: '7d' }  // Long-lived\n    );\n\n    return { accessToken, refreshToken };\n}\n\n// Verify JWT\nfunction verifyToken(token: string): JWTPayload {\n    try {\n        return jwt.verify(token, process.env.JWT_SECRET!) as JWTPayload;\n    } catch (error) {\n        if (error instanceof jwt.TokenExpiredError) {\n            throw new Error('Token expired');\n        }\n        if (error instanceof jwt.JsonWebTokenError) {\n            throw new Error('Invalid token');\n        }\n        throw error;\n    }\n}\n\n// Middleware\nfunction authenticate(req: Request, res: Response, next: NextFunction) {\n    const authHeader = req.headers.authorization;\n    if (!authHeader?.startsWith('Bearer ')) {\n        return res.status(401).json({ error: 'No token provided' });\n    }\n\n    const token = authHeader.substring(7);\n    try {\n        const payload = verifyToken(token);\n        req.user = payload;  // Attach user to request\n        next();\n    } catch (error) {\n        return res.status(401).json({ error: 'Invalid token' });\n    }\n}\n\n// Usage\napp.get('/api/profile', authenticate, (req, res) => {\n    res.json({ user: req.user });\n});\n```\n\n### Pattern 2: Refresh Token Flow\n\n```typescript\ninterface StoredRefreshToken {\n    token: string;\n    userId: string;\n    expiresAt: Date;\n    createdAt: Date;\n}\n\nclass RefreshTokenService {\n    // Store refresh token in database\n    async storeRefreshToken(userId: string, refreshToken: string) {\n        const expiresAt = new Date(Date.now() + 7 * 24 * 60 * 60 * 1000);\n        await db.refreshTokens.create({\n            token: await hash(refreshToken),  // Hash before storing\n            userId,\n            expiresAt,\n        });\n    }\n\n    // Refresh access token\n    async refreshAccessToken(refreshToken: string) {\n        // Verify refresh token\n        let payload;\n        try {\n            payload = jwt.verify(\n                refreshToken,\n                process.env.JWT_REFRESH_SECRET!\n            ) as { userId: string };\n        } catch {\n            throw new Error('Invalid refresh token');\n        }\n\n        // Check if token exists in database\n        const storedToken = await db.refreshTokens.findOne({\n            where: {\n                token: await hash(refreshToken),\n                userId: payload.userId,\n                expiresAt: { $gt: new Date() },\n            },\n        });\n\n        if (!storedToken) {\n            throw new Error('Refresh token not found or expired');\n        }\n\n        // Get user\n        const user = await db.users.findById(payload.userId);\n        if (!user) {\n            throw new Error('User not found');\n        }\n\n        // Generate new access token\n        const accessToken = jwt.sign(\n            { userId: user.id, email: user.email, role: user.role },\n            process.env.JWT_SECRET!,\n            { expiresIn: '15m' }\n        );\n\n        return { accessToken };\n    }\n\n    // Revoke refresh token (logout)\n    async revokeRefreshToken(refreshToken: string) {\n        await db.refreshTokens.deleteOne({\n            token: await hash(refreshToken),\n        });\n    }\n\n    // Revoke all user tokens (logout all devices)\n    async revokeAllUserTokens(userId: string) {\n        await db.refreshTokens.deleteMany({ userId });\n    }\n}\n\n// API endpoints\napp.post('/api/auth/refresh', async (req, res) => {\n    const { refreshToken } = req.body;\n    try {\n        const { accessToken } = await refreshTokenService\n            .refreshAccessToken(refreshToken);\n        res.json({ accessToken });\n    } catch (error) {\n        res.status(401).json({ error: 'Invalid refresh token' });\n    }\n});\n\napp.post('/api/auth/logout', authenticate, async (req, res) => {\n    const { refreshToken } = req.body;\n    await refreshTokenService.revokeRefreshToken(refreshToken);\n    res.json({ message: 'Logged out successfully' });\n});\n```\n\n## Session-Based Authentication\n\n### Pattern 1: Express Session\n\n```typescript\nimport session from 'express-session';\nimport RedisStore from 'connect-redis';\nimport { createClient } from 'redis';\n\n// Setup Redis for session storage\nconst redisClient = createClient({\n    url: process.env.REDIS_URL,\n});\nawait redisClient.connect();\n\napp.use(\n    session({\n        store: new RedisStore({ client: redisClient }),\n        secret: process.env.SESSION_SECRET!,\n        resave: false,\n        saveUninitialized: false,\n        cookie: {\n            secure: process.env.NODE_ENV === 'production',  // HTTPS only\n            httpOnly: true,  // No JavaScript access\n            maxAge: 24 * 60 * 60 * 1000,  // 24 hours\n            sameSite: 'strict',  // CSRF protection\n        },\n    })\n);\n\n// Login\napp.post('/api/auth/login', async (req, res) => {\n    const { email, password } = req.body;\n\n    const user = await db.users.findOne({ email });\n    if (!user || !(await verifyPassword(password, user.passwordHash))) {\n        return res.status(401).json({ error: 'Invalid credentials' });\n    }\n\n    // Store user in session\n    req.session.userId = user.id;\n    req.session.role = user.role;\n\n    res.json({ user: { id: user.id, email: user.email, role: user.role } });\n});\n\n// Session middleware\nfunction requireAuth(req: Request, res: Response, next: NextFunction) {\n    if (!req.session.userId) {\n        return res.status(401).json({ error: 'Not authenticated' });\n    }\n    next();\n}\n\n// Protected route\napp.get('/api/profile', requireAuth, async (req, res) => {\n    const user = await db.users.findById(req.session.userId);\n    res.json({ user });\n});\n\n// Logout\napp.post('/api/auth/logout', (req, res) => {\n    req.session.destroy((err) => {\n        if (err) {\n            return res.status(500).json({ error: 'Logout failed' });\n        }\n        res.clearCookie('connect.sid');\n        res.json({ message: 'Logged out successfully' });\n    });\n});\n```\n\n## OAuth2 / Social Login\n\n### Pattern 1: OAuth2 with Passport.js\n\n```typescript\nimport passport from 'passport';\nimport { Strategy as GoogleStrategy } from 'passport-google-oauth20';\nimport { Strategy as GitHubStrategy } from 'passport-github2';\n\n// Google OAuth\npassport.use(\n    new GoogleStrategy(\n        {\n            clientID: process.env.GOOGLE_CLIENT_ID!,\n            clientSecret: process.env.GOOGLE_CLIENT_SECRET!,\n            callbackURL: '/api/auth/google/callback',\n        },\n        async (accessToken, refreshToken, profile, done) => {\n            try {\n                // Find or create user\n                let user = await db.users.findOne({\n                    googleId: profile.id,\n                });\n\n                if (!user) {\n                    user = await db.users.create({\n                        googleId: profile.id,\n                        email: profile.emails?.[0]?.value,\n                        name: profile.displayName,\n                        avatar: profile.photos?.[0]?.value,\n                    });\n                }\n\n                return done(null, user);\n            } catch (error) {\n                return done(error, undefined);\n            }\n        }\n    )\n);\n\n// Routes\napp.get('/api/auth/google', passport.authenticate('google', {\n    scope: ['profile', 'email'],\n}));\n\napp.get(\n    '/api/auth/google/callback',\n    passport.authenticate('google', { session: false }),\n    (req, res) => {\n        // Generate JWT\n        const tokens = generateTokens(req.user.id, req.user.email, req.user.role);\n        // Redirect to frontend with token\n        res.redirect(`${process.env.FRONTEND_URL}/auth/callback?token=${tokens.accessToken}`);\n    }\n);\n```\n\n## Authorization Patterns\n\n### Pattern 1: Role-Based Access Control (RBAC)\n\n```typescript\nenum Role {\n    USER = 'user',\n    MODERATOR = 'moderator',\n    ADMIN = 'admin',\n}\n\nconst roleHierarchy: Record<Role, Role[]> = {\n    [Role.ADMIN]: [Role.ADMIN, Role.MODERATOR, Role.USER],\n    [Role.MODERATOR]: [Role.MODERATOR, Role.USER],\n    [Role.USER]: [Role.USER],\n};\n\nfunction hasRole(userRole: Role, requiredRole: Role): boolean {\n    return roleHierarchy[userRole].includes(requiredRole);\n}\n\n// Middleware\nfunction requireRole(...roles: Role[]) {\n    return (req: Request, res: Response, next: NextFunction) => {\n        if (!req.user) {\n            return res.status(401).json({ error: 'Not authenticated' });\n        }\n\n        if (!roles.some(role => hasRole(req.user.role, role))) {\n            return res.status(403).json({ error: 'Insufficient permissions' });\n        }\n\n        next();\n    };\n}\n\n// Usage\napp.delete('/api/users/:id',\n    authenticate,\n    requireRole(Role.ADMIN),\n    async (req, res) => {\n        // Only admins can delete users\n        await db.users.delete(req.params.id);\n        res.json({ message: 'User deleted' });\n    }\n);\n```\n\n### Pattern 2: Permission-Based Access Control\n\n```typescript\nenum Permission {\n    READ_USERS = 'read:users',\n    WRITE_USERS = 'write:users',\n    DELETE_USERS = 'delete:users',\n    READ_POSTS = 'read:posts',\n    WRITE_POSTS = 'write:posts',\n}\n\nconst rolePermissions: Record<Role, Permission[]> = {\n    [Role.USER]: [Permission.READ_POSTS, Permission.WRITE_POSTS],\n    [Role.MODERATOR]: [\n        Permission.READ_POSTS,\n        Permission.WRITE_POSTS,\n        Permission.READ_USERS,\n    ],\n    [Role.ADMIN]: Object.values(Permission),\n};\n\nfunction hasPermission(userRole: Role, permission: Permission): boolean {\n    return rolePermissions[userRole]?.includes(permission) ?? false;\n}\n\nfunction requirePermission(...permissions: Permission[]) {\n    return (req: Request, res: Response, next: NextFunction) => {\n        if (!req.user) {\n            return res.status(401).json({ error: 'Not authenticated' });\n        }\n\n        const hasAllPermissions = permissions.every(permission =>\n            hasPermission(req.user.role, permission)\n        );\n\n        if (!hasAllPermissions) {\n            return res.status(403).json({ error: 'Insufficient permissions' });\n        }\n\n        next();\n    };\n}\n\n// Usage\napp.get('/api/users',\n    authenticate,\n    requirePermission(Permission.READ_USERS),\n    async (req, res) => {\n        const users = await db.users.findAll();\n        res.json({ users });\n    }\n);\n```\n\n### Pattern 3: Resource Ownership\n\n```typescript\n// Check if user owns resource\nasync function requireOwnership(\n    resourceType: 'post' | 'comment',\n    resourceIdParam: string = 'id'\n) {\n    return async (req: Request, res: Response, next: NextFunction) => {\n        if (!req.user) {\n            return res.status(401).json({ error: 'Not authenticated' });\n        }\n\n        const resourceId = req.params[resourceIdParam];\n\n        // Admins can access anything\n        if (req.user.role === Role.ADMIN) {\n            return next();\n        }\n\n        // Check ownership\n        let resource;\n        if (resourceType === 'post') {\n            resource = await db.posts.findById(resourceId);\n        } else if (resourceType === 'comment') {\n            resource = await db.comments.findById(resourceId);\n        }\n\n        if (!resource) {\n            return res.status(404).json({ error: 'Resource not found' });\n        }\n\n        if (resource.userId !== req.user.userId) {\n            return res.status(403).json({ error: 'Not authorized' });\n        }\n\n        next();\n    };\n}\n\n// Usage\napp.put('/api/posts/:id',\n    authenticate,\n    requireOwnership('post'),\n    async (req, res) => {\n        // User can only update their own posts\n        const post = await db.posts.update(req.params.id, req.body);\n        res.json({ post });\n    }\n);\n```\n\n## Security Best Practices\n\n### Pattern 1: Password Security\n\n```typescript\nimport bcrypt from 'bcrypt';\nimport { z } from 'zod';\n\n// Password validation schema\nconst passwordSchema = z.string()\n    .min(12, 'Password must be at least 12 characters')\n    .regex(/[A-Z]/, 'Password must contain uppercase letter')\n    .regex(/[a-z]/, 'Password must contain lowercase letter')\n    .regex(/[0-9]/, 'Password must contain number')\n    .regex(/[^A-Za-z0-9]/, 'Password must contain special character');\n\n// Hash password\nasync function hashPassword(password: string): Promise<string> {\n    const saltRounds = 12;  // 2^12 iterations\n    return bcrypt.hash(password, saltRounds);\n}\n\n// Verify password\nasync function verifyPassword(\n    password: string,\n    hash: string\n): Promise<boolean> {\n    return bcrypt.compare(password, hash);\n}\n\n// Registration with password validation\napp.post('/api/auth/register', async (req, res) => {\n    try {\n        const { email, password } = req.body;\n\n        // Validate password\n        passwordSchema.parse(password);\n\n        // Check if user exists\n        const existingUser = await db.users.findOne({ email });\n        if (existingUser) {\n            return res.status(400).json({ error: 'Email already registered' });\n        }\n\n        // Hash password\n        const passwordHash = await hashPassword(password);\n\n        // Create user\n        const user = await db.users.create({\n            email,\n            passwordHash,\n        });\n\n        // Generate tokens\n        const tokens = generateTokens(user.id, user.email, user.role);\n\n        res.status(201).json({\n            user: { id: user.id, email: user.email },\n            ...tokens,\n        });\n    } catch (error) {\n        if (error instanceof z.ZodError) {\n            return res.status(400).json({ error: error.errors[0].message });\n        }\n        res.status(500).json({ error: 'Registration failed' });\n    }\n});\n```\n\n### Pattern 2: Rate Limiting\n\n```typescript\nimport rateLimit from 'express-rate-limit';\nimport RedisStore from 'rate-limit-redis';\n\n// Login rate limiter\nconst loginLimiter = rateLimit({\n    store: new RedisStore({ client: redisClient }),\n    windowMs: 15 * 60 * 1000,  // 15 minutes\n    max: 5,  // 5 attempts\n    message: 'Too many login attempts, please try again later',\n    standardHeaders: true,\n    legacyHeaders: false,\n});\n\n// API rate limiter\nconst apiLimiter = rateLimit({\n    windowMs: 60 * 1000,  // 1 minute\n    max: 100,  // 100 requests per minute\n    standardHeaders: true,\n});\n\n// Apply to routes\napp.post('/api/auth/login', loginLimiter, async (req, res) => {\n    // Login logic\n});\n\napp.use('/api/', apiLimiter);\n```\n\n## Best Practices\n\n1. **Never Store Plain Passwords**: Always hash with bcrypt/argon2\n2. **Use HTTPS**: Encrypt data in transit\n3. **Short-Lived Access Tokens**: 15-30 minutes max\n4. **Secure Cookies**: httpOnly, secure, sameSite flags\n5. **Validate All Input**: Email format, password strength\n6. **Rate Limit Auth Endpoints**: Prevent brute force attacks\n7. **Implement CSRF Protection**: For session-based auth\n8. **Rotate Secrets Regularly**: JWT secrets, session secrets\n9. **Log Security Events**: Login attempts, failed auth\n10. **Use MFA When Possible**: Extra security layer\n\n## Common Pitfalls\n\n- **Weak Passwords**: Enforce strong password policies\n- **JWT in localStorage**: Vulnerable to XSS, use httpOnly cookies\n- **No Token Expiration**: Tokens should expire\n- **Client-Side Auth Checks Only**: Always validate server-side\n- **Insecure Password Reset**: Use secure tokens with expiration\n- **No Rate Limiting**: Vulnerable to brute force\n- **Trusting Client Data**: Always validate on server\n\n## Resources\n\n- **references/jwt-best-practices.md**: JWT implementation guide\n- **references/oauth2-flows.md**: OAuth2 flow diagrams and examples\n- **references/session-security.md**: Secure session management\n- **assets/auth-security-checklist.md**: Security review checklist\n- **assets/password-policy-template.md**: Password requirements template\n- **scripts/token-validator.ts**: JWT validation utility\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "debugging-strategies",
      "description": "Master systematic debugging techniques, profiling tools, and root cause analysis to efficiently track down bugs across any codebase or technology stack. Use when investigating bugs, performance issues, or unexpected behavior.",
      "plugin": "developer-essentials",
      "source_path": "plugins/developer-essentials/skills/debugging-strategies/SKILL.md",
      "category": "development",
      "keywords": [
        "git",
        "sql",
        "debugging",
        "testing",
        "authentication",
        "code-review",
        "monorepo",
        "essential"
      ],
      "content": "---\nname: debugging-strategies\ndescription: Master systematic debugging techniques, profiling tools, and root cause analysis to efficiently track down bugs across any codebase or technology stack. Use when investigating bugs, performance issues, or unexpected behavior.\n---\n\n# Debugging Strategies\n\nTransform debugging from frustrating guesswork into systematic problem-solving with proven strategies, powerful tools, and methodical approaches.\n\n## When to Use This Skill\n\n- Tracking down elusive bugs\n- Investigating performance issues\n- Understanding unfamiliar codebases\n- Debugging production issues\n- Analyzing crash dumps and stack traces\n- Profiling application performance\n- Investigating memory leaks\n- Debugging distributed systems\n\n## Core Principles\n\n### 1. The Scientific Method\n\n**1. Observe**: What's the actual behavior?\n**2. Hypothesize**: What could be causing it?\n**3. Experiment**: Test your hypothesis\n**4. Analyze**: Did it prove/disprove your theory?\n**5. Repeat**: Until you find the root cause\n\n### 2. Debugging Mindset\n\n**Don't Assume:**\n- \"It can't be X\" - Yes it can\n- \"I didn't change Y\" - Check anyway\n- \"It works on my machine\" - Find out why\n\n**Do:**\n- Reproduce consistently\n- Isolate the problem\n- Keep detailed notes\n- Question everything\n- Take breaks when stuck\n\n### 3. Rubber Duck Debugging\n\nExplain your code and problem out loud (to a rubber duck, colleague, or yourself). Often reveals the issue.\n\n## Systematic Debugging Process\n\n### Phase 1: Reproduce\n\n```markdown\n## Reproduction Checklist\n\n1. **Can you reproduce it?**\n   - Always? Sometimes? Randomly?\n   - Specific conditions needed?\n   - Can others reproduce it?\n\n2. **Create minimal reproduction**\n   - Simplify to smallest example\n   - Remove unrelated code\n   - Isolate the problem\n\n3. **Document steps**\n   - Write down exact steps\n   - Note environment details\n   - Capture error messages\n```\n\n### Phase 2: Gather Information\n\n```markdown\n## Information Collection\n\n1. **Error Messages**\n   - Full stack trace\n   - Error codes\n   - Console/log output\n\n2. **Environment**\n   - OS version\n   - Language/runtime version\n   - Dependencies versions\n   - Environment variables\n\n3. **Recent Changes**\n   - Git history\n   - Deployment timeline\n   - Configuration changes\n\n4. **Scope**\n   - Affects all users or specific ones?\n   - All browsers or specific ones?\n   - Production only or also dev?\n```\n\n### Phase 3: Form Hypothesis\n\n```markdown\n## Hypothesis Formation\n\nBased on gathered info, ask:\n\n1. **What changed?**\n   - Recent code changes\n   - Dependency updates\n   - Infrastructure changes\n\n2. **What's different?**\n   - Working vs broken environment\n   - Working vs broken user\n   - Before vs after\n\n3. **Where could this fail?**\n   - Input validation\n   - Business logic\n   - Data layer\n   - External services\n```\n\n### Phase 4: Test & Verify\n\n```markdown\n## Testing Strategies\n\n1. **Binary Search**\n   - Comment out half the code\n   - Narrow down problematic section\n   - Repeat until found\n\n2. **Add Logging**\n   - Strategic console.log/print\n   - Track variable values\n   - Trace execution flow\n\n3. **Isolate Components**\n   - Test each piece separately\n   - Mock dependencies\n   - Remove complexity\n\n4. **Compare Working vs Broken**\n   - Diff configurations\n   - Diff environments\n   - Diff data\n```\n\n## Debugging Tools\n\n### JavaScript/TypeScript Debugging\n\n```typescript\n// Chrome DevTools Debugger\nfunction processOrder(order: Order) {\n    debugger;  // Execution pauses here\n\n    const total = calculateTotal(order);\n    console.log('Total:', total);\n\n    // Conditional breakpoint\n    if (order.items.length > 10) {\n        debugger;  // Only breaks if condition true\n    }\n\n    return total;\n}\n\n// Console debugging techniques\nconsole.log('Value:', value);                    // Basic\nconsole.table(arrayOfObjects);                   // Table format\nconsole.time('operation'); /* code */ console.timeEnd('operation');  // Timing\nconsole.trace();                                 // Stack trace\nconsole.assert(value > 0, 'Value must be positive');  // Assertion\n\n// Performance profiling\nperformance.mark('start-operation');\n// ... operation code\nperformance.mark('end-operation');\nperformance.measure('operation', 'start-operation', 'end-operation');\nconsole.log(performance.getEntriesByType('measure'));\n```\n\n**VS Code Debugger Configuration:**\n```json\n// .vscode/launch.json\n{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"type\": \"node\",\n            \"request\": \"launch\",\n            \"name\": \"Debug Program\",\n            \"program\": \"${workspaceFolder}/src/index.ts\",\n            \"preLaunchTask\": \"tsc: build - tsconfig.json\",\n            \"outFiles\": [\"${workspaceFolder}/dist/**/*.js\"],\n            \"skipFiles\": [\"<node_internals>/**\"]\n        },\n        {\n            \"type\": \"node\",\n            \"request\": \"launch\",\n            \"name\": \"Debug Tests\",\n            \"program\": \"${workspaceFolder}/node_modules/jest/bin/jest\",\n            \"args\": [\"--runInBand\", \"--no-cache\"],\n            \"console\": \"integratedTerminal\"\n        }\n    ]\n}\n```\n\n### Python Debugging\n\n```python\n# Built-in debugger (pdb)\nimport pdb\n\ndef calculate_total(items):\n    total = 0\n    pdb.set_trace()  # Debugger starts here\n\n    for item in items:\n        total += item.price * item.quantity\n\n    return total\n\n# Breakpoint (Python 3.7+)\ndef process_order(order):\n    breakpoint()  # More convenient than pdb.set_trace()\n    # ... code\n\n# Post-mortem debugging\ntry:\n    risky_operation()\nexcept Exception:\n    import pdb\n    pdb.post_mortem()  # Debug at exception point\n\n# IPython debugging (ipdb)\nfrom ipdb import set_trace\nset_trace()  # Better interface than pdb\n\n# Logging for debugging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\ndef fetch_user(user_id):\n    logger.debug(f'Fetching user: {user_id}')\n    user = db.query(User).get(user_id)\n    logger.debug(f'Found user: {user}')\n    return user\n\n# Profile performance\nimport cProfile\nimport pstats\n\ncProfile.run('slow_function()', 'profile_stats')\nstats = pstats.Stats('profile_stats')\nstats.sort_stats('cumulative')\nstats.print_stats(10)  # Top 10 slowest\n```\n\n### Go Debugging\n\n```go\n// Delve debugger\n// Install: go install github.com/go-delve/delve/cmd/dlv@latest\n// Run: dlv debug main.go\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"runtime/debug\"\n)\n\n// Print stack trace\nfunc debugStack() {\n    debug.PrintStack()\n}\n\n// Panic recovery with debugging\nfunc processRequest() {\n    defer func() {\n        if r := recover(); r != nil {\n            fmt.Println(\"Panic:\", r)\n            debug.PrintStack()\n        }\n    }()\n\n    // ... code that might panic\n}\n\n// Memory profiling\nimport _ \"net/http/pprof\"\n// Visit http://localhost:6060/debug/pprof/\n\n// CPU profiling\nimport (\n    \"os\"\n    \"runtime/pprof\"\n)\n\nf, _ := os.Create(\"cpu.prof\")\npprof.StartCPUProfile(f)\ndefer pprof.StopCPUProfile()\n// ... code to profile\n```\n\n## Advanced Debugging Techniques\n\n### Technique 1: Binary Search Debugging\n\n```bash\n# Git bisect for finding regression\ngit bisect start\ngit bisect bad                    # Current commit is bad\ngit bisect good v1.0.0            # v1.0.0 was good\n\n# Git checks out middle commit\n# Test it, then:\ngit bisect good   # if it works\ngit bisect bad    # if it's broken\n\n# Continue until bug found\ngit bisect reset  # when done\n```\n\n### Technique 2: Differential Debugging\n\nCompare working vs broken:\n\n```markdown\n## What's Different?\n\n| Aspect       | Working         | Broken          |\n|--------------|-----------------|-----------------|\n| Environment  | Development     | Production      |\n| Node version | 18.16.0         | 18.15.0         |\n| Data         | Empty DB        | 1M records      |\n| User         | Admin           | Regular user    |\n| Browser      | Chrome          | Safari          |\n| Time         | During day      | After midnight  |\n\nHypothesis: Time-based issue? Check timezone handling.\n```\n\n### Technique 3: Trace Debugging\n\n```typescript\n// Function call tracing\nfunction trace(target: any, propertyKey: string, descriptor: PropertyDescriptor) {\n    const originalMethod = descriptor.value;\n\n    descriptor.value = function(...args: any[]) {\n        console.log(`Calling ${propertyKey} with args:`, args);\n        const result = originalMethod.apply(this, args);\n        console.log(`${propertyKey} returned:`, result);\n        return result;\n    };\n\n    return descriptor;\n}\n\nclass OrderService {\n    @trace\n    calculateTotal(items: Item[]): number {\n        return items.reduce((sum, item) => sum + item.price, 0);\n    }\n}\n```\n\n### Technique 4: Memory Leak Detection\n\n```typescript\n// Chrome DevTools Memory Profiler\n// 1. Take heap snapshot\n// 2. Perform action\n// 3. Take another snapshot\n// 4. Compare snapshots\n\n// Node.js memory debugging\nif (process.memoryUsage().heapUsed > 500 * 1024 * 1024) {\n    console.warn('High memory usage:', process.memoryUsage());\n\n    // Generate heap dump\n    require('v8').writeHeapSnapshot();\n}\n\n// Find memory leaks in tests\nlet beforeMemory: number;\n\nbeforeEach(() => {\n    beforeMemory = process.memoryUsage().heapUsed;\n});\n\nafterEach(() => {\n    const afterMemory = process.memoryUsage().heapUsed;\n    const diff = afterMemory - beforeMemory;\n\n    if (diff > 10 * 1024 * 1024) {  // 10MB threshold\n        console.warn(`Possible memory leak: ${diff / 1024 / 1024}MB`);\n    }\n});\n```\n\n## Debugging Patterns by Issue Type\n\n### Pattern 1: Intermittent Bugs\n\n```markdown\n## Strategies for Flaky Bugs\n\n1. **Add extensive logging**\n   - Log timing information\n   - Log all state transitions\n   - Log external interactions\n\n2. **Look for race conditions**\n   - Concurrent access to shared state\n   - Async operations completing out of order\n   - Missing synchronization\n\n3. **Check timing dependencies**\n   - setTimeout/setInterval\n   - Promise resolution order\n   - Animation frame timing\n\n4. **Stress test**\n   - Run many times\n   - Vary timing\n   - Simulate load\n```\n\n### Pattern 2: Performance Issues\n\n```markdown\n## Performance Debugging\n\n1. **Profile first**\n   - Don't optimize blindly\n   - Measure before and after\n   - Find bottlenecks\n\n2. **Common culprits**\n   - N+1 queries\n   - Unnecessary re-renders\n   - Large data processing\n   - Synchronous I/O\n\n3. **Tools**\n   - Browser DevTools Performance tab\n   - Lighthouse\n   - Python: cProfile, line_profiler\n   - Node: clinic.js, 0x\n```\n\n### Pattern 3: Production Bugs\n\n```markdown\n## Production Debugging\n\n1. **Gather evidence**\n   - Error tracking (Sentry, Bugsnag)\n   - Application logs\n   - User reports\n   - Metrics/monitoring\n\n2. **Reproduce locally**\n   - Use production data (anonymized)\n   - Match environment\n   - Follow exact steps\n\n3. **Safe investigation**\n   - Don't change production\n   - Use feature flags\n   - Add monitoring/logging\n   - Test fixes in staging\n```\n\n## Best Practices\n\n1. **Reproduce First**: Can't fix what you can't reproduce\n2. **Isolate the Problem**: Remove complexity until minimal case\n3. **Read Error Messages**: They're usually helpful\n4. **Check Recent Changes**: Most bugs are recent\n5. **Use Version Control**: Git bisect, blame, history\n6. **Take Breaks**: Fresh eyes see better\n7. **Document Findings**: Help future you\n8. **Fix Root Cause**: Not just symptoms\n\n## Common Debugging Mistakes\n\n- **Making Multiple Changes**: Change one thing at a time\n- **Not Reading Error Messages**: Read the full stack trace\n- **Assuming It's Complex**: Often it's simple\n- **Debug Logging in Prod**: Remove before shipping\n- **Not Using Debugger**: console.log isn't always best\n- **Giving Up Too Soon**: Persistence pays off\n- **Not Testing the Fix**: Verify it actually works\n\n## Quick Debugging Checklist\n\n```markdown\n## When Stuck, Check:\n\n- [ ] Spelling errors (typos in variable names)\n- [ ] Case sensitivity (fileName vs filename)\n- [ ] Null/undefined values\n- [ ] Array index off-by-one\n- [ ] Async timing (race conditions)\n- [ ] Scope issues (closure, hoisting)\n- [ ] Type mismatches\n- [ ] Missing dependencies\n- [ ] Environment variables\n- [ ] File paths (absolute vs relative)\n- [ ] Cache issues (clear cache)\n- [ ] Stale data (refresh database)\n```\n\n## Resources\n\n- **references/debugging-tools-guide.md**: Comprehensive tool documentation\n- **references/performance-profiling.md**: Performance debugging guide\n- **references/production-debugging.md**: Debugging live systems\n- **assets/debugging-checklist.md**: Quick reference checklist\n- **assets/common-bugs.md**: Common bug patterns\n- **scripts/debug-helper.ts**: Debugging utility functions\n",
      "references": {},
      "assets": {}
    },
    {
      "name": "monorepo-management",
      "description": "Master monorepo management with Turborepo, Nx, and pnpm workspaces to build efficient, scalable multi-package repositories with optimized builds and dependency management. Use when setting up monorepos, optimizing builds, or managing shared dependencies.",
      "plugin": "developer-essentials",
      "source_path": "plugins/developer-essentials/skills/monorepo-management/SKILL.md",
      "category": "development",
      "keywords": [
        "git",
        "sql",
        "debugging",
        "testing",
        "authentication",
        "code-review",
        "monorepo",
        "essential"
      ],
      "content": "---\nname: monorepo-management\ndescription: Master monorepo management with Turborepo, Nx, and pnpm workspaces to build efficient, scalable multi-package repositories with optimized builds and dependency management. Use when setting up monorepos, optimizing builds, or managing shared dependencies.\n---\n\n# Monorepo Management\n\nBuild efficient, scalable monorepos that enable code sharing, consistent tooling, and atomic changes across multiple packages and applications.\n\n## When to Use This Skill\n\n- Setting up new monorepo projects\n- Migrating from multi-repo to monorepo\n- Optimizing build and test performance\n- Managing shared dependencies\n- Implementing code sharing strategies\n- Setting up CI/CD for monorepos\n- Versioning and publishing packages\n- Debugging monorepo-specific issues\n\n## Core Concepts\n\n### 1. Why Monorepos?\n\n**Advantages:**\n- Shared code and dependencies\n- Atomic commits across projects\n- Consistent tooling and standards\n- Easier refactoring\n- Simplified dependency management\n- Better code visibility\n\n**Challenges:**\n- Build performance at scale\n- CI/CD complexity\n- Access control\n- Large Git repository\n\n### 2. Monorepo Tools\n\n**Package Managers:**\n- pnpm workspaces (recommended)\n- npm workspaces\n- Yarn workspaces\n\n**Build Systems:**\n- Turborepo (recommended for most)\n- Nx (feature-rich, complex)\n- Lerna (older, maintenance mode)\n\n## Turborepo Setup\n\n### Initial Setup\n\n```bash\n# Create new monorepo\nnpx create-turbo@latest my-monorepo\ncd my-monorepo\n\n# Structure:\n# apps/\n#   web/          - Next.js app\n#   docs/         - Documentation site\n# packages/\n#   ui/           - Shared UI components\n#   config/       - Shared configurations\n#   tsconfig/     - Shared TypeScript configs\n# turbo.json      - Turborepo configuration\n# package.json    - Root package.json\n```\n\n### Configuration\n\n```json\n// turbo.json\n{\n  \"$schema\": \"https://turbo.build/schema.json\",\n  \"globalDependencies\": [\"**/.env.*local\"],\n  \"pipeline\": {\n    \"build\": {\n      \"dependsOn\": [\"^build\"],\n      \"outputs\": [\"dist/**\", \".next/**\", \"!.next/cache/**\"]\n    },\n    \"test\": {\n      \"dependsOn\": [\"build\"],\n      \"outputs\": [\"coverage/**\"]\n    },\n    \"lint\": {\n      \"outputs\": []\n    },\n    \"dev\": {\n      \"cache\": false,\n      \"persistent\": true\n    },\n    \"type-check\": {\n      \"dependsOn\": [\"^build\"],\n      \"outputs\": []\n    }\n  }\n}\n```\n\n```json\n// package.json (root)\n{\n  \"name\": \"my-monorepo\",\n  \"private\": true,\n  \"workspaces\": [\n    \"apps/*\",\n    \"packages/*\"\n  ],\n  \"scripts\": {\n    \"build\": \"turbo run build\",\n    \"dev\": \"turbo run dev\",\n    \"test\": \"turbo run test\",\n    \"lint\": \"turbo run lint\",\n    \"format\": \"prettier --write \\\"**/*.{ts,tsx,md}\\\"\",\n    \"clean\": \"turbo run clean && rm -rf node_modules\"\n  },\n  \"devDependencies\": {\n    \"turbo\": \"^1.10.0\",\n    \"prettier\": \"^3.0.0\",\n    \"typescript\": \"^5.0.0\"\n  },\n  \"packageManager\": \"pnpm@8.0.0\"\n}\n```\n\n### Package Structure\n\n```json\n// packages/ui/package.json\n{\n  \"name\": \"@repo/ui\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"main\": \"./dist/index.js\",\n  \"types\": \"./dist/index.d.ts\",\n  \"exports\": {\n    \".\": {\n      \"import\": \"./dist/index.js\",\n      \"types\": \"./dist/index.d.ts\"\n    },\n    \"./button\": {\n      \"import\": \"./dist/button.js\",\n      \"types\": \"./dist/button.d.ts\"\n    }\n  },\n  \"scripts\": {\n    \"build\": \"tsup src/index.ts --format esm,cjs --dts\",\n    \"dev\": \"tsup src/index.ts --format esm,cjs --dts --watch\",\n    \"lint\": \"eslint src/\",\n    \"type-check\": \"tsc --noEmit\"\n  },\n  \"devDependencies\": {\n    \"@repo/tsconfig\": \"workspace:*\",\n    \"tsup\": \"^7.0.0\",\n    \"typescript\": \"^5.0.0\"\n  },\n  \"dependencies\": {\n    \"react\": \"^18.2.0\"\n  }\n}\n```\n\n## pnpm Workspaces\n\n### Setup\n\n```yaml\n# pnpm-workspace.yaml\npackages:\n  - 'apps/*'\n  - 'packages/*'\n  - 'tools/*'\n```\n\n```json\n// .npmrc\n# Hoist shared dependencies\nshamefully-hoist=true\n\n# Strict peer dependencies\nauto-install-peers=true\nstrict-peer-dependencies=true\n\n# Performance\nstore-dir=~/.pnpm-store\n```\n\n### Dependency Management\n\n```bash\n# Install dependency in specific package\npnpm add react --filter @repo/ui\npnpm add -D typescript --filter @repo/ui\n\n# Install workspace dependency\npnpm add @repo/ui --filter web\n\n# Install in all packages\npnpm add -D eslint -w\n\n# Update all dependencies\npnpm update -r\n\n# Remove dependency\npnpm remove react --filter @repo/ui\n```\n\n### Scripts\n\n```bash\n# Run script in specific package\npnpm --filter web dev\npnpm --filter @repo/ui build\n\n# Run in all packages\npnpm -r build\npnpm -r test\n\n# Run in parallel\npnpm -r --parallel dev\n\n# Filter by pattern\npnpm --filter \"@repo/*\" build\npnpm --filter \"...web\" build  # Build web and dependencies\n```\n\n## Nx Monorepo\n\n### Setup\n\n```bash\n# Create Nx monorepo\nnpx create-nx-workspace@latest my-org\n\n# Generate applications\nnx generate @nx/react:app my-app\nnx generate @nx/next:app my-next-app\n\n# Generate libraries\nnx generate @nx/react:lib ui-components\nnx generate @nx/js:lib utils\n```\n\n### Configuration\n\n```json\n// nx.json\n{\n  \"extends\": \"nx/presets/npm.json\",\n  \"$schema\": \"./node_modules/nx/schemas/nx-schema.json\",\n  \"targetDefaults\": {\n    \"build\": {\n      \"dependsOn\": [\"^build\"],\n      \"inputs\": [\"production\", \"^production\"],\n      \"cache\": true\n    },\n    \"test\": {\n      \"inputs\": [\"default\", \"^production\", \"{workspaceRoot}/jest.preset.js\"],\n      \"cache\": true\n    },\n    \"lint\": {\n      \"inputs\": [\"default\", \"{workspaceRoot}/.eslintrc.json\"],\n      \"cache\": true\n    }\n  },\n  \"namedInputs\": {\n    \"default\": [\"{projectRoot}/**/*\", \"sharedGlobals\"],\n    \"production\": [\n      \"default\",\n      \"!{projectRoot}/**/?(*.)+(spec|test).[jt]s?(x)?(.snap)\",\n      \"!{projectRoot}/tsconfig.spec.json\"\n    ],\n    \"sharedGlobals\": []\n  }\n}\n```\n\n### Running Tasks\n\n```bash\n# Run task for specific project\nnx build my-app\nnx test ui-components\nnx lint utils\n\n# Run for affected projects\nnx affected:build\nnx affected:test --base=main\n\n# Visualize dependencies\nnx graph\n\n# Run in parallel\nnx run-many --target=build --all --parallel=3\n```\n\n## Shared Configurations\n\n### TypeScript Configuration\n\n```json\n// packages/tsconfig/base.json\n{\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"bundler\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"incremental\": true,\n    \"declaration\": true\n  },\n  \"exclude\": [\"node_modules\"]\n}\n\n// packages/tsconfig/react.json\n{\n  \"extends\": \"./base.json\",\n  \"compilerOptions\": {\n    \"jsx\": \"react-jsx\",\n    \"lib\": [\"ES2022\", \"DOM\", \"DOM.Iterable\"]\n  }\n}\n\n// apps/web/tsconfig.json\n{\n  \"extends\": \"@repo/tsconfig/react.json\",\n  \"compilerOptions\": {\n    \"outDir\": \"dist\",\n    \"rootDir\": \"src\"\n  },\n  \"include\": [\"src\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n### ESLint Configuration\n\n```javascript\n// packages/config/eslint-preset.js\nmodule.exports = {\n  extends: [\n    'eslint:recommended',\n    'plugin:@typescript-eslint/recommended',\n    'plugin:react/recommended',\n    'plugin:react-hooks/recommended',\n    'prettier',\n  ],\n  plugins: ['@typescript-eslint', 'react', 'react-hooks'],\n  parser: '@typescript-eslint/parser',\n  parserOptions: {\n    ecmaVersion: 2022,\n    sourceType: 'module',\n    ecmaFeatures: {\n      jsx: true,\n    },\n  },\n  settings: {\n    react: {\n      version: 'detect',\n    },\n  },\n  rules: {\n    '@typescript-eslint/no-unused-vars': 'error',\n    'react/react-in-jsx-scope': 'off',\n  },\n};\n\n// apps/web/.eslintrc.js\nmodule.exports = {\n  extends: ['@repo/config/eslint-preset'],\n  rules: {\n    // App-specific rules\n  },\n};\n```\n\n## Code Sharing Patterns\n\n### Pattern 1: Shared UI Components\n\n```typescript\n// packages/ui/src/button.tsx\nimport * as React from 'react';\n\nexport interface ButtonProps {\n  variant?: 'primary' | 'secondary';\n  children: React.ReactNode;\n  onClick?: () => void;\n}\n\nexport function Button({ variant = 'primary', children, onClick }: ButtonProps) {\n  return (\n    <button\n      className={`btn btn-${variant}`}\n      onClick={onClick}\n    >\n      {children}\n    </button>\n  );\n}\n\n// packages/ui/src/index.ts\nexport { Button, type ButtonProps } from './button';\nexport { Input, type InputProps } from './input';\n\n// apps/web/src/app.tsx\nimport { Button } from '@repo/ui';\n\nexport function App() {\n  return <Button variant=\"primary\">Click me</Button>;\n}\n```\n\n### Pattern 2: Shared Utilities\n\n```typescript\n// packages/utils/src/string.ts\nexport function capitalize(str: string): string {\n  return str.charAt(0).toUpperCase() + str.slice(1);\n}\n\nexport function truncate(str: string, length: number): string {\n  return str.length > length ? str.slice(0, length) + '...' : str;\n}\n\n// packages/utils/src/index.ts\nexport * from './string';\nexport * from './array';\nexport * from './date';\n\n// Usage in apps\nimport { capitalize, truncate } from '@repo/utils';\n```\n\n### Pattern 3: Shared Types\n\n```typescript\n// packages/types/src/user.ts\nexport interface User {\n  id: string;\n  email: string;\n  name: string;\n  role: 'admin' | 'user';\n}\n\nexport interface CreateUserInput {\n  email: string;\n  name: string;\n  password: string;\n}\n\n// Used in both frontend and backend\nimport type { User, CreateUserInput } from '@repo/types';\n```\n\n## Build Optimization\n\n### Turborepo Caching\n\n```json\n// turbo.json\n{\n  \"pipeline\": {\n    \"build\": {\n      // Build depends on dependencies being built first\n      \"dependsOn\": [\"^build\"],\n\n      // Cache these outputs\n      \"outputs\": [\"dist/**\", \".next/**\"],\n\n      // Cache based on these inputs (default: all files)\n      \"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"package.json\"]\n    },\n    \"test\": {\n      // Run tests in parallel, don't depend on build\n      \"cache\": true,\n      \"outputs\": [\"coverage/**\"]\n    }\n  }\n}\n```\n\n### Remote Caching\n\n```bash\n# Turborepo Remote Cache (Vercel)\nnpx turbo login\nnpx turbo link\n\n# Custom remote cache\n# turbo.json\n{\n  \"remoteCache\": {\n    \"signature\": true,\n    \"enabled\": true\n  }\n}\n```\n\n## CI/CD for Monorepos\n\n### GitHub Actions\n\n```yaml\n# .github/workflows/ci.yml\nname: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 0  # For Nx affected commands\n\n      - uses: pnpm/action-setup@v2\n        with:\n          version: 8\n\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          cache: 'pnpm'\n\n      - name: Install dependencies\n        run: pnpm install --frozen-lockfile\n\n      - name: Build\n        run: pnpm turbo run build\n\n      - name: Test\n        run: pnpm turbo run test\n\n      - name: Lint\n        run: pnpm turbo run lint\n\n      - name: Type check\n        run: pnpm turbo run type-check\n```\n\n### Deploy Affected Only\n\n```yaml\n# Deploy only changed apps\n- name: Deploy affected apps\n  run: |\n    if pnpm nx affected:apps --base=origin/main --head=HEAD | grep -q \"web\"; then\n      echo \"Deploying web app\"\n      pnpm --filter web deploy\n    fi\n```\n\n## Best Practices\n\n1. **Consistent Versioning**: Lock dependency versions across workspace\n2. **Shared Configs**: Centralize ESLint, TypeScript, Prettier configs\n3. **Dependency Graph**: Keep it acyclic, avoid circular dependencies\n4. **Cache Effectively**: Configure inputs/outputs correctly\n5. **Type Safety**: Share types between frontend/backend\n6. **Testing Strategy**: Unit tests in packages, E2E in apps\n7. **Documentation**: README in each package\n8. **Release Strategy**: Use changesets for versioning\n\n## Common Pitfalls\n\n- **Circular Dependencies**: A depends on B, B depends on A\n- **Phantom Dependencies**: Using deps not in package.json\n- **Incorrect Cache Inputs**: Missing files in Turborepo inputs\n- **Over-Sharing**: Sharing code that should be separate\n- **Under-Sharing**: Duplicating code across packages\n- **Large Monorepos**: Without proper tooling, builds slow down\n\n## Publishing Packages\n\n```bash\n# Using Changesets\npnpm add -Dw @changesets/cli\npnpm changeset init\n\n# Create changeset\npnpm changeset\n\n# Version packages\npnpm changeset version\n\n# Publish\npnpm changeset publish\n```\n\n```yaml\n# .github/workflows/release.yml\n- name: Create Release Pull Request or Publish\n  uses: changesets/action@v1\n  with:\n    publish: pnpm release\n  env:\n    GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n    NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n```\n\n## Resources\n\n- **references/turborepo-guide.md**: Comprehensive Turborepo documentation\n- **references/nx-guide.md**: Nx monorepo patterns\n- **references/pnpm-workspaces.md**: pnpm workspace features\n- **assets/monorepo-checklist.md**: Setup checklist\n- **assets/migration-guide.md**: Multi-repo to monorepo migration\n- **scripts/dependency-graph.ts**: Visualize package dependencies\n",
      "references": {},
      "assets": {}
    }
  ]
}