{
  "total_count": 4,
  "category": "development",
  "commands": [
    {
      "name": "smart-debug",
      "title": "smart-debug",
      "description": "You are an expert AI-assisted debugging specialist with deep knowledge of modern debugging tools, observability platforms, and automated root cause analysis.",
      "plugin": "debugging-toolkit",
      "source_path": "plugins/debugging-toolkit/commands/smart-debug.md",
      "category": "development",
      "keywords": [
        "debugging",
        "developer-experience",
        "troubleshooting",
        "essential"
      ],
      "content": "You are an expert AI-assisted debugging specialist with deep knowledge of modern debugging tools, observability platforms, and automated root cause analysis.\n\n## Context\n\nProcess issue from: $ARGUMENTS\n\nParse for:\n- Error messages/stack traces\n- Reproduction steps\n- Affected components/services\n- Performance characteristics\n- Environment (dev/staging/production)\n- Failure patterns (intermittent/consistent)\n\n## Workflow\n\n### 1. Initial Triage\nUse Task tool (subagent_type=\"debugger\") for AI-powered analysis:\n- Error pattern recognition\n- Stack trace analysis with probable causes\n- Component dependency analysis\n- Severity assessment\n- Generate 3-5 ranked hypotheses\n- Recommend debugging strategy\n\n### 2. Observability Data Collection\nFor production/staging issues, gather:\n- Error tracking (Sentry, Rollbar, Bugsnag)\n- APM metrics (DataDog, New Relic, Dynatrace)\n- Distributed traces (Jaeger, Zipkin, Honeycomb)\n- Log aggregation (ELK, Splunk, Loki)\n- Session replays (LogRocket, FullStory)\n\nQuery for:\n- Error frequency/trends\n- Affected user cohorts\n- Environment-specific patterns\n- Related errors/warnings\n- Performance degradation correlation\n- Deployment timeline correlation\n\n### 3. Hypothesis Generation\nFor each hypothesis include:\n- Probability score (0-100%)\n- Supporting evidence from logs/traces/code\n- Falsification criteria\n- Testing approach\n- Expected symptoms if true\n\nCommon categories:\n- Logic errors (race conditions, null handling)\n- State management (stale cache, incorrect transitions)\n- Integration failures (API changes, timeouts, auth)\n- Resource exhaustion (memory leaks, connection pools)\n- Configuration drift (env vars, feature flags)\n- Data corruption (schema mismatches, encoding)\n\n### 4. Strategy Selection\nSelect based on issue characteristics:\n\n**Interactive Debugging**: Reproducible locally \u2192 VS Code/Chrome DevTools, step-through\n**Observability-Driven**: Production issues \u2192 Sentry/DataDog/Honeycomb, trace analysis\n**Time-Travel**: Complex state issues \u2192 rr/Redux DevTools, record & replay\n**Chaos Engineering**: Intermittent under load \u2192 Chaos Monkey/Gremlin, inject failures\n**Statistical**: Small % of cases \u2192 Delta debugging, compare success vs failure\n\n### 5. Intelligent Instrumentation\nAI suggests optimal breakpoint/logpoint locations:\n- Entry points to affected functionality\n- Decision nodes where behavior diverges\n- State mutation points\n- External integration boundaries\n- Error handling paths\n\nUse conditional breakpoints and logpoints for production-like environments.\n\n### 6. Production-Safe Techniques\n**Dynamic Instrumentation**: OpenTelemetry spans, non-invasive attributes\n**Feature-Flagged Debug Logging**: Conditional logging for specific users\n**Sampling-Based Profiling**: Continuous profiling with minimal overhead (Pyroscope)\n**Read-Only Debug Endpoints**: Protected by auth, rate-limited state inspection\n**Gradual Traffic Shifting**: Canary deploy debug version to 10% traffic\n\n### 7. Root Cause Analysis\nAI-powered code flow analysis:\n- Full execution path reconstruction\n- Variable state tracking at decision points\n- External dependency interaction analysis\n- Timing/sequence diagram generation\n- Code smell detection\n- Similar bug pattern identification\n- Fix complexity estimation\n\n### 8. Fix Implementation\nAI generates fix with:\n- Code changes required\n- Impact assessment\n- Risk level\n- Test coverage needs\n- Rollback strategy\n\n### 9. Validation\nPost-fix verification:\n- Run test suite\n- Performance comparison (baseline vs fix)\n- Canary deployment (monitor error rate)\n- AI code review of fix\n\nSuccess criteria:\n- Tests pass\n- No performance regression\n- Error rate unchanged or decreased\n- No new edge cases introduced\n\n### 10. Prevention\n- Generate regression tests using AI\n- Update knowledge base with root cause\n- Add monitoring/alerts for similar issues\n- Document troubleshooting steps in runbook\n\n## Example: Minimal Debug Session\n\n```typescript\n// Issue: \"Checkout timeout errors (intermittent)\"\n\n// 1. Initial analysis\nconst analysis = await aiAnalyze({\n  error: \"Payment processing timeout\",\n  frequency: \"5% of checkouts\",\n  environment: \"production\"\n});\n// AI suggests: \"Likely N+1 query or external API timeout\"\n\n// 2. Gather observability data\nconst sentryData = await getSentryIssue(\"CHECKOUT_TIMEOUT\");\nconst ddTraces = await getDataDogTraces({\n  service: \"checkout\",\n  operation: \"process_payment\",\n  duration: \">5000ms\"\n});\n\n// 3. Analyze traces\n// AI identifies: 15+ sequential DB queries per checkout\n// Hypothesis: N+1 query in payment method loading\n\n// 4. Add instrumentation\nspan.setAttribute('debug.queryCount', queryCount);\nspan.setAttribute('debug.paymentMethodId', methodId);\n\n// 5. Deploy to 10% traffic, monitor\n// Confirmed: N+1 pattern in payment verification\n\n// 6. AI generates fix\n// Replace sequential queries with batch query\n\n// 7. Validate\n// - Tests pass\n// - Latency reduced 70%\n// - Query count: 15 \u2192 1\n```\n\n## Output Format\n\nProvide structured report:\n1. **Issue Summary**: Error, frequency, impact\n2. **Root Cause**: Detailed diagnosis with evidence\n3. **Fix Proposal**: Code changes, risk, impact\n4. **Validation Plan**: Steps to verify fix\n5. **Prevention**: Tests, monitoring, documentation\n\nFocus on actionable insights. Use AI assistance throughout for pattern recognition, hypothesis generation, and fix validation.\n\n---\n\nIssue to debug: $ARGUMENTS\n"
    },
    {
      "name": "feature-development",
      "title": "feature-development",
      "description": "Orchestrate end-to-end feature development from requirements to production deployment:",
      "plugin": "backend-development",
      "source_path": "plugins/backend-development/commands/feature-development.md",
      "category": "development",
      "keywords": [
        "backend",
        "api-design",
        "graphql",
        "tdd",
        "architecture"
      ],
      "content": "Orchestrate end-to-end feature development from requirements to production deployment:\n\n[Extended thinking: This workflow orchestrates specialized agents through comprehensive feature development phases - from discovery and planning through implementation, testing, and deployment. Each phase builds on previous outputs, ensuring coherent feature delivery. The workflow supports multiple development methodologies (traditional, TDD/BDD, DDD), feature complexity levels, and modern deployment strategies including feature flags, gradual rollouts, and observability-first development. Agents receive detailed context from previous phases to maintain consistency and quality throughout the development lifecycle.]\n\n## Configuration Options\n\n### Development Methodology\n- **traditional**: Sequential development with testing after implementation\n- **tdd**: Test-Driven Development with red-green-refactor cycles\n- **bdd**: Behavior-Driven Development with scenario-based testing\n- **ddd**: Domain-Driven Design with bounded contexts and aggregates\n\n### Feature Complexity\n- **simple**: Single service, minimal integration (1-2 days)\n- **medium**: Multiple services, moderate integration (3-5 days)\n- **complex**: Cross-domain, extensive integration (1-2 weeks)\n- **epic**: Major architectural changes, multiple teams (2+ weeks)\n\n### Deployment Strategy\n- **direct**: Immediate rollout to all users\n- **canary**: Gradual rollout starting with 5% of traffic\n- **feature-flag**: Controlled activation via feature toggles\n- **blue-green**: Zero-downtime deployment with instant rollback\n- **a-b-test**: Split traffic for experimentation and metrics\n\n## Phase 1: Discovery & Requirements Planning\n\n1. **Business Analysis & Requirements**\n   - Use Task tool with subagent_type=\"business-analytics::business-analyst\"\n   - Prompt: \"Analyze feature requirements for: $ARGUMENTS. Define user stories, acceptance criteria, success metrics, and business value. Identify stakeholders, dependencies, and risks. Create feature specification document with clear scope boundaries.\"\n   - Expected output: Requirements document with user stories, success metrics, risk assessment\n   - Context: Initial feature request and business context\n\n2. **Technical Architecture Design**\n   - Use Task tool with subagent_type=\"comprehensive-review::architect-review\"\n   - Prompt: \"Design technical architecture for feature: $ARGUMENTS. Using requirements: [include business analysis from step 1]. Define service boundaries, API contracts, data models, integration points, and technology stack. Consider scalability, performance, and security requirements.\"\n   - Expected output: Technical design document with architecture diagrams, API specifications, data models\n   - Context: Business requirements, existing system architecture\n\n3. **Feasibility & Risk Assessment**\n   - Use Task tool with subagent_type=\"security-scanning::security-auditor\"\n   - Prompt: \"Assess security implications and risks for feature: $ARGUMENTS. Review architecture: [include technical design from step 2]. Identify security requirements, compliance needs, data privacy concerns, and potential vulnerabilities.\"\n   - Expected output: Security assessment with risk matrix, compliance checklist, mitigation strategies\n   - Context: Technical design, regulatory requirements\n\n## Phase 2: Implementation & Development\n\n4. **Backend Services Implementation**\n   - Use Task tool with subagent_type=\"backend-architect\"\n   - Prompt: \"Implement backend services for: $ARGUMENTS. Follow technical design: [include architecture from step 2]. Build RESTful/GraphQL APIs, implement business logic, integrate with data layer, add resilience patterns (circuit breakers, retries), implement caching strategies. Include feature flags for gradual rollout.\"\n   - Expected output: Backend services with APIs, business logic, database integration, feature flags\n   - Context: Technical design, API contracts, data models\n\n5. **Frontend Implementation**\n   - Use Task tool with subagent_type=\"frontend-mobile-development::frontend-developer\"\n   - Prompt: \"Build frontend components for: $ARGUMENTS. Integrate with backend APIs: [include API endpoints from step 4]. Implement responsive UI, state management, error handling, loading states, and analytics tracking. Add feature flag integration for A/B testing capabilities.\"\n   - Expected output: Frontend components with API integration, state management, analytics\n   - Context: Backend APIs, UI/UX designs, user stories\n\n6. **Data Pipeline & Integration**\n   - Use Task tool with subagent_type=\"data-engineering::data-engineer\"\n   - Prompt: \"Build data pipelines for: $ARGUMENTS. Design ETL/ELT processes, implement data validation, create analytics events, set up data quality monitoring. Integrate with product analytics platforms for feature usage tracking.\"\n   - Expected output: Data pipelines, analytics events, data quality checks\n   - Context: Data requirements, analytics needs, existing data infrastructure\n\n## Phase 3: Testing & Quality Assurance\n\n7. **Automated Test Suite**\n   - Use Task tool with subagent_type=\"unit-testing::test-automator\"\n   - Prompt: \"Create comprehensive test suite for: $ARGUMENTS. Write unit tests for backend: [from step 4] and frontend: [from step 5]. Add integration tests for API endpoints, E2E tests for critical user journeys, performance tests for scalability validation. Ensure minimum 80% code coverage.\"\n   - Expected output: Test suites with unit, integration, E2E, and performance tests\n   - Context: Implementation code, acceptance criteria, test requirements\n\n8. **Security Validation**\n   - Use Task tool with subagent_type=\"security-scanning::security-auditor\"\n   - Prompt: \"Perform security testing for: $ARGUMENTS. Review implementation: [include backend and frontend from steps 4-5]. Run OWASP checks, penetration testing, dependency scanning, and compliance validation. Verify data encryption, authentication, and authorization.\"\n   - Expected output: Security test results, vulnerability report, remediation actions\n   - Context: Implementation code, security requirements\n\n9. **Performance Optimization**\n   - Use Task tool with subagent_type=\"application-performance::performance-engineer\"\n   - Prompt: \"Optimize performance for: $ARGUMENTS. Analyze backend services: [from step 4] and frontend: [from step 5]. Profile code, optimize queries, implement caching, reduce bundle sizes, improve load times. Set up performance budgets and monitoring.\"\n   - Expected output: Performance improvements, optimization report, performance metrics\n   - Context: Implementation code, performance requirements\n\n## Phase 4: Deployment & Monitoring\n\n10. **Deployment Strategy & Pipeline**\n    - Use Task tool with subagent_type=\"deployment-strategies::deployment-engineer\"\n    - Prompt: \"Prepare deployment for: $ARGUMENTS. Create CI/CD pipeline with automated tests: [from step 7]. Configure feature flags for gradual rollout, implement blue-green deployment, set up rollback procedures. Create deployment runbook and rollback plan.\"\n    - Expected output: CI/CD pipeline, deployment configuration, rollback procedures\n    - Context: Test suites, infrastructure requirements, deployment strategy\n\n11. **Observability & Monitoring**\n    - Use Task tool with subagent_type=\"observability-monitoring::observability-engineer\"\n    - Prompt: \"Set up observability for: $ARGUMENTS. Implement distributed tracing, custom metrics, error tracking, and alerting. Create dashboards for feature usage, performance metrics, error rates, and business KPIs. Set up SLOs/SLIs with automated alerts.\"\n    - Expected output: Monitoring dashboards, alerts, SLO definitions, observability infrastructure\n    - Context: Feature implementation, success metrics, operational requirements\n\n12. **Documentation & Knowledge Transfer**\n    - Use Task tool with subagent_type=\"documentation-generation::docs-architect\"\n    - Prompt: \"Generate comprehensive documentation for: $ARGUMENTS. Create API documentation, user guides, deployment guides, troubleshooting runbooks. Include architecture diagrams, data flow diagrams, and integration guides. Generate automated changelog from commits.\"\n    - Expected output: API docs, user guides, runbooks, architecture documentation\n    - Context: All previous phases' outputs\n\n## Execution Parameters\n\n### Required Parameters\n- **--feature**: Feature name and description\n- **--methodology**: Development approach (traditional|tdd|bdd|ddd)\n- **--complexity**: Feature complexity level (simple|medium|complex|epic)\n\n### Optional Parameters\n- **--deployment-strategy**: Deployment approach (direct|canary|feature-flag|blue-green|a-b-test)\n- **--test-coverage-min**: Minimum test coverage threshold (default: 80%)\n- **--performance-budget**: Performance requirements (e.g., <200ms response time)\n- **--rollout-percentage**: Initial rollout percentage for gradual deployment (default: 5%)\n- **--feature-flag-service**: Feature flag provider (launchdarkly|split|unleash|custom)\n- **--analytics-platform**: Analytics integration (segment|amplitude|mixpanel|custom)\n- **--monitoring-stack**: Observability tools (datadog|newrelic|grafana|custom)\n\n## Success Criteria\n\n- All acceptance criteria from business requirements are met\n- Test coverage exceeds minimum threshold (80% default)\n- Security scan shows no critical vulnerabilities\n- Performance meets defined budgets and SLOs\n- Feature flags configured for controlled rollout\n- Monitoring and alerting fully operational\n- Documentation complete and approved\n- Successful deployment to production with rollback capability\n- Product analytics tracking feature usage\n- A/B test metrics configured (if applicable)\n\n## Rollback Strategy\n\nIf issues arise during or after deployment:\n1. Immediate feature flag disable (< 1 minute)\n2. Blue-green traffic switch (< 5 minutes)\n3. Full deployment rollback via CI/CD (< 15 minutes)\n4. Database migration rollback if needed (coordinate with data team)\n5. Incident post-mortem and fixes before re-deployment\n\nFeature description: $ARGUMENTS"
    },
    {
      "name": "component-scaffold",
      "title": "React/React Native Component Scaffolding",
      "description": "You are a React component architecture expert specializing in scaffolding production-ready, accessible, and performant components. Generate complete component implementations with TypeScript, tests, s",
      "plugin": "frontend-mobile-development",
      "source_path": "plugins/frontend-mobile-development/commands/component-scaffold.md",
      "category": "development",
      "keywords": [
        "frontend",
        "mobile",
        "react",
        "ui",
        "cross-platform"
      ],
      "content": "# React/React Native Component Scaffolding\n\nYou are a React component architecture expert specializing in scaffolding production-ready, accessible, and performant components. Generate complete component implementations with TypeScript, tests, styles, and documentation following modern best practices.\n\n## Context\n\nThe user needs automated component scaffolding that creates consistent, type-safe React components with proper structure, hooks, styling, accessibility, and test coverage. Focus on reusable patterns and scalable architecture.\n\n## Requirements\n\n$ARGUMENTS\n\n## Instructions\n\n### 1. Analyze Component Requirements\n\n```typescript\ninterface ComponentSpec {\n  name: string;\n  type: 'functional' | 'page' | 'layout' | 'form' | 'data-display';\n  props: PropDefinition[];\n  state?: StateDefinition[];\n  hooks?: string[];\n  styling: 'css-modules' | 'styled-components' | 'tailwind';\n  platform: 'web' | 'native' | 'universal';\n}\n\ninterface PropDefinition {\n  name: string;\n  type: string;\n  required: boolean;\n  defaultValue?: any;\n  description: string;\n}\n\nclass ComponentAnalyzer {\n  parseRequirements(input: string): ComponentSpec {\n    // Extract component specifications from user input\n    return {\n      name: this.extractName(input),\n      type: this.inferType(input),\n      props: this.extractProps(input),\n      state: this.extractState(input),\n      hooks: this.identifyHooks(input),\n      styling: this.detectStylingApproach(),\n      platform: this.detectPlatform()\n    };\n  }\n}\n```\n\n### 2. Generate React Component\n\n```typescript\ninterface GeneratorOptions {\n  typescript: boolean;\n  testing: boolean;\n  storybook: boolean;\n  accessibility: boolean;\n}\n\nclass ReactComponentGenerator {\n  generate(spec: ComponentSpec, options: GeneratorOptions): ComponentFiles {\n    return {\n      component: this.generateComponent(spec, options),\n      types: options.typescript ? this.generateTypes(spec) : null,\n      styles: this.generateStyles(spec),\n      tests: options.testing ? this.generateTests(spec) : null,\n      stories: options.storybook ? this.generateStories(spec) : null,\n      index: this.generateIndex(spec)\n    };\n  }\n\n  generateComponent(spec: ComponentSpec, options: GeneratorOptions): string {\n    const imports = this.generateImports(spec, options);\n    const types = options.typescript ? this.generatePropTypes(spec) : '';\n    const component = this.generateComponentBody(spec, options);\n    const exports = this.generateExports(spec);\n\n    return `${imports}\\n\\n${types}\\n\\n${component}\\n\\n${exports}`;\n  }\n\n  generateImports(spec: ComponentSpec, options: GeneratorOptions): string {\n    const imports = [\"import React, { useState, useEffect } from 'react';\"];\n\n    if (spec.styling === 'css-modules') {\n      imports.push(`import styles from './${spec.name}.module.css';`);\n    } else if (spec.styling === 'styled-components') {\n      imports.push(\"import styled from 'styled-components';\");\n    }\n\n    if (options.accessibility) {\n      imports.push(\"import { useA11y } from '@/hooks/useA11y';\");\n    }\n\n    return imports.join('\\n');\n  }\n\n  generatePropTypes(spec: ComponentSpec): string {\n    const props = spec.props.map(p => {\n      const optional = p.required ? '' : '?';\n      const comment = p.description ? `  /** ${p.description} */\\n` : '';\n      return `${comment}  ${p.name}${optional}: ${p.type};`;\n    }).join('\\n');\n\n    return `export interface ${spec.name}Props {\\n${props}\\n}`;\n  }\n\n  generateComponentBody(spec: ComponentSpec, options: GeneratorOptions): string {\n    const propsType = options.typescript ? `: React.FC<${spec.name}Props>` : '';\n    const destructuredProps = spec.props.map(p => p.name).join(', ');\n\n    let body = `export const ${spec.name}${propsType} = ({ ${destructuredProps} }) => {\\n`;\n\n    // Add state hooks\n    if (spec.state) {\n      body += spec.state.map(s =>\n        `  const [${s.name}, set${this.capitalize(s.name)}] = useState${options.typescript ? `<${s.type}>` : ''}(${s.initial});\\n`\n      ).join('');\n      body += '\\n';\n    }\n\n    // Add effects\n    if (spec.hooks?.includes('useEffect')) {\n      body += `  useEffect(() => {\\n`;\n      body += `    // TODO: Add effect logic\\n`;\n      body += `  }, [${destructuredProps}]);\\n\\n`;\n    }\n\n    // Add accessibility\n    if (options.accessibility) {\n      body += `  const a11yProps = useA11y({\\n`;\n      body += `    role: '${this.inferAriaRole(spec.type)}',\\n`;\n      body += `    label: ${spec.props.find(p => p.name === 'label')?.name || `'${spec.name}'`}\\n`;\n      body += `  });\\n\\n`;\n    }\n\n    // JSX return\n    body += `  return (\\n`;\n    body += this.generateJSX(spec, options);\n    body += `  );\\n`;\n    body += `};`;\n\n    return body;\n  }\n\n  generateJSX(spec: ComponentSpec, options: GeneratorOptions): string {\n    const className = spec.styling === 'css-modules' ? `className={styles.${this.camelCase(spec.name)}}` : '';\n    const a11y = options.accessibility ? '{...a11yProps}' : '';\n\n    return `    <div ${className} ${a11y}>\\n` +\n           `      {/* TODO: Add component content */}\\n` +\n           `    </div>\\n`;\n  }\n}\n```\n\n### 3. Generate React Native Component\n\n```typescript\nclass ReactNativeGenerator {\n  generateComponent(spec: ComponentSpec): string {\n    return `\nimport React, { useState } from 'react';\nimport {\n  View,\n  Text,\n  StyleSheet,\n  TouchableOpacity,\n  AccessibilityInfo\n} from 'react-native';\n\ninterface ${spec.name}Props {\n${spec.props.map(p => `  ${p.name}${p.required ? '' : '?'}: ${this.mapNativeType(p.type)};`).join('\\n')}\n}\n\nexport const ${spec.name}: React.FC<${spec.name}Props> = ({\n  ${spec.props.map(p => p.name).join(',\\n  ')}\n}) => {\n  return (\n    <View\n      style={styles.container}\n      accessible={true}\n      accessibilityLabel=\"${spec.name} component\"\n    >\n      <Text style={styles.text}>\n        {/* Component content */}\n      </Text>\n    </View>\n  );\n};\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    padding: 16,\n    backgroundColor: '#fff',\n  },\n  text: {\n    fontSize: 16,\n    color: '#333',\n  },\n});\n`;\n  }\n\n  mapNativeType(webType: string): string {\n    const typeMap: Record<string, string> = {\n      'string': 'string',\n      'number': 'number',\n      'boolean': 'boolean',\n      'React.ReactNode': 'React.ReactNode',\n      'Function': '() => void'\n    };\n    return typeMap[webType] || webType;\n  }\n}\n```\n\n### 4. Generate Component Tests\n\n```typescript\nclass ComponentTestGenerator {\n  generateTests(spec: ComponentSpec): string {\n    return `\nimport { render, screen, fireEvent } from '@testing-library/react';\nimport { ${spec.name} } from './${spec.name}';\n\ndescribe('${spec.name}', () => {\n  const defaultProps = {\n${spec.props.filter(p => p.required).map(p => `    ${p.name}: ${this.getMockValue(p.type)},`).join('\\n')}\n  };\n\n  it('renders without crashing', () => {\n    render(<${spec.name} {...defaultProps} />);\n    expect(screen.getByRole('${this.inferAriaRole(spec.type)}')).toBeInTheDocument();\n  });\n\n  it('displays correct content', () => {\n    render(<${spec.name} {...defaultProps} />);\n    expect(screen.getByText(/content/i)).toBeVisible();\n  });\n\n${spec.props.filter(p => p.type.includes('()') || p.name.startsWith('on')).map(p => `\n  it('calls ${p.name} when triggered', () => {\n    const mock${this.capitalize(p.name)} = jest.fn();\n    render(<${spec.name} {...defaultProps} ${p.name}={mock${this.capitalize(p.name)}} />);\n\n    const trigger = screen.getByRole('button');\n    fireEvent.click(trigger);\n\n    expect(mock${this.capitalize(p.name)}).toHaveBeenCalledTimes(1);\n  });`).join('\\n')}\n\n  it('meets accessibility standards', async () => {\n    const { container } = render(<${spec.name} {...defaultProps} />);\n    const results = await axe(container);\n    expect(results).toHaveNoViolations();\n  });\n});\n`;\n  }\n\n  getMockValue(type: string): string {\n    if (type === 'string') return \"'test value'\";\n    if (type === 'number') return '42';\n    if (type === 'boolean') return 'true';\n    if (type.includes('[]')) return '[]';\n    if (type.includes('()')) return 'jest.fn()';\n    return '{}';\n  }\n}\n```\n\n### 5. Generate Styles\n\n```typescript\nclass StyleGenerator {\n  generateCSSModule(spec: ComponentSpec): string {\n    const className = this.camelCase(spec.name);\n    return `\n.${className} {\n  display: flex;\n  flex-direction: column;\n  padding: 1rem;\n  background-color: var(--bg-primary);\n}\n\n.${className}Title {\n  font-size: 1.5rem;\n  font-weight: 600;\n  color: var(--text-primary);\n  margin-bottom: 0.5rem;\n}\n\n.${className}Content {\n  flex: 1;\n  color: var(--text-secondary);\n}\n`;\n  }\n\n  generateStyledComponents(spec: ComponentSpec): string {\n    return `\nimport styled from 'styled-components';\n\nexport const ${spec.name}Container = styled.div\\`\n  display: flex;\n  flex-direction: column;\n  padding: \\${({ theme }) => theme.spacing.md};\n  background-color: \\${({ theme }) => theme.colors.background};\n\\`;\n\nexport const ${spec.name}Title = styled.h2\\`\n  font-size: \\${({ theme }) => theme.fontSize.lg};\n  font-weight: 600;\n  color: \\${({ theme }) => theme.colors.text.primary};\n  margin-bottom: \\${({ theme }) => theme.spacing.sm};\n\\`;\n`;\n  }\n\n  generateTailwind(spec: ComponentSpec): string {\n    return `\n// Use these Tailwind classes in your component:\n// Container: \"flex flex-col p-4 bg-white rounded-lg shadow\"\n// Title: \"text-xl font-semibold text-gray-900 mb-2\"\n// Content: \"flex-1 text-gray-700\"\n`;\n  }\n}\n```\n\n### 6. Generate Storybook Stories\n\n```typescript\nclass StorybookGenerator {\n  generateStories(spec: ComponentSpec): string {\n    return `\nimport type { Meta, StoryObj } from '@storybook/react';\nimport { ${spec.name} } from './${spec.name}';\n\nconst meta: Meta<typeof ${spec.name}> = {\n  title: 'Components/${spec.name}',\n  component: ${spec.name},\n  tags: ['autodocs'],\n  argTypes: {\n${spec.props.map(p => `    ${p.name}: { control: '${this.inferControl(p.type)}', description: '${p.description}' },`).join('\\n')}\n  },\n};\n\nexport default meta;\ntype Story = StoryObj<typeof ${spec.name}>;\n\nexport const Default: Story = {\n  args: {\n${spec.props.map(p => `    ${p.name}: ${p.defaultValue || this.getMockValue(p.type)},`).join('\\n')}\n  },\n};\n\nexport const Interactive: Story = {\n  args: {\n    ...Default.args,\n  },\n};\n`;\n  }\n\n  inferControl(type: string): string {\n    if (type === 'string') return 'text';\n    if (type === 'number') return 'number';\n    if (type === 'boolean') return 'boolean';\n    if (type.includes('[]')) return 'object';\n    return 'text';\n  }\n}\n```\n\n## Output Format\n\n1. **Component File**: Fully implemented React/React Native component\n2. **Type Definitions**: TypeScript interfaces and types\n3. **Styles**: CSS modules, styled-components, or Tailwind config\n4. **Tests**: Complete test suite with coverage\n5. **Stories**: Storybook stories for documentation\n6. **Index File**: Barrel exports for clean imports\n\nFocus on creating production-ready, accessible, and maintainable components that follow modern React patterns and best practices.\n"
    },
    {
      "name": "multi-platform",
      "title": "Multi-Platform Feature Development Workflow",
      "description": "Build and deploy the same feature consistently across web, mobile, and desktop platforms using API-first architecture and parallel implementation strategies.",
      "plugin": "multi-platform-apps",
      "source_path": "plugins/multi-platform-apps/commands/multi-platform.md",
      "category": "development",
      "keywords": [
        "cross-platform",
        "mobile",
        "web",
        "desktop",
        "react-native",
        "flutter"
      ],
      "content": "# Multi-Platform Feature Development Workflow\n\nBuild and deploy the same feature consistently across web, mobile, and desktop platforms using API-first architecture and parallel implementation strategies.\n\n[Extended thinking: This workflow orchestrates multiple specialized agents to ensure feature parity across platforms while maintaining platform-specific optimizations. The coordination strategy emphasizes shared contracts and parallel development with regular synchronization points. By establishing API contracts and data models upfront, teams can work independently while ensuring consistency. The workflow benefits include faster time-to-market, reduced integration issues, and maintainable cross-platform codebases.]\n\n## Phase 1: Architecture and API Design (Sequential)\n\n### 1. Define Feature Requirements and API Contracts\n- Use Task tool with subagent_type=\"backend-architect\"\n- Prompt: \"Design the API contract for feature: $ARGUMENTS. Create OpenAPI 3.1 specification with:\n  - RESTful endpoints with proper HTTP methods and status codes\n  - GraphQL schema if applicable for complex data queries\n  - WebSocket events for real-time features\n  - Request/response schemas with validation rules\n  - Authentication and authorization requirements\n  - Rate limiting and caching strategies\n  - Error response formats and codes\n  Define shared data models that all platforms will consume.\"\n- Expected output: Complete API specification, data models, and integration guidelines\n\n### 2. Design System and UI/UX Consistency\n- Use Task tool with subagent_type=\"ui-ux-designer\"\n- Prompt: \"Create cross-platform design system for feature using API spec: [previous output]. Include:\n  - Component specifications for each platform (Material Design, iOS HIG, Fluent)\n  - Responsive layouts for web (mobile-first approach)\n  - Native patterns for iOS (SwiftUI) and Android (Material You)\n  - Desktop-specific considerations (keyboard shortcuts, window management)\n  - Accessibility requirements (WCAG 2.2 Level AA)\n  - Dark/light theme specifications\n  - Animation and transition guidelines\"\n- Context from previous: API endpoints, data structures, authentication flows\n- Expected output: Design system documentation, component library specs, platform guidelines\n\n### 3. Shared Business Logic Architecture\n- Use Task tool with subagent_type=\"comprehensive-review::architect-review\"\n- Prompt: \"Design shared business logic architecture for cross-platform feature. Define:\n  - Core domain models and entities (platform-agnostic)\n  - Business rules and validation logic\n  - State management patterns (MVI/Redux/BLoC)\n  - Caching and offline strategies\n  - Error handling and retry policies\n  - Platform-specific adapter patterns\n  Consider Kotlin Multiplatform for mobile or TypeScript for web/desktop sharing.\"\n- Context from previous: API contracts, data models, UI requirements\n- Expected output: Shared code architecture, platform abstraction layers, implementation guide\n\n## Phase 2: Parallel Platform Implementation\n\n### 4a. Web Implementation (React/Next.js)\n- Use Task tool with subagent_type=\"frontend-developer\"\n- Prompt: \"Implement web version of feature using:\n  - React 18+ with Next.js 14+ App Router\n  - TypeScript for type safety\n  - TanStack Query for API integration: [API spec]\n  - Zustand/Redux Toolkit for state management\n  - Tailwind CSS with design system: [design specs]\n  - Progressive Web App capabilities\n  - SSR/SSG optimization where appropriate\n  - Web vitals optimization (LCP < 2.5s, FID < 100ms)\n  Follow shared business logic: [architecture doc]\"\n- Context from previous: API contracts, design system, shared logic patterns\n- Expected output: Complete web implementation with tests\n\n### 4b. iOS Implementation (SwiftUI)\n- Use Task tool with subagent_type=\"ios-developer\"\n- Prompt: \"Implement iOS version using:\n  - SwiftUI with iOS 17+ features\n  - Swift 5.9+ with async/await\n  - URLSession with Combine for API: [API spec]\n  - Core Data/SwiftData for persistence\n  - Design system compliance: [iOS HIG specs]\n  - Widget extensions if applicable\n  - Platform-specific features (Face ID, Haptics, Live Activities)\n  - Testable MVVM architecture\n  Follow shared patterns: [architecture doc]\"\n- Context from previous: API contracts, iOS design guidelines, shared models\n- Expected output: Native iOS implementation with unit/UI tests\n\n### 4c. Android Implementation (Kotlin/Compose)\n- Use Task tool with subagent_type=\"mobile-developer\"\n- Prompt: \"Implement Android version using:\n  - Jetpack Compose with Material 3\n  - Kotlin coroutines and Flow\n  - Retrofit/Ktor for API: [API spec]\n  - Room database for local storage\n  - Hilt for dependency injection\n  - Material You dynamic theming: [design specs]\n  - Platform features (biometric auth, widgets)\n  - Clean architecture with MVI pattern\n  Follow shared logic: [architecture doc]\"\n- Context from previous: API contracts, Material Design specs, shared patterns\n- Expected output: Native Android implementation with tests\n\n### 4d. Desktop Implementation (Optional - Electron/Tauri)\n- Use Task tool with subagent_type=\"frontend-mobile-development::frontend-developer\"\n- Prompt: \"Implement desktop version using Tauri 2.0 or Electron with:\n  - Shared web codebase where possible\n  - Native OS integration (system tray, notifications)\n  - File system access if needed\n  - Auto-updater functionality\n  - Code signing and notarization setup\n  - Keyboard shortcuts and menu bar\n  - Multi-window support if applicable\n  Reuse web components: [web implementation]\"\n- Context from previous: Web implementation, desktop-specific requirements\n- Expected output: Desktop application with platform packages\n\n## Phase 3: Integration and Validation\n\n### 5. API Documentation and Testing\n- Use Task tool with subagent_type=\"documentation-generation::api-documenter\"\n- Prompt: \"Create comprehensive API documentation including:\n  - Interactive OpenAPI/Swagger documentation\n  - Platform-specific integration guides\n  - SDK examples for each platform\n  - Authentication flow diagrams\n  - Rate limiting and quota information\n  - Postman/Insomnia collections\n  - WebSocket connection examples\n  - Error handling best practices\n  - API versioning strategy\n  Test all endpoints with platform implementations.\"\n- Context from previous: Implemented platforms, API usage patterns\n- Expected output: Complete API documentation portal, test results\n\n### 6. Cross-Platform Testing and Feature Parity\n- Use Task tool with subagent_type=\"unit-testing::test-automator\"\n- Prompt: \"Validate feature parity across all platforms:\n  - Functional testing matrix (features work identically)\n  - UI consistency verification (follows design system)\n  - Performance benchmarks per platform\n  - Accessibility testing (platform-specific tools)\n  - Network resilience testing (offline, slow connections)\n  - Data synchronization validation\n  - Platform-specific edge cases\n  - End-to-end user journey tests\n  Create test report with any platform discrepancies.\"\n- Context from previous: All platform implementations, API documentation\n- Expected output: Test report, parity matrix, performance metrics\n\n### 7. Platform-Specific Optimizations\n- Use Task tool with subagent_type=\"application-performance::performance-engineer\"\n- Prompt: \"Optimize each platform implementation:\n  - Web: Bundle size, lazy loading, CDN setup, SEO\n  - iOS: App size, launch time, memory usage, battery\n  - Android: APK size, startup time, frame rate, battery\n  - Desktop: Binary size, resource usage, startup time\n  - API: Response time, caching, compression\n  Maintain feature parity while leveraging platform strengths.\n  Document optimization techniques and trade-offs.\"\n- Context from previous: Test results, performance metrics\n- Expected output: Optimized implementations, performance improvements\n\n## Configuration Options\n\n- **--platforms**: Specify target platforms (web,ios,android,desktop)\n- **--api-first**: Generate API before UI implementation (default: true)\n- **--shared-code**: Use Kotlin Multiplatform or similar (default: evaluate)\n- **--design-system**: Use existing or create new (default: create)\n- **--testing-strategy**: Unit, integration, e2e (default: all)\n\n## Success Criteria\n\n- API contract defined and validated before implementation\n- All platforms achieve feature parity with <5% variance\n- Performance metrics meet platform-specific standards\n- Accessibility standards met (WCAG 2.2 AA minimum)\n- Cross-platform testing shows consistent behavior\n- Documentation complete for all platforms\n- Code reuse >40% between platforms where applicable\n- User experience optimized for each platform's conventions\n\n## Platform-Specific Considerations\n\n**Web**: PWA capabilities, SEO optimization, browser compatibility\n**iOS**: App Store guidelines, TestFlight distribution, iOS-specific features\n**Android**: Play Store requirements, Android App Bundles, device fragmentation\n**Desktop**: Code signing, auto-updates, OS-specific installers\n\nInitial feature specification: $ARGUMENTS"
    }
  ]
}